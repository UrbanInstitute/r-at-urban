[
  {
    "objectID": "graphics-guide.html#bar-plots",
    "href": "graphics-guide.html#bar-plots",
    "title": "Urban Institute R Graphics Guide",
    "section": "Bar Plots",
    "text": "Bar Plots\n\n\nOne Color\n\nmtcars %&gt;%\n  count(cyl) %&gt;%\n  ggplot(mapping = aes(x = factor(cyl), y = n)) +\n  geom_col() +\n  geom_text(mapping = aes(label = n), vjust = -1) +    \n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +\n  remove_ticks() +\n  remove_axis() \n\n\n\n\n\n\nOne Color (Rotated)\nThis example introduces coord_flip() and remove_axis(axis = \"x\", flip = TRUE). remove_axis() is from library(urbnthemes) and creates a custom theme for rotated bar plots.\n\nmtcars %&gt;%\n  count(cyl) %&gt;%\n  ggplot(mapping = aes(x = factor(cyl), y = n)) +\n  geom_col() +\n  geom_text(mapping = aes(label = n), hjust = -1) +  \n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  coord_flip() +\n  remove_axis(axis = \"x\", flip = TRUE)\n\n\n\n\n\n\nThree Colors\nThis is identical to the previous plot except colors and a legend are added with fill = cyl. Turning x into a factor with factor(cyl) skips 5 and 7 on the x-axis. Adding fill = cyl without factor() would have created a continuous color scheme and legend.\n\nmtcars %&gt;%\n  mutate(cyl = factor(cyl)) %&gt;%\n  count(cyl) %&gt;%\n  ggplot(mapping = aes(x = cyl, y = n, fill = cyl)) +\n  geom_col() +\n  geom_text(mapping = aes(label = n), vjust = -1) +    \n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +\n  remove_ticks() +\n  remove_axis()\n\n\n\n\n\n\nStacked Bar Plot\nAn additional aesthetic can easily be added to bar plots by adding fill = categorical variable to the mapping. Here, transmission type subsets each bar showing the count of cars with different numbers of cylinders.\n\nmtcars %&gt;%\n  mutate(am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n         cyl = factor(cyl)) %&gt;%  \n  group_by(am) %&gt;%\n  count(cyl) %&gt;%\n  group_by(cyl) %&gt;%\n  arrange(desc(am)) %&gt;%\n  mutate(label_height = cumsum(n)) %&gt;%\n  ggplot() +\n  geom_col(mapping = aes(x = cyl, y = n, fill = am)) +\n  geom_text(aes(x = cyl, y = label_height - 0.5, label = n, color = am)) +\n  scale_color_manual(values = c(\"white\", \"black\")) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  remove_ticks() +\n  remove_axis() +\n  guides(color = \"none\")\n\n\n\n\n\n\nStacked Bar Plot With Position = Fill\nThe previous examples used geom_col(), which takes a y value for bar height. This example uses geom_bar() which sums the values and generates a value for bar heights. In this example, position = \"fill\" in geom_bar() changes the y-axis from count to the proportion of each bar.\n\nmtcars %&gt;%\n  mutate(am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n         cyl = factor(cyl)) %&gt;%  \n  ggplot() +\n  geom_bar(mapping = aes(x = cyl, fill = am), position = \"fill\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1)), labels = scales::percent) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  remove_ticks() +\n  guides(color = \"none\")\n\n\n\n\n\n\nDodged Bar Plot\nSubsetted bar charts in ggplot2 are stacked by default. position = \"dodge\" in geom_col() expands the bar chart so the bars appear next to each other.\n\nmtcars %&gt;%\n  mutate(am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n         cyl = factor(cyl)) %&gt;%\n  group_by(am) %&gt;%\n  count(cyl) %&gt;%\n  ggplot(mapping = aes(cyl, y = n, fill = factor(am))) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = n), position = position_dodge(width = 0.7), vjust = -1) +    \n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  remove_ticks() +\n  remove_axis()\n\n\n\n\n\n\nLollipop plot/Cleveland dot plot\nLollipop plots and Cleveland dot plots are minimalist alternatives to bar plots. The key to both plots is to order the data based on the continuous variable using arrange() and then turn the discrete variable into a factor with the ordered levels of the continuous variable using mutate(). This step “stores” the order of the data.\n\nLollipop plot\n\nmtcars %&gt;%\n    rownames_to_column(\"model\") %&gt;%\n    arrange(mpg) %&gt;%\n    mutate(model = factor(model, levels = .$model)) %&gt;%\n    ggplot(aes(mpg, model)) +\n        geom_segment(aes(x = 0, xend = mpg, y = model, yend = model)) + \n        geom_point() +\n        scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, 40)) +\n        labs(x = NULL, \n                 y = \"Miles Per Gallon\")\n\n\n\n\n\n\nCleveland dot plot\n\nmtcars %&gt;%\n    rownames_to_column(\"model\") %&gt;%\n    arrange(mpg) %&gt;%\n    mutate(model = factor(model, levels = .$model)) %&gt;%\n    ggplot(aes(mpg, model)) +\n        geom_point() +\n        scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, 40)) +\n        labs(x = NULL, \n                 y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\nDumbell plot"
  },
  {
    "objectID": "graphics-guide.html#scatter-plots",
    "href": "graphics-guide.html#scatter-plots",
    "title": "Urban Institute R Graphics Guide",
    "section": "Scatter Plots",
    "text": "Scatter Plots\n\n\nOne Color Scatter Plot\nScatter plots are useful for showing relationships between two or more variables. Use scatter_grid() from library(urbnthemes) to easily add vertical grid lines for scatter plots.\n\nmtcars %&gt;%\n  ggplot(mapping = aes(x = wt, y = mpg)) +\n  geom_point() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:8 * 5) +\n  labs(x = \"Weight (thousands of pounds)\",\n       y = \"City MPG\") +\n  scatter_grid()\n\n\n\n\n\n\nHigh-Density Scatter Plot with Transparency\nLarge numbers of observations can sometimes make scatter plots tough to interpret because points overlap. Adding alpha = with a number between 0 and 1 adds transparency to points and clarity to plots. Now it’s easy to see that jewelry stores are probably rounding up but not rounding down carats!\n\ndiamonds %&gt;%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 20000),\n                     breaks = 0:4 * 5000,\n                     labels = scales::dollar) +\n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid()\n\n\n\n\n\n\nHex Scatter Plot\nSometimes transparency isn’t enough to bring clarity to a scatter plot with many observations. As n increases into the hundreds of thousands and even millions, geom_hex can be one of the best ways to display relationships between two variables.\n\ndiamonds %&gt;%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_hex(mapping = aes(fill = after_stat(count))) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 20000),\n                     breaks = 0:4 * 5000,\n                     labels = scales::dollar) +\n    scale_fill_gradientn(labels = scales::comma) +  \n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid() +\n  theme(legend.position = \"right\",\n        legend.direction = \"vertical\")\n\n\n\n\n\n\nScatter Plots With Random Noise\nSometimes scatter plots have many overlapping points but a reasonable number of observations. geom_jitter adds a small amount of random noise so points are less likely to overlap. width and height control the amount of noise that is added. In the following before-and-after, notice how many more points are visible after adding jitter.\n\nBefore\n\nmpg %&gt;%\n  ggplot(mapping = aes(x = displ, y = cty)) +\n  geom_point() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 8),\n                     breaks = 0:8) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:4 * 10) +\n  labs(x = \"Displacement\",\n       y = \"City MPG\") +\n  scatter_grid()\n\n\n\n\n\n\nAfter\n\nset.seed(2017)\nmpg %&gt;%\n  ggplot(mapping = aes(x = displ, y = cty)) +\n  geom_jitter() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 8),\n                     breaks = 0:8) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:4 * 10) +\n  labs(x = \"Displacement\",\n       y = \"City MPG\") +\n  scatter_grid()\n\n\n\n\n\n\n\nScatter Plots with Varying Point Size\nWeights and populations can be mapped in scatter plots to the size of the points. Here, the number of households in each state is mapped to the size of each point using aes(size = hhpop). Note: ggplot2::geom_point() is used instead of geom_point().\n\nurbnmapr::statedata %&gt;%\n  ggplot(mapping = aes(x = medhhincome, y = horate)) +\n  ggplot2::geom_point(mapping = aes(size = hhpop), alpha = 0.3) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(30000, 80000),\n                     breaks = 3:8 * 10000,\n                     labels = scales::dollar) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 0.8),\n                     breaks = 0:4 * 0.2) +\n  scale_radius(range = c(3, 15),\n               breaks = c(2500000, 7500000, 12500000), \n               labels = scales::comma) +\n  labs(x = \"Household income\",\n       y = \"Homeownership rate\") +\n  scatter_grid() +\n    theme(plot.margin = margin(r = 20))\n\n\n\n\n\n\nScatter Plots with Fill\nA third aesthetic can be added to scatter plots. Here, color signifies the number of cylinders in each car. Before ggplot() is called, Cylinders is created using library(dplyr) and the piping operator %&gt;%.\n\nmtcars %&gt;%\n  mutate(cyl = paste(cyl, \"cylinders\")) %&gt;%\n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:8 * 5) +\n  labs(x = \"Weight (thousands of pounds)\",\n       y = \"City MPG\") +\n  scatter_grid()"
  },
  {
    "objectID": "graphics-guide.html#line-plots",
    "href": "graphics-guide.html#line-plots",
    "title": "Urban Institute R Graphics Guide",
    "section": "Line Plots",
    "text": "Line Plots\n\n\neconomics %&gt;%\n  ggplot(mapping = aes(x = date, y = unemploy)) +\n  geom_line() +\n  scale_x_date(expand = expansion(mult = c(0.002, 0)), \n               breaks = \"10 years\",\n               limits = c(as.Date(\"1961-01-01\"), as.Date(\"2020-01-01\")),\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     breaks = 0:4 * 4000,\n                     limits = c(0, 16000),\n                     labels = scales::comma) +\n  labs(x = \"Year\", \n       y = \"Number Unemployed (1,000s)\")\n\n\n\n\n\nLines Plots With Multiple Lines\n\nlibrary(gapminder)\n\ngapminder %&gt;%\n  filter(country %in% c(\"Australia\", \"Canada\", \"New Zealand\")) %&gt;%\n  mutate(country = factor(country, levels = c(\"Canada\", \"Australia\", \"New Zealand\"))) %&gt;%\n  ggplot(aes(year, gdpPercap, color = country)) +\n  geom_line() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     breaks = c(1952 + 0:12 * 5), \n                     limits = c(1952, 2007)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar, \n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Per capita GDP (US dollars)\")\n\n\n\n\nPlotting more than one variable can be useful for seeing the relationship of variables over time, but it takes a small amount of data munging.\nThis is because ggplot2 wants data in a “long” format instead of a “wide” format for line plots with multiple lines. gather() and spread() from the tidyr package make switching back-and-forth between “long” and “wide” painless. Essentially, variable titles go into “key” and variable values go into “value”. Then ggplot2, turns the different levels of the key variable (population, unemployment) into colors.\n\nas_tibble(EuStockMarkets) %&gt;%\n    mutate(date = time(EuStockMarkets)) %&gt;%\n    gather(key = \"key\", value = \"value\", -date) %&gt;%\n    ggplot(mapping = aes(x = date, y = value, color = key)) +\n    geom_line() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(1991, 1999), \n                     breaks = c(1991, 1993, 1995, 1997, 1999)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     breaks = 0:4 * 2500,\n                     labels = scales::dollar, \n                     limits = c(0, 10000)) +  \n    labs(x = \"Date\",\n             y = \"Value\")\n\n\n\n\n\n\nStep plot\ngeom_line() connects coordinates with the shortest possible straight line. Sometimes step plots are necessary because y values don’t change between coordinates. For example, the upper-bound of the Federal Funds Rate is set at regular intervals and remains constant until it is changed.\n\n# downloaded from FRED on 2018-12-06\n\n# https://fred.stlouisfed.org/series/DFEDTARU\n\nfed_fund_rate &lt;- read_csv(\n  \"date, fed_funds_rate\n   2014-01-01,0.0025\n   2015-12-16,0.0050\n   2016-12-14,0.0075\n   2017-03-16,0.0100\n   2017-06-15,0.0125\n   2017-12-14,0.0150\n   2018-03-22,0.0175\n   2018-06-14,0.0200\n   2018-09-27,0.0225\n   2018-12-06,0.0225\")\n\nfed_fund_rate %&gt;%\n  ggplot(mapping = aes(x = date, y = fed_funds_rate)) + \n  geom_step() +\n  scale_x_date(expand = expansion(mult = c(0.002, 0)), \n               breaks = \"1 year\",\n               limits = c(as.Date(\"2014-01-01\"), as.Date(\"2019-01-01\")),\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     breaks = c(0, 0.01, 0.02, 0.03),\n                     limits = c(0, 0.03),\n                     labels = scales::percent) +  \n    labs(x = \"Date\",\n             y = \"Upper-bound of the Federal Funds Rate\")\n\n\n\n\n\n\nPath plot\nThe Beveridge curve is a macroeconomic plot that displays a relationship between the unemployment rate and the vacancy rate. Movements along the curve indicate changes in the business cyle and horizontal shifts of the curve suggest structural changes in the labor market.\nLines in Beveridge curves do not monotonically move from left to right. Therefore, it is necessary to use geom_path().\n\n# seasonally-adjusted, quarterly vacancy rate - JOLTS # seasonally-adjusted, quarterly unemployment rate - CPS\n\n# pulled from FRED on April 11, 2018. \n\nlibrary(ggrepel)\n\nbeveridge &lt;- read_csv(\n    \"quarter, vacanacy_rate, unempoyment_rate\n    2006-01-01,0.0310,0.0473\n    2006-04-01,0.0316,0.0463\n    2006-07-01,0.0313,0.0463\n    2006-10-01,0.0310,0.0443\n    2007-01-01,0.0323,0.0450\n    2007-04-01,0.0326,0.0450\n    2007-07-01,0.0316,0.0466\n    2007-10-01,0.0293,0.0480\n    2008-01-01,0.0286,0.0500\n    2008-04-01,0.0280,0.0533\n    2008-07-01,0.0253,0.0600\n    2008-10-01,0.0220,0.0686\n    2009-01-01,0.0196,0.0826\n    2009-04-01,0.0180,0.0930\n    2009-07-01,0.0176,0.0963\n    2009-10-01,0.0180,0.0993\n    2010-01-01,0.0196,0.0983\n    2010-04-01,0.0220,0.0963\n    2010-07-01,0.0216,0.0946\n    2010-10-01,0.0220,0.0950\n    2011-01-01,0.0226,0.0903\n    2011-04-01,0.0236,0.0906\n    2011-07-01,0.0250,0.0900\n    2011-10-01,0.0243,0.0863\n    2012-01-01,0.0270,0.0826\n    2012-04-01,0.0270,0.0820\n    2012-07-01,0.0266,0.0803\n    2012-10-01,0.0260,0.0780\n    2013-01-01,0.0276,0.0773\n    2013-04-01,0.0280,0.0753\n    2013-07-01,0.0280,0.0723\n    2013-10-01,0.0276,0.0693\n    2014-01-01,0.0290,0.0666\n    2014-04-01,0.0323,0.0623\n    2014-07-01,0.0326,0.0610\n    2014-10-01,0.0330,0.0570\n    2015-01-01,0.0350,0.0556\n    2015-04-01,0.0366,0.0540\n    2015-07-01,0.0373,0.0510\n    2015-10-01,0.0360,0.0500\n    2016-01-01,0.0386,0.0493\n    2016-04-01,0.0383,0.0486\n    2016-07-01,0.0383,0.0493\n    2016-10-01,0.0363,0.0473\n    2017-01-01,0.0366,0.0466\n    2017-04-01,0.0390,0.0433\n    2017-07-01,0.0406,0.0430\n    2017-10-01,0.0386,0.0410\")\n\nlabels &lt;- beveridge %&gt;%\n  filter(lubridate::month(quarter) == 1)\n\nbeveridge %&gt;%\n    ggplot() +\n    geom_path(mapping = aes(x = unempoyment_rate, y = vacanacy_rate), alpha = 0.5) +\n  geom_point(data = labels, mapping = aes(x = unempoyment_rate, y = vacanacy_rate)) +\n  geom_text_repel(data = labels, mapping = aes(x = unempoyment_rate, y = vacanacy_rate, label = lubridate::year(quarter))) +  \n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0.04, 0.1),\n                     labels = scales::percent) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     breaks = c(0, 0.01, 0.02, 0.03, 0.04, 0.05),\n                     limits = c(0, 0.05),\n                     labels = scales::percent) +  \n    labs(x = \"Seasonally-adjusted unemployment rate\",\n             y = \"Seasonally-adjusted vacancy rate\") +  \n  scatter_grid()\n\n\n\n\n\n\nSlope plots\n\n# https://www.bls.gov/lau/\nlibrary(ggrepel)\n\nunemployment &lt;- tibble(\n    time = c(\"October 2009\", \"October 2009\", \"October 2009\", \"August 2017\", \"August 2017\", \"August 2017\"),\n    rate = c(7.4, 7.1, 10.0, 3.9, 3.8, 6.4),\n    state = c(\"Maryland\", \"Virginia\", \"Washington, D.C.\", \"Maryland\", \"Virginia\", \"Washington, D.C.\")\n)\n\nlabel &lt;- tibble(label = c(\"October 2009\", \"August 2017\"))\noctober &lt;- filter(unemployment, time == \"October 2009\")\naugust &lt;- filter(unemployment, time == \"August 2017\")\n\nunemployment %&gt;%\n    mutate(time = factor(time, levels = c(\"October 2009\", \"August 2017\")),\n           state = factor(state, levels = c(\"Washington, D.C.\", \"Maryland\", \"Virginia\"))) %&gt;%\n    ggplot() + \n    geom_line(aes(time, rate, group = state, color = state), show.legend = FALSE) +\n    geom_point(aes(x = time, y = rate, color = state)) +\n    labs(subtitle = \"Unemployment Rate\") +\n    theme(axis.ticks.x = element_blank(),\n                axis.title.x = element_blank(),\n                axis.ticks.y = element_blank(),\n        axis.title.y = element_blank(), \n        axis.text.y = element_blank(),\n                panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n                axis.line = element_blank()) +\n    geom_text_repel(data = october, mapping = aes(x = time, y = rate, label = as.character(rate)), nudge_x = -0.06) + \n    geom_text_repel(data = august, mapping = aes(x = time, y = rate, label = as.character(rate)), nudge_x = 0.06)"
  },
  {
    "objectID": "graphics-guide.html#univariate",
    "href": "graphics-guide.html#univariate",
    "title": "Urban Institute R Graphics Guide",
    "section": "Univariate",
    "text": "Univariate\n\nThere are a number of ways to explore the distributions of univariate data in R. Some methods, like strip charts, show all data points. Other methods, like the box and whisker plot, show selected data points that communicate key values like the median and 25th percentile. Finally, some methods don’t show any of the underlying data but calculate density estimates. Each method has advantages and disadvantages, so it is worthwhile to understand the different forms. For more information, read 40 years of boxplots by Hadley Wickham and Lisa Stryjewski.\n\nStrip Chart\nStrip charts, the simplest univariate plot, show the distribution of values along one axis. Strip charts work best with variables that have plenty of variation. If not, the points tend to cluster on top of each other. Even if the variable has plenty of variation, it is often important to add transparency to the points with alpha = so overlapping values are visible.\n\nmsleep %&gt;%\n  ggplot(aes(x = sleep_total, y = factor(1))) +\n  geom_point(alpha = 0.2, size = 5) +\n  labs(y = NULL) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 25), \n                     breaks = 0:5 * 5) +\n  scale_y_discrete(labels = NULL) +\n  labs(title = \"Total Sleep Time of Different Mammals\",\n       x = \"Total sleep time (hours)\",\n       y = NULL) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\n\n\nStrip Chart with Highlighting\nBecause strip charts show all values, they are useful for showing where selected points lie in the distribution of a variable. The clearest way to do this is by adding geom_point() twice with filter() in the data argument. This way, the highlighted values show up on top of unhighlighted values.\n\nggplot() +\n  geom_point(data = filter(msleep, name != \"Red fox\"), \n                    aes(x = sleep_total, \n                        y = factor(1)),\n             alpha = 0.2, \n             size = 5,\n                     color = \"grey50\") +\n  geom_point(data = filter(msleep, name == \"Red fox\"),\n             aes(x = sleep_total, \n                 y = factor(1), \n                 color = name),\n             alpha = 0.8,\n             size = 5) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 25), \n                     breaks = 0:5 * 5) +  \n  scale_y_discrete(labels = NULL) +\n  labs(title = \"Total Sleep Time of Different Mammals\",\n       x = \"Total sleep time (hours)\",\n       y = NULL,\n       legend) +\n  guides(color = guide_legend(title = NULL)) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\n\n\nSubsetted Strip Chart\nAdd a y variable to see the distributions of the continuous variable in subsets of a categorical variable.\n\nlibrary(forcats)\n\nmsleep %&gt;%\n  filter(!is.na(vore)) %&gt;%\n  mutate(vore = fct_recode(vore, \n                            \"Insectivore\" = \"insecti\",\n                            \"Omnivore\" = \"omni\", \n                            \"Herbivore\" = \"herbi\", \n                            \"Carnivore\" = \"carni\"\n                            )) %&gt;%\n  ggplot(aes(x = sleep_total, y = vore)) +\n  geom_point(alpha = 0.2, size = 5) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 25), \n                     breaks = 0:5 * 5) +  \n  labs(title = \"Total Sleep Time of Different Mammals by Diet\",\n       x = \"Total sleep time (hours)\",\n       y = NULL) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\n\n\nBeeswarm Plots\nBeesward plots are a variation of strip charts that shows the distribution of data, but without the points overlaping.\n\nlibrary(ggbeeswarm)\n\ntxhousing %&gt;%\n    filter(city %in% c(\"Austin\",\"Houston\",\"Dallas\",\"San Antonio\",\"Fort Worth\")) %&gt;% \n  ggplot(aes(x = median, y = city)) +\n  geom_beeswarm(alpha = 0.2, size = 5) + \n    scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Household Sale Price by City\",\n       x = \"Sale Price\",\n       y = NULL) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\n\n\nHistograms\nHistograms divide the distribution of a variable into n equal-sized bins and then count and display the number of observations in each bin. Histograms are sensitive to bin width. As ?geom_histogram notes, “You should always override [the default binwidth] value, exploring multiple widths to find the best to illustrate the stories in your data.”\n\nggplot(data = diamonds, mapping = aes(x = depth)) + \n  geom_histogram(bins = 100) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, 100)) +  \n  scale_y_continuous(expand = expansion(mult = c(0, 0.2)), labels = scales::comma) +\n  labs(x = \"Depth\",\n       y = \"Count\")\n\n\n\n\n\n\nBoxplots\nBoxplots were invented in the 1970s by John Tukey1. Instead of showing the underlying data or binned counts of the underlying data, they focus on important values like the 25th percentile, median, and 75th percentile.\n\nInsectSprays %&gt;%\n  ggplot(mapping =  aes(x = spray, y = count)) +\n  geom_boxplot() +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +\n  labs(x = \"Type of insect spray\",\n       y = \"Number of dead insects\") +\n  remove_ticks()\n\n\n\n\n\n\nSmoothed Kernel Density Plots\nContinuous variables with smooth distributions are sometimes better represented with smoothed kernel density estimates than histograms or boxplots. geom_density() computes and plots a kernel density estimate. Notice the lumps around integers and halves in the following distribution because of rounding.\n\ndiamonds %&gt;%\n  ggplot(mapping = aes(carat)) +\n  geom_density(color = NA) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, NA)) +\n    scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +\n  labs(x = \"Carat\",\n       y = \"Density\")\n\n\n\n\n\ndiamonds %&gt;%\n  mutate(cost = ifelse(price &gt; 5500, \"More than $5,500 +\", \"$0 to $5,500\")) %&gt;%\n  ggplot(mapping = aes(carat, fill = cost)) +\n  geom_density(alpha = 0.25, color = NA) +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(0, NA)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Carat\",\n       y = \"Density\")\n\n\n\n\n\n\nRidgeline Plots\nRidgeline plots are partially overlapping smoothed kernel density plots faceted by a categorical variable that pack a lot of information into one elegant plot.\n\nlibrary(ggridges)\n\nggplot(diamonds, mapping = aes(x = price, y = cut)) +\n    geom_density_ridges(fill = \"#1696d2\") +\n  labs(x = \"Price\",\n       y = \"Cut\")\n\n\n\n\n\n\nViolin Plots\nViolin plots are symmetrical displays of smooth kernel density plots.\n\nInsectSprays %&gt;%\n  ggplot(mapping = aes(x = spray, y = count, fill = spray)) +\n  geom_violin(color = NA) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +\n  labs(x = \"Type of insect spray\",\n       y = \"Number of dead insects\") +\n  remove_ticks()\n\n\n\n\n\n\nBean Plot\nIndividual outliers and important summary values are not visible in violin plots or smoothed kernel density plots. Bean plots, created by Peter Kampstra in 2008, are violin plots with data shown as small lines in a one-dimensional sstrip plot and larger lines for the mean.\n\nmsleep %&gt;%\n  filter(!is.na(vore)) %&gt;%\n  mutate(vore = fct_recode(vore, \n                            \"Insectivore\" = \"insecti\",\n                            \"Omnivore\" = \"omni\", \n                            \"Herbivore\" = \"herbi\", \n                            \"Carnivore\" = \"carni\"\n                            )) %&gt;%\n  ggplot(aes(x = vore, y = sleep_total, fill = vore)) +\n  stat_summary(fun = \"mean\",\n               colour = \"black\", \n               size = 30,\n               shape = 95,\n               geom = \"point\") +\n  geom_violin(color = NA) +\n  geom_jitter(width = 0,\n              height = 0.05,\n              alpha = 0.4,\n              shape = \"-\",\n              size = 10,\n                        color = \"grey50\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +  \n    labs(x = NULL,\n         y = \"Total sleep time (hours)\") +\n  theme(legend.position = \"none\") +\n  remove_ticks()"
  },
  {
    "objectID": "graphics-guide.html#area-plot",
    "href": "graphics-guide.html#area-plot",
    "title": "Urban Institute R Graphics Guide",
    "section": "Area Plot",
    "text": "Area Plot\n\n\nStacked Area\n\ntxhousing %&gt;%\n  filter(city %in% c(\"Austin\",\"Houston\",\"Dallas\",\"San Antonio\",\"Fort Worth\")) %&gt;%\n  group_by(city, year) %&gt;%\n  summarize(sales = sum(sales)) %&gt;%\n  ggplot(aes(x = year, y = sales, fill = city)) +\n  geom_area(position = \"stack\") +\n  scale_x_continuous(expand = expansion(mult = c(0, 0)),\n                     limits = c(2000, 2015),\n                     breaks = 2000 + 0:15) +  \n  scale_y_continuous(expand = expansion(mult = c(0, 0.2)), \n                     labels = scales::comma) +\n  labs(x = \"Year\",\n       y = \"Home sales\")\n\n\n\n\n\n\nFilled Area\n\ntxhousing %&gt;%\n  filter(city %in% c(\"Austin\",\"Houston\",\"Dallas\",\"San Antonio\",\"Fort Worth\")) %&gt;%\n  group_by(city, year) %&gt;%\n  summarize(sales = sum(sales)) %&gt;%\n  ggplot(aes(x = year, y = sales, fill = city)) +\n  geom_area(position = \"fill\") +\n  scale_x_continuous(expand = expansion(mult = c(0, 0)),\n                     limits = c(2000, 2015),\n                     breaks = 2000 + 0:15) +  \n  scale_y_continuous(expand = expansion(mult = c(0, 0.02)),\n                     breaks = c(0, 0.25, 0.5, 0.75, 1),\n                     labels = scales::percent) +\n  labs(x = \"Year\",\n       y = \"Home sales\")"
  },
  {
    "objectID": "graphics-guide.html#sankey-plot",
    "href": "graphics-guide.html#sankey-plot",
    "title": "Urban Institute R Graphics Guide",
    "section": "Sankey Plot",
    "text": "Sankey Plot\n\nSankey plots visualize flows from one set of variables to another. This can be useful for showing outcomes from the start of a program to the end. You’ll need to install the ggsankey package to create Sankey plots in R. In this example I make a dummy data set of housing status prior to program start and at exit to show the flow of people between outcomes. A key step is to transform your data set using the make_long function from the package. This creates a data frame that specifies each of the initial nodes and how they flow into the next stage.\n\n# load ggsankey package\nremotes::install_github(\"davidsjoberg/ggsankey\")\nlibrary(ggsankey)\n\n# create a dummy dataset of housing status\ndf &lt;- data_frame(entry_status = c(rep(\"Housed\", 7), rep(\"Unhoused\", 15), rep(\"Staying w/ Family\", 8)), \n                 exit_status = c(rep(\"Housed\", 15), rep(\"Unhoused\", 2), rep(\"Staying w/ Family\", 13))) %&gt;% \n    # transform the data frame into the proper format for the sankey plot\n  make_long(entry_status, exit_status) %&gt;% \n    # recode the labels to be cleaner in the plot \n  mutate(x = recode(x, entry_status = \"Prior Housing Status\", exit_status = \"Exit Housing Status\"),\n         next_x = recode(next_x, entry_status = \"Prior Housing Status\", exit_status = \"Exit Housing Status\"))\n\n# create sankey plot\nggplot(df, aes(x = x, \n               next_x = next_x, \n               node = node, \n               next_node = next_node,\n               fill = factor(node), \n               label = node)) +\n  geom_sankey(flow.alpha = 0.5, node.color = 1, show.legend = FALSE) +\n  # add labels to plot and style\n  geom_sankey_label(size = 3.5, color = 1, fill = \"white\") +\n  theme_sankey(base_size = 16)+\n  labs(x = NULL)"
  },
  {
    "objectID": "graphics-guide.html#heat-map",
    "href": "graphics-guide.html#heat-map",
    "title": "Urban Institute R Graphics Guide",
    "section": "Heat Map",
    "text": "Heat Map\n\n\nlibrary(fivethirtyeight)\n\nbad_drivers %&gt;%\n  filter(state %in% c(\"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Connecticut\", \"New York\")) %&gt;%\n  mutate(`Number of\\nDrivers` = scale(num_drivers),\n         `Percent\\nSpeeding` = scale(perc_speeding),\n         `Percent\\nAlcohol` = scale(perc_alcohol),\n         `Percent Not\\nDistracted` = scale(perc_not_distracted),\n         `Percent No\\nPrevious` = scale(perc_no_previous),\n         state = factor(state, levels = rev(state))\n         ) %&gt;%\n  select(-insurance_premiums, -losses, -(num_drivers:losses)) %&gt;%\n  gather(`Number of\\nDrivers`:`Percent No\\nPrevious`, key = \"variable\", value = \"SD's from Mean\") %&gt;%\n  ggplot(aes(variable, state)) +\n    geom_tile(aes(fill = `SD's from Mean`)) +\n    labs(x = NULL,\n         y = NULL) + \n    scale_fill_gradientn() +\n    theme(legend.position = \"right\",\n          legend.direction = \"vertical\",\n          axis.line.x = element_blank(),\n          panel.grid.major.y = element_blank()) +\n  remove_ticks()\n\n\n\n#https://learnr.wordpress.com/2010/01/26/ggplot2-quick-heatmap-plotting/"
  },
  {
    "objectID": "graphics-guide.html#faceting-and-small-multiples",
    "href": "graphics-guide.html#faceting-and-small-multiples",
    "title": "Urban Institute R Graphics Guide",
    "section": "Faceting and Small Multiples",
    "text": "Faceting and Small Multiples\n\n\nfacet_wrap()\nR’s faceting system is a powerful way to make “small multiples”.\nSome edits to the theme may be necessary depending upon how many rows and columns are in the plot.\n\ndiamonds %&gt;%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  facet_wrap(~cut, ncol = 5) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0)),\n                     limits = c(0, 6)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0)),\n                     limits = c(0, 20000), \n                     labels = scales::dollar) +\n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid()\n\n\n\n\n\n\nfacet_grid()\n\ndiamonds %&gt;%\n  filter(color %in% c(\"D\", \"E\", \"F\", \"G\")) %&gt;%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  facet_grid(color ~ cut) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0)),\n                     limits = c(0, 4)) +  \n  scale_y_continuous(expand = expansion(mult = c(0, 0)),\n                     limits = c(0, 20000), \n                     labels = scales::dollar) +\n  labs(x = \"Carat\",\n       y = \"Price\") +\n  theme(panel.spacing = unit(20L, \"pt\")) +\n  scatter_grid()"
  },
  {
    "objectID": "graphics-guide.html#smoothers",
    "href": "graphics-guide.html#smoothers",
    "title": "Urban Institute R Graphics Guide",
    "section": "Smoothers",
    "text": "Smoothers\n\ngeom_smooth() fits and plots models to data with two or more dimensions.\nUnderstanding and manipulating defaults is more important for geom_smooth() than other geoms because it contains a number of assumptions. geom_smooth() automatically uses loess for datasets with fewer than 1,000 observations and a generalized additive model with formula = y ~ s(x, bs = \"cs\") for datasets with greater than 1,000 observations. Both default to a 95% confidence interval with the confidence interval displayed.\nModels are chosen with method = and can be set to lm(), glm(), gam(), loess(), rlm(), and more. Formulas can be specified with formula = and y ~ x syntax. Plotting the standard error is toggled with se = TRUE and se = FALSE, and level is specificed with level =. As always, more information can be seen in RStudio with ?geom_smooth().\ngeom_point() adds a scatterplot to geom_smooth(). The order of the function calls is important. The function called second will be layed on top of the function called first.\n\ndiamonds %&gt;%\n  ggplot(mapping = aes(x = carat, y = price)) +\n    geom_point(alpha = 0.05) +\n    geom_smooth(color =  \"#ec008b\") +\n    scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                       limits = c(0, 5),\n                       breaks = 0:5) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                     limits = c(0, 20000), \n                     labels = scales::dollar) +  \n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid()\n\n\n\n\ngeom_smooth can be subset by categorical and factor variables. This requires subgroups to have a decent number of observations and and a fair amount of variability across the x-axis. Confidence intervals often widen at the ends so special care is needed for the chart to be meaningful and readable.\nThis example uses Loess with MPG = displacement.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = factor(cyl))) +\n    geom_point(alpha = 0.2) +\n    geom_smooth() +\n    scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                       limits = c(0, 7),\n                       breaks = 0:7) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                     limits = c(0, 60)) +  \n    labs(x = \"Engine displacement\",\n             y = \"Highway MPG\") +\n  scatter_grid()\n\n\n\n\nThis example uses linear models with MPG = displacement.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = factor(cyl))) +\n    geom_point(alpha = 0.2) +\n    geom_smooth(method = \"lm\") +\n    scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                       limits = c(0, 7),\n                       breaks = 0:7) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                     limits = c(0, 60)) +  \n    labs(x = \"Engine displacement\",\n             y = \"Highway MPG\") +\n  scatter_grid()"
  },
  {
    "objectID": "graphics-guide.html#highlighting",
    "href": "graphics-guide.html#highlighting",
    "title": "Urban Institute R Graphics Guide",
    "section": "Highlighting",
    "text": "Highlighting\n\nlibrary(gghighlight) enables the intuitive highlighting of ggplot2 plots. gghighlight modifies existing ggplot2 objects, so no other code should change. All of the highlighting is handled by the function gghighlight(), which can handle all types of geoms.\nWarning: R will throw an error if too many colors are highlighted because of the design of urbnthemes. Simply decrease the number of highlighted geoms to solve this issue.\nThere are two main ways to highlight.\n\nThreshold\nThe first way to highlight is with a threshold. Add a logical test to gghighlight() to describe which lines should be highlighted. Here, lines with maximum change in per-capita Gross Domestic Product greater than $35,000 are highlighted by gghighlight(max(pcgpd_change) &gt; 35000, use_direct_label = FALSE).\n\nlibrary(gghighlight)\nlibrary(gapminder)\n\ndata &lt;- gapminder %&gt;%\n  filter(continent %in% c(\"Europe\")) %&gt;%\n  group_by(country) %&gt;%\n  mutate(pcgpd_change = ifelse(year == 1952, 0, gdpPercap - lag(gdpPercap))) %&gt;%\n  mutate(pcgpd_change = cumsum(pcgpd_change))\n  \ndata %&gt;%\n  ggplot(aes(year, pcgpd_change, group = country, color = country)) +\n  geom_line() +\n  gghighlight(max(pcgpd_change) &gt; 35000, use_direct_label = FALSE) +  \n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)),\n                     breaks = c(seq(1950, 2010, 10)),\n                     limits = c(1950, 2010)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar,\n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Change in per-capita GDP (US dollars)\")\n\n\n\n\n\n\nRank\nThe second way to highlight is by rank. Here, the countries with the first highest values for change in per-capita Gross Domestic Product are highlighted with gghighlight(max(pcgpd_change), max_highlight = 5, use_direct_label = FALSE).\n\ndata %&gt;%\n  ggplot(aes(year, pcgpd_change, group = country, color = country)) +\n  geom_line() +\n  gghighlight(max(pcgpd_change), max_highlight = 5, use_direct_label = FALSE) +  \n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)),\n                     breaks = c(seq(1950, 2010, 10)),\n                     limits = c(1950, 2010)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar,\n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Change in per-capita GDP (US dollars)\")\n\n\n\n\n\n\nFaceting\ngghighlight() works well with ggplot2’s faceting system.\n\ndata %&gt;%\n  ggplot(aes(year, pcgpd_change, group = country)) +\n  geom_line() +\n  gghighlight(max(pcgpd_change), max_highlight = 4, use_direct_label = FALSE) +  \n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)),\n                     breaks = c(seq(1950, 2010, 10)),\n                     limits = c(1950, 2010)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar,\n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Change in per-capita GDP (US dollars)\") +\n  facet_wrap(~ country) +\n  theme(panel.spacing = unit(20L, \"pt\"))"
  },
  {
    "objectID": "graphics-guide.html#text-and-annotation",
    "href": "graphics-guide.html#text-and-annotation",
    "title": "Urban Institute R Graphics Guide",
    "section": "Text and Annotation",
    "text": "Text and Annotation\n\nSeveral functions can be used to annotate, label, and highlight different parts of plots. geom_text() and geom_text_repel() both display variables from data frames. annotate(), which has several different uses, displays variables and values included in the function call.\n\ngeom_text()\ngeom_text() turns text variables in data sets into geometric objects. This is useful for labeling data in plots. Both functions need x values and y values to determine placement on the coordinate plane, and a text vector of labels.\nThis can be used to label geom_bar().\n\ndiamonds %&gt;%\n  group_by(cut) %&gt;%\n  summarize(price = mean(price)) %&gt;%\n  ggplot(aes(cut, price)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = scales::dollar(price)), vjust = -1) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.2)),\n                                     labels = scales::dollar) +\n  labs(title = \"Average Diamond Price by Diamond Cut\",\n       x = \"Cut\",\n       y = \"Price\") +\n  remove_ticks()\n\n\n\n\nIt can also be used to label points in a scatter plot.\nIt’s rarely useful to label every point in a scatter plot. Use filter() to create a second data set that is subsetted and pass it into the labelling function.\n\nlabels &lt;- mtcars %&gt;%\n    rownames_to_column(\"model\") %&gt;%\n    filter(model %in% c(\"Toyota Corolla\", \"Merc 240D\", \"Datsun 710\"))\n\nmtcars %&gt;%\n    ggplot() +\n    geom_point(mapping = aes(x = wt, y = mpg)) +\n    geom_text(data = labels, mapping = aes(x = wt, y = mpg, label = model), nudge_x = 0.38) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(0, 6)) + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(0, 40)) +  \n  labs(x = \"Weight (Tons)\",\n       y = \"Miles per gallon (MPG)\") +\n  scatter_grid()\n\n\n\n\nText too often overlaps with other text or geoms when using geom_text(). library(ggrepel) is a library(ggplot2) add-on that automatically positions text so it doesn’t overlap with geoms or other text. To add this functionality, install and load library(ggrepel) and then use geom_text_repel() with the same syntax as geom_text().\n\n\ngeom_text_repel()\n\nlibrary(ggrepel)\n\nlabels &lt;- mtcars %&gt;%\n    rownames_to_column(\"model\") %&gt;%\n    top_n(5, mpg)\n\nmtcars %&gt;%\n    ggplot(mapping = aes(x = wt, y = mpg)) +\n    geom_point() +\n    geom_text_repel(data = labels, \n                    mapping = aes(label = model), \n                    nudge_x = 0.38) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(0, 6)) + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(0, 40)) +  \n  labs(x = \"Weight (Tons)\",\n       y = \"Miles per gallon (MPG)\") +\n  scatter_grid()\n\n\n\n\n\n\nannotate()\nannotate() doesn’t use data frames. Instead, it takes values for x = and y =. It can add text, rectangles, segments, and pointrange.\n\nmsleep %&gt;%\n  filter(bodywt &lt;= 1000) %&gt;%\n  ggplot(aes(bodywt, sleep_total)) +\n  geom_point() +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(-10, 1000),\n                                     labels = scales::comma) + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(0, 25)) +  \n  annotate(\"text\", x = 500, y = 12, label = \"These data suggest that heavy \\n animals sleep less than light animals\") +\n  labs(x = \"Body weight (pounds)\",\n       y = \"Sleep time (hours)\") +\n  scatter_grid()  \n\n\n\n\n\nlibrary(AmesHousing)\n\names &lt;- make_ames()\n\names %&gt;%\n  mutate(square_footage = Total_Bsmt_SF - Bsmt_Unf_SF + First_Flr_SF + Second_Flr_SF) %&gt;%\n  mutate(Sale_Price = Sale_Price / 1000) %&gt;%  \n  ggplot(aes(square_footage, Sale_Price)) +\n  geom_point(alpha = 0.2) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(-10, 12000),\n                                     labels = scales::comma) + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)),\n                                     limits = c(0, 800),\n                                     labels = scales::dollar) +  \n  annotate(\"rect\", xmin = 6800, xmax = 11500, ymin = 145, ymax = 210, alpha = 0.1) +\n  annotate(\"text\", x = 8750, y = 230, label = \"Unfinished homes\") +\n  labs(x = \"Square footage\", \n       y = \"Sale price (thousands)\") +\n  scatter_grid()"
  },
  {
    "objectID": "graphics-guide.html#layered-geoms",
    "href": "graphics-guide.html#layered-geoms",
    "title": "Urban Institute R Graphics Guide",
    "section": "Layered Geoms",
    "text": "Layered Geoms\n\nGeoms can be layered in ggplot2. This is useful for design and analysis.\nIt is often useful to add points to line plots with a small number of values across the x-axis. This example from R for Data Science shows how changing the line to grey can be appealing.\n\nDesign\n\nBefore\n\ntable1 %&gt;%\n    ggplot(aes(x = year, y = cases)) +\n        geom_line(aes(color = country)) +\n        geom_point(aes(color = country)) +\n        scale_y_continuous(expand = expansion(mult = c(0, 0.2)), \n                           labels = scales::comma) +\n        scale_x_continuous(breaks = c(1999, 2000)) +\n        labs(title = \"Changes in Tuberculosis Cases in Three Countries\")\n\n\n\n\n\n\nAfter\n\ntable1 %&gt;%\n    ggplot(aes(year, cases)) +\n        geom_line(aes(group = country), color = \"grey50\") +\n        geom_point(aes(color = country)) +\n        scale_y_continuous(expand = expansion(mult = c(0, 0.2)), \n                           labels = scales::comma) +\n        scale_x_continuous(breaks = c(1999, 2000)) +\n        labs(title = \"Changes in Tuberculosis Cases in Three Countries\")\n\n\n\n\n\n\n\nCentroids\n\nmpg_summary &lt;- mpg %&gt;%\n    group_by(cyl) %&gt;%\n    summarize(displ = mean(displ), cty = mean(cty))\n\nmpg %&gt;%\n    ggplot() +\n    geom_point(aes(x = displ, y = cty, color = factor(cyl)), alpha = 0.5) +\n    geom_point(data = mpg_summary, aes(x = displ, y = cty), size = 5, color = \"#ec008b\") +\n    geom_text(data = mpg_summary, aes(x = displ, y = cty, label = cyl)) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.002)), \n                     limits = c(0, 8)) +  \n  scale_y_continuous(expand = expansion(mult = c(0, 0)), \n                     limits = c(0, 40)) +\n    labs(x = \"Displacement\",\n         y = \"City MPG\") +\n  scatter_grid()"
  },
  {
    "objectID": "graphics-guide.html#saving-plots",
    "href": "graphics-guide.html#saving-plots",
    "title": "Urban Institute R Graphics Guide",
    "section": "Saving Plots",
    "text": "Saving Plots\n\nggsave() exports ggplot2 plots. The function can be used in two ways. If plot = isn’t specified in the function call, then ggsave() automatically saves the plot that was last displayed in the Viewer window. Second, if plot = is specified, then ggsave() saves the specified plot. ggsave() guesses the type of graphics device to use in export (.png, .pdf, .svg, etc.) from the file extension in the filename.\nmtcars %&gt;%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\nggsave(filename = \"cars.png\")\n\nplot2 &lt;- mtcars %&gt;%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\nggsave(filename = \"cars.png\", plot = plot2)\nExported plots rarely look identical to the plots that show up in the Viewer window in RStudio because the overall size and aspect ratio of the Viewer is often different than the defaults for ggsave(). Specific sizes, aspect ratios, and resolutions can be controlled with arguments in ggsave(). RStudio has a useful cheatsheet called “How Big is Your Graph?” that should help with choosing the best size, aspect ratio, and resolution.\nFonts are not embedded in PDFs by default. To embed fonts in PDFs, include device = cairo_pdf in ggsave().\nplot &lt;- mtcars %&gt;%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\nggsave(filename = \"cars.pdf\", plot = plot2, width = 6.5, height = 4, device = cairo_pdf)"
  },
  {
    "objectID": "graphics-guide.html#interactive-plots",
    "href": "graphics-guide.html#interactive-plots",
    "title": "Urban Institute R Graphics Guide",
    "section": "Interactive Plots",
    "text": "Interactive Plots\nWe can make any of the previous plots interactive with the powerful and easy plotly library. All we have to do is wrap a ggplot object in the ggplotly function. Note: You can’t add ggplotly to the end of a ggplot object, but have to actually save the ggplot as a variable and then wrap that in the function call as shown below.\nYou can customize the tooltip text by adding a value to text in aes() and then specifying tooltip = \"text\" in the ggplotly call.\n\nlibrary(plotly)\n\nstock_plot &lt;- as_tibble(EuStockMarkets) %&gt;% \n    mutate(date = time(EuStockMarkets)) %&gt;% \n    gather(key = \"key\", value = \"value\", -date) %&gt;% \n    ggplot(mapping = aes(x = date, y = value, color = key,\n                                             # sometimes ggplotly messes with line charts,\n                                             # adding a group value usually helps with that\n                                             group = key,\n                                             # customize the tooltip with the text aes\n                                             text = paste0(\"Value: \", round(value, 2), \"&lt;br&gt;\",\n                                                                        \"Date: \", round(date, 3), \"&lt;br&gt;\",\n                                                                        \"Key: \", key))\n                                             ) +\n    geom_line() +\n  scale_x_continuous(expand = expansion(mult = c(0.002, 0)), \n                     limits = c(1991, 1999), \n                     breaks = c(1991, 1993, 1995, 1997, 1999)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.002)), \n                     breaks = 0:4 * 2500,\n                     labels = scales::dollar, \n                     limits = c(0, 10000)) +  \n    labs(x = \"Date\",\n             y = \"Value\")\n\n# make interactive with gggplotly\n# Uncomment pipe to hide the interative toolbar in the top right \nggplotly(stock_plot, tooltip = \"text\")  # %&gt;%  config(displayModeBar = FALSE)"
  },
  {
    "objectID": "graphics-guide.html#urbnthemes",
    "href": "graphics-guide.html#urbnthemes",
    "title": "Urban Institute R Graphics Guide",
    "section": "urbnthemes",
    "text": "urbnthemes\n\nOverview\nurbnthemes is a set of tools for creating Urban Institute-themed plots and maps in R. The package extends ggplot2 with print and map themes as well as tools that make plotting easier at the Urban Institute. urbnthemes replaces the urban_R_theme.\nAlways load library(urbnthemes) after library(ggplot2) or library(tidyverse).\n\n\nUsage\nUse set_urbn_defaults(style = \"print\") to set the default styles. scatter_grid(), remove_ticks(), add_axis(), and remove_axis() can all be used to improve graphics.\n\nlibrary(ggplot2)\nlibrary(urbnthemes)\n\nset_urbn_defaults(style = \"print\")\n\nggplot(data = mtcars, mapping = aes(factor(cyl))) +\n  geom_bar() + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Number of Cylinders\",\n       y = \"Count\") +\n  remove_ticks()\n\n\n\n\n\n\nCombining elements\nlibrary(urbnthemes) contains functions for combining plot elements into graphics. urbn_plot() brings all of the elements together.\n\nurbn_logo_text()\nremove_ticks()\nremove_axis()\nscatter_grid()\nadd_axis()\nurbn_geofacet\n\n\nlibrary(ggplot2)\nlibrary(urbnthemes)\n\nset_urbn_defaults(style = \"print\")\n\nplot &lt;- ggplot(data = mtcars, mapping = aes(factor(cyl))) +\n  geom_bar() + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(x = \"Number of Cylinders\",\n       y = \"Count\") +\n  remove_ticks()\n\nurbn_plot(plot, urbn_logo_text(), ncol = 1, heights = c(30, 1))\n\n\n\n\nSometimes it’s important to horizontally add the y-axis title above the plot. urbn_y_title() can be sued for this task. The following example goes one step further and adds the title between the legend and the plot.\n\nlibrary(ggplot2)\nlibrary(urbnthemes)\n\nset_urbn_defaults()\n\nplot &lt;- ggplot(data = mtcars, mapping = aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() + \n    scale_x_continuous(expand = c(0, 0),\n                                         limits = c(0, 8)) +\n  scale_y_continuous(expand = c(0, 0),\n                                     limits = c(0, 40)) +\n  remove_ticks() +\n    labs(\"\") +\n    scatter_grid()\n\nurbn_plot(get_legend(plot),\n                    urbn_y_title(\"Miles per gallon\"),\n                    remove_legend(plot), \n                    urbn_logo_text(), \n                    ncol = 1, \n                    heights = c(3, 1, 30, 1))\n\n\n\n\n\n\nPalettes\nurbnthemes contains many quick-access color palettes from the Urban Institute Data Visualization Style Guide. These palettes can be used to quickly overwrite default color palettes from urbnthemes.\n\npalette_urbn_main is the eight color discrete palette of the Urban Institute with cyan, yellow, black, gray, magenta, green, space gray, and red.\npalette_urbn_diverging is an eight color diverging palette.\npalette_urbn_quintile is a five color blue palette that is good for quintiles.\npalette_urbn_politics is a two color palette with blue for Democrats and red for Republicans.\n\nThere are seven palettes that are continuous palettes of the seven unique colors in the discrete Urban Institute color palette:\n\npalette_urbn_cyan\npalette_urbn_gray\npalette_urbn_yellow\npalette_urbn_magenta\npalette_urbn_green\npalette_urbn_spacegray\npalette_urbn_red\n\nUse view_palette() to see the palette:\n\nview_palette(palette_urbn_magenta)\n\n[1] \"c(#351123, #761548, #af1f6b, #e90989, #e54096, #e46aa7, #eb99c2, #f5cbdf)\"\n\n\n\n\n\nThe vectors can be subset using base R syntax. This allows for the quick selection of specific colors from a palette.\n\npalette_urbn_main[1:4]\n\n     cyan    yellow     black      gray \n\"#1696d2\" \"#fdbf11\" \"#000000\" \"#d2d2d2\" \n\n\n\npalette_urbn_spacegray[1:5]\n\n[1] \"#d5d5d4\" \"#adabac\" \"#848081\" \"#5c5859\" \"#332d2f\"\n\n\n\n\nUtility functions\nlibrary(urbnthemes) contains four functions that are helpful with managing font instalations:\n\nlato_test()\nlato_install()\nfontawesome_test()\nfontawesome_install()"
  },
  {
    "objectID": "graphics-guide.html#bibliography-and-session-information",
    "href": "graphics-guide.html#bibliography-and-session-information",
    "title": "Urban Institute R Graphics Guide",
    "section": "Bibliography and Session Information",
    "text": "Bibliography and Session Information\n\nNote: Examples present in this document by Aaron Williams were created during personal time.\nBob Rudis and Dave Gandy (2017). waffle: Create Waffle Chart Visualizations in R. R package version 0.7.0. https://CRAN.R-project.org/package=waffle\nChester Ismay and Jennifer Chunn (2017). fivethirtyeight: Data and Code Behind the Stories and Interactives at ‘FiveThirtyEight’. R package version 0.3.0. https://CRAN.R-project.org/package=fivethirtyeight\nHadley Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009.\nHadley Wickham (2017). tidyverse: Easily Install and Load the ‘Tidyverse’. R package version 1.2.1. https://CRAN.R-project.org/package=tidyverse\nHadley Wickham (2017). forcats: Tools for Working with Categorical Variables (Factors). R package version 0.2.0. https://CRAN.R-project.org/package=forcats\nJennifer Bryan (2017). gapminder: Data from Gapminder. R package version 0.3.0. https://CRAN.R-project.org/package=gapminder\nKamil Slowikowski (2017). ggrepel: Repulsive Text and Label Geoms for ‘ggplot2’. R package version 0.7.0. https://CRAN.R-project.org/package=ggrepel\nMax Kuhn (2017). AmesHousing: The Ames Iowa Housing Data. R package version 0.0.3. https://CRAN.R-project.org/package=AmesHousing\nPeter Kampstra (2008). Beanplot: A Boxplot Alternative for Visual Comparison of Distributions, Journal of Statistical Software, 2008. https://www.jstatsoft.org/article/view/v028c01\nR Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.\nWinston Chang, (2014). extrafont: Tools for using fonts. R package version 0.17. https://CRAN.R-project.org/package=extrafont\nYihui Xie (2018). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.19.\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Monterey 12.5.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] plotly_4.10.4         AmesHousing_0.0.4     gghighlight_0.4.0    \n [4] fivethirtyeight_0.6.2 ggsankey_0.0.99999    ggridges_0.5.4       \n [7] ggbeeswarm_0.7.1      ggrepel_0.9.2         gapminder_0.3.0      \n[10] urbnthemes_0.0.2      forcats_1.0.0         stringr_1.5.1        \n[13] dplyr_1.1.4           purrr_1.0.2           readr_2.1.3          \n[16] tidyr_1.3.1           tibble_3.2.1          ggplot2_3.5.0        \n[19] tidyverse_1.3.2       knitr_1.40           \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-160        fs_1.5.2            lubridate_1.9.0    \n [4] bit64_4.0.5         httr_1.4.4          tools_4.2.2        \n [7] backports_1.4.1     utf8_1.2.4          R6_2.5.1           \n[10] vipor_0.4.5         lazyeval_0.2.2      DBI_1.1.3          \n[13] mgcv_1.8-41         colorspace_2.1-0    withr_3.0.0        \n[16] tidyselect_1.2.1    gridExtra_2.3       bit_4.0.5          \n[19] curl_4.3.3          compiler_4.2.2      extrafontdb_1.0    \n[22] cli_3.6.2           rvest_1.0.3         xml2_1.3.3         \n[25] labeling_0.4.3      scales_1.3.0        hexbin_1.28.2      \n[28] digest_0.6.30       rmarkdown_2.18      pkgconfig_2.0.3    \n[31] htmltools_0.5.4     extrafont_0.18      dbplyr_2.2.1       \n[34] fastmap_1.1.0       htmlwidgets_1.6.1   rlang_1.1.3        \n[37] readxl_1.4.1        rstudioapi_0.14     farver_2.1.1       \n[40] generics_0.1.3      jsonlite_1.8.3      crosstalk_1.2.0    \n[43] vroom_1.6.0         googlesheets4_1.0.1 magrittr_2.0.3     \n[46] Matrix_1.5-1        Rcpp_1.0.9          munsell_0.5.1      \n[49] fansi_1.0.6         lifecycle_1.0.4     stringi_1.8.3      \n[52] yaml_2.3.6          grid_4.2.2          parallel_4.2.2     \n[55] crayon_1.5.2        lattice_0.20-45     splines_4.2.2      \n[58] haven_2.5.1         hms_1.1.2           pillar_1.9.0       \n[61] urbnmapr_0.0.0.9002 reprex_2.0.2        glue_1.7.0         \n[64] evaluate_0.18       data.table_1.14.4   remotes_2.4.2      \n[67] renv_0.16.0         modelr_0.1.10       vctrs_0.6.5        \n[70] tzdb_0.3.0          Rttf2pt1_1.3.11     cellranger_1.1.0   \n[73] gtable_0.3.4        assertthat_0.2.1    xfun_0.34          \n[76] broom_1.0.1         viridisLite_0.4.2   googledrive_2.0.0  \n[79] gargle_1.2.1        beeswarm_0.4.0      timechange_0.1.1   \n[82] ellipsis_0.3.2"
  },
  {
    "objectID": "graphics-guide.html#footnotes",
    "href": "graphics-guide.html#footnotes",
    "title": "Urban Institute R Graphics Guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWickham, H., & Stryjewski, L. (2011). 40 years of boxplots.↩︎"
  },
  {
    "objectID": "mapping.html#geospatial-workflow",
    "href": "mapping.html#geospatial-workflow",
    "title": "Introduction",
    "section": "Geospatial Workflow",
    "text": "Geospatial Workflow\nThis picture below outlines what we think are the main steps in a geospatial workflow. This guide will be split into sections describing each of the steps."
  },
  {
    "objectID": "mapping.html#should-this-be-a-map",
    "href": "mapping.html#should-this-be-a-map",
    "title": "Introduction",
    "section": "Should this be a map?",
    "text": "Should this be a map?\nThe Urban Institute Data Visualization Style Guide offers some blunt but useful suggestions for maps:\n\nJust because you’ve got geographic data, doesn’t mean that you have to make a map. Many times, there are more efficient storyforms that will get your point across more clearly. If your data shows a very clear geographic trend or if the absolute location of a place or event matters, maps might be the best approach, but sometimes the reflexive impulse to map the data can make you forget that showing the data in another form might answer other—and sometimes more important—questions.\n\nSo we would encourage you to think critically before making a map."
  },
  {
    "objectID": "mapping.html#why-map-with-r",
    "href": "mapping.html#why-map-with-r",
    "title": "Introduction",
    "section": "Why map with R?",
    "text": "Why map with R?\nR can have a steeper learning curve than point-and-click tools - like QGIS or ArcGIS - for geospatial analysis and mapping. But creating maps in R has many advantages including:\n\nReproducibility: By creating maps with R code, you can easily share the outputs and the code that generated the output with collaborators, allowing them to replicate your work and catch errors easily.\nIteration: With point and click software like ArcGIS, making 50 maps would be 50 times the work/time. But using R, we can easily make make many iterations of the same map with a few changes to the code.\nEasy Updates: Writing code provides a roadmap for others (and future you!) to quickly update parts of the map as needed. Say for example a collaborator wanted to change the legend colors of 50 state maps. With R, this is possible in just a few seconds!\nAn Expansive ecosystem: There are several R packages that make it very easy to get spatial data, create static and interactive maps, and perform spatial analyses. This feature rich package ecosystem which all play nice together is frankly unmatched by other programming languages and even point and click tools like QGIS and ArcGIS. Some of these R packages include:\n\nsf: For managing and analyzing spatial dataframes\ntigris: For downloading in Census geographies\nggplot2: For making publication ready static maps\nurbnmapr: For automatically adding Urban styling to static maps\nmapview: For making expxploratory interactive maps\n\nCost: Most point-and-click tools for geospatial analysis are proprietary and expensive. R is free open-source software. The software and most of its packages can be used for free by anyone for almost any use case."
  },
  {
    "objectID": "mapping.html#helpful-learning-resources",
    "href": "mapping.html#helpful-learning-resources",
    "title": "Introduction",
    "section": "Helpful Learning Resources",
    "text": "Helpful Learning Resources\nIn addition to this guide, you may want to look at these other helpful resources:\n\nThe Urban Institute mapping training series (with video lectures and notes)\nChapters 5, 6, and 7 from Kyle Walker’s Analyzing US Census Data book.\nAndrew Heiss’ fantastic mapping guide\nAll of the vignettes for the sf package\nGeocomputation with R: A book by Robin Lovelace and others\nUChicago’s R Spatial Workshops: https://spatialanalysis.github.io/tutorials/"
  },
  {
    "objectID": "mapping.html#librarysf",
    "href": "mapping.html#librarysf",
    "title": "Introduction",
    "section": "library(sf)",
    "text": "library(sf)\n\nThe short version\nlibrary(sf) stores geospatial data, which are points (a single longitude/latitude), lines (a pair of connected points), or polygons (a collection of points which make a polygon) in a geometry column within R dataframes\n\nThis is what sf dataframe looks like in the console:\n\ndc_parks &lt;- st_read(\"mapping/data/dc_parks.geojson\", \n                                        quiet = TRUE)\n\n# Print just the NAME and geometry column\ndc_parks %&gt;%\n  select(NAME) %&gt;%\n  head(2)\n\nSimple feature collection with 2 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -77.01063 ymin: 38.81718 xmax: -76.9625 ymax: 38.89723\nGeodetic CRS:  WGS 84\n                          NAME                       geometry\n1 Kingman and Heritage Islands MULTIPOLYGON (((-76.96566 3...\n2              Bald Eagle Hill MULTIPOLYGON (((-77.01063 3...\n\n\n\n\nThe long version\nThe sf library is a key tool for reading in, managing, and working with spatial data in R. sf stands for simple features (not San Francisco you Bay Area folks) and denotes a way to describe the spatial attributes of real life objects. The R object you will be working with most frequently for mapping is an sf dataframe. An sf dataframe is essentially a regular R dataframe, with a couple of extra features for use in mapping. These extra features exclusive to sf dataframes include:\n\nsticky geometry columns\nattached coordinate reference systems\nsome other spatial metadata\n\nThe most important of the above list is the sticky geometry column, which is a magical column that contains all of the geographic information for each row of data. Say for example you had a sf dataframe of all DC census tracts. Then the geometry column would contain all of the geographic points used to define DC census tract polygons. The stickiness of this column means that no matter what data munging/filtering you do, you will not be able to drop or delete the geometry column. Below is a graphic to help you understand this:\n\ncredits: @allisonhorst\nThis is what an sf dataframe looks like in the console:\n\n# Read in spatial data about DC parks from DC Open Data Portal\ndc_parks  &lt;- st_read(\"https://opendata.arcgis.com/api/v3/datasets/287eaa2ecbff4d699762bbc6795ffdca_9/downloads/data?format=geojson&spatialRefId=4326\",\n                                        quiet = TRUE)\n\n# dc_parks &lt;- st_read(\"mapping/data/dc_parks.geojson\")\n\n# Select just a few columns for readability\ndc_parks &lt;- dc_parks %&gt;%\n  select(NAME, geometry)\n\n# Print to the console\ndc_parks\n\nSimple feature collection with 256 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -77.11113 ymin: 38.81718 xmax: -76.91108 ymax: 38.98811\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                          NAME                       geometry\n1              Plymouth Circle MULTIPOLYGON (((-77.04677 3...\n2       Triangle Park RES 0566 MULTIPOLYGON (((-77.04481 3...\n3               Shepherd Field MULTIPOLYGON (((-77.03528 3...\n4  Marvin Caplan Memorial Park MULTIPOLYGON (((-77.03027 3...\n5             Pinehurst Circle MULTIPOLYGON (((-77.06643 3...\n6   Triangle Park 3278    0801 MULTIPOLYGON (((-77.01759 3...\n7                 Fort Stevens MULTIPOLYGON (((-77.02988 3...\n8     Takoma Recreation Center MULTIPOLYGON (((-77.01794 3...\n9      Takoma Community Center MULTIPOLYGON (((-77.01716 3...\n10      Triangle Park RES 0648 MULTIPOLYGON (((-77.03362 3...\n\n\nNote that there is some spatial metadata such as the Geometry Type, Bounding Box, and CRS which shows up as a header before the actual contents of the dataframe.\nSince sf dataframes operate similarly to regular dataframes, we can use all our familiar tidyverse functions for data wrangling, including select, filter, rename, mutate, group_by and summarize. The sf package also has many functions that provide easy ways to replicate common tasks done in other GIS software like spatial joins, clipping, and buffering. Almost all of the mapping and geospatial analysis methods described in this guide rely on you having an sf dataframe. So let’s talk about how to get one!"
  },
  {
    "objectID": "mapping.html#importing-spatial-data",
    "href": "mapping.html#importing-spatial-data",
    "title": "Introduction",
    "section": "Importing spatial data",
    "text": "Importing spatial data\nGetting an sf dataframe is always the first step in the geospatial workflow. Here’s how to import spatial data for…\n\nStates and counties\nWe highly recommend using the library(urbnmapr) package, which was created by folks here at Urban to easily create state and county level maps. The get_urbn_map() function in the package allows you to read in spatial data on states and counties, with options to include territories. Importantly, it will also display AL and HI as insets on the map in accordance with the Urban Institute Data Visualization Style Guide. For information on how to install urbnmapr, see the GitHub repository.\nBelow is an example of how you would use urbnmapr to get an sf dataframe of all the states or counties in the US.\n\nlibrary(urbnmapr)\n\n# Get state data\nstates &lt;- get_urbn_map(\"states\", sf = TRUE)\n\n# Can also get county data\ncounties &lt;- get_urbn_map(\"counties\", sf = TRUE)\n\n\n\nOther Census geographies\nUse the library(tigris) package, which allows you to easily download TIGER and other cartographic boundaries from the US Census Bureau. In order to automatically load in the boundaries as sf objects, run once per R session.\nlibrary(tigris) has all the standard census geographies, including census tracts, counties, CBSAs, ZCTAs, congressional districts, tribal areas, and more. It also includes other elements such as water, roads, and military bases.\nBy default, libraray(tigris) will download large very large and detailed TIGER line boundary files. For thematic mapping, the smaller cartographic boundary files are a better choice, as they are clipped to the shoreline, generalized, and therefore usually smaller in size without losing too much accuracy. To load cartographic boundaries, use the cb = TRUE argument. If you are doing detailed geospatial analysis and need the most detailed shapefiles, then you should use the detailed TIGER line boundary files and set cb = FALSE.\nBelow is an example of how you would use library(tigris) to get a sf dataframe of all Census tracts in DC for 2019.\n\nlibrary(tigris)\n\n# Only need to set once per script\noptions(tigris_class = \"sf\")\n\ndc_tracts &lt;- tracts(\n  state = \"DC\",\n  cb = TRUE,\n  year = 2019\n)\n\nUnlike library(urbnmapr), different functions are used to get geographic data for different geographic levels. For instance, the blocks() function will load census block group data, and the tracts() function will load tract data. Other functions include block_groups(), zctas() , and core_based_statistical_areas(). For the full list of supported geographies and functions, see the package vignette.\nFor folks interested in pulling in Census demographic information along with Census geographies, we recommend checking out the sister package to library(tigris): library(tidycensus). That package allows you to download in Census variables and Census geographic data simultaneously.\n\n\nCountries\nWe recommend using the library(rnaturalearth) package, which is similar to library(tigris) but allows you to download and use boundaries beyond the US. Instead of setting class to sf one time per session as we did with library(tigris), you must set the returnclass = \"sf\" argument each time you use a function from the package. Below is an example of downloading in an sf dataframe of all the countries in the world.\n\nlibrary(rnaturalearth)\n\nworld &lt;- ne_countries(returnclass = \"sf\")\n\nggplot() +\n  geom_sf(data = world, mapping = aes())\n\n\n\nYour own files\n\nShapefiles/GeoJSONS\nShapefiles and GeoJSONs are 2 common spatial file formats you will found out in the wild. library(sf) has a function called st_read which allows you to easily read in these files as sf dataframes. The only required argument is dsn or data source name. This is the filepath of the .shp file or the .geojson file on your local computer. For geojsons, dsn can also be a URL.\nBelow is an example of reading in a shapefile of fire stations in DC which is stored in mapping/data/shapefiles/. Note that shapefiles are actually stored as 6+ different files inside a folder. You need to provide the filepath to the file ending in .shp.\n\nlibrary(sf)\n\n# Print out all files in the directory\nlist.files(\"mapping/data/shapefiles\")\n\n[1] \"Fire_Stations.cpg\" \"Fire_Stations.dbf\" \"Fire_Stations.prj\"\n[4] \"Fire_Stations.shp\" \"Fire_Stations.shx\" \"Fire_Stations.xml\"\n\n# Read in .shp file\ndc_firestations &lt;- st_read(\n  dsn = \"mapping/data/shapefiles/Fire_Stations.shp\",\n  quiet = TRUE\n)\n\nAnd now dc_firestations is an sf dataframe you can use for all your mapping needs! st_read supports reading in a wide variety of other spatial file formats, including geodatabases, KML files, and over 200 others. For an incomplete list, please see the this sf vignette.\n\n\nCSVs or dataframes with lat/lons\nIf you have a CSV with geographic information stored in columns, you will need to read in the CSV as a regular R dataframe and then convert to an sf dataframe. library(sf) contains the st_as_sf() function for converting regular R dataframes into an sf dataframe. The two arguments you must specify for this function are:\n\ncoords: A length 2 vector with the names of the columns corresponding to longitude and latitude (in that order!). For example, c(\"lon\", \"lat\").\ncrs: The CRS (coordinate references system) for your longitude/latitude coordinates. Remember you need to specify both the\nauthority and the SRID code, for example (“EPSG:4326”). For more information on finding and setting CRS codes, please see the CRS section.\n\nBelow is an example of reading in data from a CSV and converting it to an sf dataframe.\n\nlibrary(sf)\n\n# Read in dataset of state capitals which is stored as a csv\nstate_capitals &lt;- read_csv(\"mapping/data/state-capitals.csv\")\n\nstate_capitals &lt;- state_capitals %&gt;%\n  # Specify names of the lon/lat columns in the CSV to use to make geometry col\n  st_as_sf(\n    coords = c(\"longitude\", \"latitude\"),\n    crs = 4326\n  )\n\nOne common mistake is that before converting to an sf dataframe, you must drop any rows that have NA values for latitude or longitude. If your data contains NA values, then the st_as_sf() function will throw an error."
  },
  {
    "objectID": "mapping.html#appending-spatial-info-to-your-data",
    "href": "mapping.html#appending-spatial-info-to-your-data",
    "title": "Introduction",
    "section": "Appending spatial info to your data",
    "text": "Appending spatial info to your data\nOftentimes, the data you are working with will just have state or county identifiers - like FIPS codes or state abbreviations - but will not contain any geographic information. In this case, you must do the extra work of downloading in the geographic data as an sf dataframe and then joining your non-spatial data to the spatial data. Generally this involves 3 steps:\n\nReading in your own data as a data frame\nReading in the geographic data as an sf dataframe\nUsing left_join to merge the geographic data with your own non spatial data and create a new expanded sf dataframe\n\nLet’s say we had a dataframe on CHIP enrollment by state with state abbreviations.\n\n# read the state CHIP data\nchip_by_state &lt;- read_csv(\"mapping/data/chip-enrollment.csv\") %&gt;%\n  # clean column names so there are no random spaces/uppercase letters\n  janitor::clean_names()\n\n# print to the console\nchip_by_state %&gt;% head()\n\n# A tibble: 6 × 3\n  state      chip_enrollment state_abbreviation\n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;             \n1 Alabama             150040 AL                \n2 Alaska               15662 AK                \n3 Arizona              88224 AZ                \n4 Arkansas            120863 AR                \n5 California         2022213 CA                \n6 Colorado            167227 CO                \n\n\nIn order to convert this to an sf dataframe, we need to read in the spatial boundaries for each state and append it to our dataframe. Here is how we do that with get_urbn_map() and left_join() .\n\nlibrary(urbnmapr)\n\n# read in state geographic data from urbnmapr\nstates &lt;- get_urbn_map(map = \"states\", sf = TRUE)\n\n# left join state geographies to chip data\nchip_with_geographies &lt;- states %&gt;%\n  left_join(\n    chip_by_state,\n    # Specify join column, which are slightly differently named in states and chip\n    # respectively\n    by = c(\"state_abbv\" = \"state_abbreviation\")\n  )\n\nchip_with_geographies %&gt;%\n  select(state_fips, state_abbv, chip_enrollment)\n\nSimple feature collection with 51 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -2600000 ymin: -2363000 xmax: 2516374 ymax: 732352.2\nProjected CRS: NAD27 / US National Atlas Equal Area\nFirst 10 features:\n   state_fips state_abbv chip_enrollment                       geometry\n1          01         AL          150040 MULTIPOLYGON (((1150023 -15...\n2          04         AZ           88224 MULTIPOLYGON (((-1386136 -1...\n3          08         CO          167227 MULTIPOLYGON (((-786661.9 -...\n4          09         CT           25551 MULTIPOLYGON (((2156197 -83...\n5          12         FL          374884 MULTIPOLYGON (((1953691 -20...\n6          13         GA          232050 MULTIPOLYGON (((1308636 -10...\n7          16         ID           35964 MULTIPOLYGON (((-1357097 78...\n8          18         IN          114927 MULTIPOLYGON (((1042064 -71...\n9          20         KS           79319 MULTIPOLYGON (((-174904.2 -...\n10         22         LA          161565 MULTIPOLYGON (((1075669 -15..."
  },
  {
    "objectID": "mapping.html#crs",
    "href": "mapping.html#crs",
    "title": "Introduction",
    "section": "Coordinate Reference Systems",
    "text": "Coordinate Reference Systems\n\nThe short version\nJust watch this video and know the following:\n\nAll spatial data has a CRS, which specifies how to identify a location on earth.\nIt’s important that all spatial datasets you are working with be in the same CRS. You can find the CRS with st_crs() and change the CRS with st_transform().\nThe Urban Institute Style Guide requires the use of the Atlas Equal Earth Projection (\"ESRI:102003\") for national maps. For state and local maps, use this handy guide to find an appropriate State Plane projection.\n\n\n\nThe long version\nCoordinate reference systems (CRS) specify the 3d shape of the earth and optionally how we project that 3d shape onto a 2d surface. They are an important part of working with spatial data as you need to ensure that all the data you are working with are in the same CRS in order for spatial operations and maps to be accurate.\nCRS can be specified either by name (ie Maryland State Plane) or Spatial Reference System IDentifier (SRID). THe SRID is a numeric identifier that uniquely identifies a coordinate reference system. Generally when referring to an SRID, you need to refer to an authority (ie the data source) and a unique ID. An example is EPSG:26985 which refers to the Maryland State plane projection from the EPSG, or ESRI:102003 which refers to the Atlas Equal Area projection from ESRI. Most CRS codes will be from the EPSG, and some from ESRI and others. A good resource for finding/validating CRS codes is epsg.io.\nSidenote - EPSG stands for the now defunct European Petroleum Survey Group. And while oil companies have generally been terrible for the earth, the one nice thing they did for the earth was to set up common standards for coordinate reference systems.\nYou might be thinking well isn’t the earth just a sphere? Why do we need all this complicated stuff? And the answer is well the earth is kind of a sphere, but it’s really more of a misshapen ellipsoid which is pudgier at the equator than at the poles. To visualize how coordinate reference systems work, imagine that the earth is a (lumpy) orange. Now peel the skin off an orange and try to flatten it. There are many ways to do it, but all will create distortions of some kind. The CRS will give us the formula we’ve used to specify the shape of the orange (usually a sphere or ellipsoid of some kind) and optionally, specify how we flattened the orange into 2d.\nBroadly, there are two kinds of Coordinate Reference Systems:\n\nGeographic coordinate systems\n\n(sometimes called unprojected coordinate systems)\nSpecifies a 3d shape for the earth\nUses a spheroid/ellipsoid to approximate shape of the earth\nUsually use decimal degree units (ie latitude/longitude) to identify locations on earth\n\n\n\n\nProjected coordinate systems\n\nSpecifies a 3d shape for the earth + a 2d mapping\n\nIs a geographic coordinate system + a projection\n\ncredit: xkcd\nprojection: mathematical formula used to convert a 3d coordinate system to a 2d flat coordinate system\nMany different kinds of projections, including Equal Area, Equidistant, Conformal, etc\nAll projections distort the true shape of the earth in some way, either in terms of shape, area, or angle. Required xkcd comic\nUsually use linear units (ie feet, meters) and therefore useful for distance based spatial operations (ie creating buffers)"
  },
  {
    "objectID": "mapping.html#finding-the-crs",
    "href": "mapping.html#finding-the-crs",
    "title": "Introduction",
    "section": "Finding the CRS",
    "text": "Finding the CRS\nIf you are lucky, your data will have embedded CRS data that will be automatically detected when the file is read in. This is usually the case for GeoJSONS (.geojson) and shapefiles (.shp). When you use st_read() on these files, you should see the CRS displayed in the metadata:\n\nYou can also the st_crs() function to find the CRS. The CRS code is located at the end in ID[authority, SRID].\n\nst_crs(dc_firestations)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nSometimes, the CRS will be blank or NA as the dataset did not specify the CRS. In that case you MUST find and set the CRS for your data before proceeding with analysis. Below are some good rules of thumb for finding out what the CRS for your data is:\n\nFor geojsons, the CRS should always be EPSG:4326 (or WGS 84). The official geojson specification states that this is the only valid CRS for geojsons, but in the wild, this may not be true 100% of the time.\nFor shapefiles, there should be a file that ends in .proj in the same directory as the .shp file. This file contains the projection information for that file and should be used automatically when reading in shapefiles.\nFor CSV’s with latitude/longitude columns, the CRS is usually EPSG:4326 (or WGS 84).\nLook at the metadata and any accompanying documentation to see if the coordinate reference system for the data is specified\n\nIf none of the above rules of thumb apply to you, check out the crsuggest R package.\nOnce you’ve identified the appropriate CRS, you can set the CRS for your data with st_crs():\n\n# If you are certain that your data contains coordinates in the ESRI Atlas Equal Earth projections\nst_crs(some_sf_dataframe) &lt;- st_crs(\"ESRI:102003\")"
  },
  {
    "objectID": "mapping.html#transforming-the-crs",
    "href": "mapping.html#transforming-the-crs",
    "title": "Introduction",
    "section": "Transforming the CRS",
    "text": "Transforming the CRS\nOften you will need to change the CRS for your sf dataframe so that all datasets you are using have the same CRS, or to use a projected CRS for performing more accurate spatial operations. You can do this with st_transform:\n\n# Transforming CRS from WGS 84 to Urban required Equal Earth Projection\nstate_capitals &lt;- state_capitals %&gt;% st_transform(\"ESRI:102003\")\n\nst_transform() also allows you to just use the CRS of another sf dataframe when transforming.\n\n# transform CRS of chip_with_geographies to be the same as CRS of dc_firestations\nchip_with_geographies &lt;- chip_with_geographies %&gt;%\n  st_transform(crs = st_crs(state_capitals))\n\nIf you are working with local data, you should use an appropriate state plane projection instead of the Atlas Equal Earth projection which is meant for national maps. library(crsuggest) can simplify the process of picking an appropriate state plane CRS.\n\nlibrary(crsuggest)\n\nsuggest_crs(dc_firestations) %&gt;%\n  # Use the value in the \"crs_code\" column to transform CRS's\n  head(4)\n\n# A tibble: 4 × 6\n  crs_code crs_name                         crs_type crs_gcs crs_units crs_proj4\n  &lt;chr&gt;    &lt;chr&gt;                            &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n1 6488     NAD83(2011) / Maryland (ftUS)    project…    6318 us-ft     +proj=lc…\n2 6487     NAD83(2011) / Maryland           project…    6318 m         +proj=lc…\n3 3582     NAD83(NSRS2007) / Maryland (ftU… project…    4759 us-ft     +proj=lc…\n4 3559     NAD83(NSRS2007) / Maryland       project…    4759 m         +proj=lc…"
  },
  {
    "objectID": "mapping.html#the-basics",
    "href": "mapping.html#the-basics",
    "title": "Introduction",
    "section": "The basics",
    "text": "The basics\n\nlibrary(ggplot2)\nMost mapping in R fits the same theoretical framework as plotting in R using library(ggplot2). To learn more about ggplot2, visit the Data Viz page or read the official ggplot book.\nThe key function for mapping is the special geom_sf() function which works with sf dataframes. This function magically detects whether you have point or polygon spatial data and displays the results on a map.\n\n\nA simple map\nTo make a simple map, add geom_sf() to a ggplot() and set data = an_sf_dataframe. Below is code for making a map of all 50 states using library(urbnmapr):\n\nlibrary(urbnmapr)\n\nstates &lt;- get_urbn_map(\"states\", sf = TRUE)\n\nggplot() +\n  geom_sf(\n    data = states,\n    mapping = aes()\n  )"
  },
  {
    "objectID": "mapping.html#styling",
    "href": "mapping.html#styling",
    "title": "Introduction",
    "section": "Styling",
    "text": "Styling\n\nlibrary(urbnthemes)\nlibrary(urbnthemes) automatically styles maps in accordance with the Urban Institute Data Visualization Style Guide. By using library(urbnthemes), you can create publication ready maps you can immediately drop in to Urban research briefs or blog posts.\nTo install urbnthemes, visit the package’s GitHub repository and follow the instructions. There are 2 ways to use the urbnthemes functions:\n\nlibrary(urbnthemes)\n\n# You can either run this once per script to automatically style all maps with\n# the Urban theme\nset_urbn_defaults(style = \"map\")\n\n# Or you can add `+ theme_urbn_map()` to the end of every map you make\nggplot() +\n  geom_sf(states, mapping = aes()) +\n  theme_urbn_map()\n\n\n\n\n\n\nLayering\nYou can layer multiple points/lines/polygons on top of each other using the + operator from library(ggplot2). The shapes will appear from bottom to top (ie the last mapped object will show up on top). It is important that all layers are in the same CRS (coordinate reference system).\n\nstate_capitals &lt;- state_capitals %&gt;%\n  # This will change CRS to ESRI:102003 and shift the AK and HI state capitals\n  # point locations to the appropriate locations on the inset maps.\n  tigris::shift_geometry() %&gt;%\n  # For now filter out AL and HI as their state capitals will be slightly off.\n  filter(!state %in% c(\"Alaska\", \"Hawaii\"))\n\nggplot() +\n  geom_sf(\n    data = states,\n    mapping = aes()\n  ) +\n  # Note we change the data argument\n  geom_sf(\n    data = state_capitals,\n    mapping = aes(),\n    # urbnthemes library has urbn color palettes built in.\n    color = palette_urbn_main[\"yellow\"],\n    size = 2.0\n  ) +\n  theme_urbn_map()\n\n\n\n\n\n\nFill and Outline Colors\nThe same commands used to change colors, opacity, lines, size, etc. in charts can be used for maps too. To change the colors of the map , just use the fill = and color = parameters in geom_sf(). fill will change the fill color of polygons; color will change the color of polygon outlines, lines, and points.\nGenerally, maps that show the magnitude of a variable use the blue sequential ramp and maps that display positives and negatives use the diverging color ramp.library(urbnthemes) contains inbuilt. helper variables (like palette_urbn_main) for accessing color palettes from the Urban Data Viz Style guide. If for example you want states to be Urban’s magenta color:\n\nggplot() +\n  geom_sf(states,\n    mapping = aes(),\n    # Adjust polygon fill color\n    fill = palette_urbn_main[\"magenta\"],\n    # Adjust polygon outline color\n    color = \"white\"\n  ) +\n  theme_urbn_map()\n\n\n\n\n\n\nAdding text\nYou can also add text, like state abbreviations, directly to your map using geom_sf_text and the helper function get_urbn_labels().\n\nlibrary(urbnmapr)\n\nggplot() +\n  geom_sf(states,\n    mapping = aes(),\n    color = \"white\"\n  ) +\n  theme_urbn_map() +\n  # Generates dataframe of state abbv and appropriate location to plot them\n  geom_sf_text(\n    data = get_urbn_labels(\n      map = \"states\",\n      sf = TRUE\n    ),\n    aes(label = state_abbv),\n    size = 3\n  )\n\n\n\n\nThere’s also geom_sf_label() if you want labels with a border."
  },
  {
    "objectID": "mapping.html#choropleth-maps",
    "href": "mapping.html#choropleth-maps",
    "title": "Introduction",
    "section": "Choropleth Maps",
    "text": "Choropleth Maps\nChoropleth maps display geographic areas with shades, colors, or patterns in proportion to a variable or variables. Choropleth maps can represent massive geographies like the entire world and small geographies like Census Tracts. To make a choropleth map, you need to set geom_sf(aes(fill = some_variable_name)). Below are examples\n\nContinuous color scale\n\n# Map of CHIP enrollment percentage by state\nchip_with_geographies_map &lt;- chip_with_geographies %&gt;%\n  ggplot() +\n  geom_sf(aes(\n    # Color in states by the chip_pct variable\n    fill = chip_pct\n  ))\n\n\n# Below add-ons to the map are optional, but make the map look prettier.\nchip_with_geographies_map +\n  # scale_fill_gradientn adds colors with more interpolation and reverses color scale\n  scale_fill_gradientn(\n    # Convert legend from decimal to percentages\n    labels = scales::percent_format(),\n    # Make legend title more readable\n    name = \"CHIP Enrollment %\",\n    # Manually add 0 to lower limit to include it in legend. NA=use maximum value in data\n    limits = c(0, NA),\n    # Set number of breaks on legend = 3\n    n.breaks = 3\n  )\n\n\n\n\n\n\nDiscrete color scale\nThe quick and dirty way is with scale_fill_steps(), which creates discretized bins for continuous variables:\n\nchip_with_geographies %&gt;%\n  ggplot() +\n  geom_sf(aes(\n    # Color in states by the chip_pct variable\n    fill = chip_pct\n  )) +\n  scale_fill_steps(\n    # Convert legend from decimal to percentages\n    labels = scales::percent_format(),\n    # Make legend title more readable\n    name = \"CHIP Enrollment %\",\n    # Show top and bottom limits on legend\n    show.limits = TRUE,\n    # Roughly set number of bins. Won't be exact as R uses algorithms under the\n    # hood for pretty looking breaks.\n    n.breaks = 4\n  )\n\n\n\n\nOften you will want to manually generate the bins yourself to give you more fine grained control over the exact legend text. (ie 1% - 1.8%, 1.8 - 2.5%, etc). Below is an example of discretizing the continuous chip_pct variable yourself using cut_interval() and a helper function to get nice looking interval labels:\n\n# Helper function to clean up R generated intervals into nice looking interval labels\nformat_interval &lt;- function(interval_text) {\n  text &lt;- interval_text %&gt;%\n    # Remove open and close brackets which is R generated math notation\n    str_remove_all(\"\\\\(\") %&gt;%\n    str_remove_all(\"\\\\)\") %&gt;%\n    str_remove_all(\"\\\\[\") %&gt;%\n    str_remove_all(\"\\\\]\") %&gt;%\n    str_replace_all(\",\", \" — \")\n\n  # Convert decimal ranges to percent ranges\n  text &lt;- text %&gt;%\n    str_split(\" — \") %&gt;%\n    map(~ as.numeric(.x) %&gt;%\n      scales::percent() %&gt;%\n      paste0(collapse = \" — \")) %&gt;%\n    unlist() %&gt;%\n    # By default character vectors are plotted in alphabetical order. We want\n    # factors in reverse alphabetical order to get correct colors in ggplot\n    fct_rev()\n\n  return(text)\n}\n\nchip_with_geographies &lt;- chip_with_geographies %&gt;%\n  # cut_interval into n groups with equal range. Set boundary so 0 is included in the bins\n  mutate(chip_pct_interval = cut_interval(chip_pct, n = 5)) %&gt;%\n  # Generate nice looking interval labels\n  mutate(chip_pct_interval = format_interval(chip_pct_interval))\n\nAnd now we can map the discretized chip_pct_interval variable using geom_sf():\n\nchip_with_geographies %&gt;%\n  ggplot() +\n  geom_sf(aes(\n    # Color in states by the chip_pct variable\n    fill = chip_pct_interval\n  )) +\n  # Default is to use main urban palette, which assumes unrelated groups. We\n  # adjust colors manually to be on Urban cyan palette\n  scale_fill_manual(\n    values = palette_urbn_cyan[c(8, 7, 5, 3, 1)],\n    name = \"CHIP Enrollment %\"\n  )\n\n\n\n\nIn addition to cut_interval there are similar functions for creating intervals/bins with slightly different rules. When creating bins, be careful as changing the number of bins can drastically change how the map looks."
  },
  {
    "objectID": "mapping.html#bubble-maps",
    "href": "mapping.html#bubble-maps",
    "title": "Introduction",
    "section": "Bubble Maps",
    "text": "Bubble Maps\nThis is just a layered map with one polygon layer and one point layer, where the points are sized in accordance with a variable in your data.\n\nset_urbn_defaults(style = \"map\")\n\n# Get sf dataframe of DC tracts\nlibrary(tigris)\ndc_tracts &lt;- tracts(\n  state = \"DC\",\n  year = 2019,\n  progress_bar = FALSE\n)\n\n# Add bubbles for firestations\nggplot() +\n  geom_sf(data = dc_tracts, fill = palette_urbn_main[\"gray\"]) +\n  geom_sf(\n    data = dc_firestations,\n    # Size bubbles by number of trucks at each station\n    aes(size = TRUCK),\n    color = palette_urbn_main[\"yellow\"],\n    # Adjust transparency for readability\n    alpha = 0.8\n  )"
  },
  {
    "objectID": "mapping.html#dot-density-maps",
    "href": "mapping.html#dot-density-maps",
    "title": "Introduction",
    "section": "Dot-density Maps",
    "text": "Dot-density Maps\nThese maps scatter dots within a geographic area. Typically each dot represents a unit (like 100 people, or 1000 houses). To create this kind of map, you need to start with an sf dataframe that is of geometry type POLYGON or MULTIPOLYGON and then sample points within the polygon.\nThe below code generates a dot-density map representing people of different races within Washington DC tracts The code may look a little complicated, but the key workhorse function is st_sample() which samples points within each polygon to use in the dot density map:\n\nlibrary(tidycensus)\n\n# Get counts by race of DC tracts\ndc_pop &lt;- get_acs(\n  geography = \"tract\",\n  state = \"DC\",\n  year = 2019,\n  variables = c(\n    Hispanic = \"DP05_0071\",\n    White = \"DP05_0077\",\n    Black = \"DP05_0078\",\n    Asian = \"DP05_0080\"\n  ),\n  geometry = TRUE,\n  progress_bar = FALSE\n)\n\n# Get unique groups (ie races)\ngroups &lt;- unique(dc_pop$variable)\n\n# For each unique group (ie race), generate sampled points\ndc_race_dots &lt;- map_dfr(groups, ~ {\n  dc_pop %&gt;%\n    # .x = the group used in the loop\n    filter(variable == .x) %&gt;%\n    # Use the projected MD state plane for accuracy\n    st_transform(crs = \"EPSG:6487\") %&gt;%\n    # Have every dot represent 100 people\n    mutate(est100 = as.integer(estimate / 100)) %&gt;%\n    st_sample(size = .$est100, exact = TRUE) %&gt;%\n    st_sf() %&gt;%\n    # Add group (ie race) as a column so we can use it when plotting\n    mutate(group = .x)\n})\n\n\nggplot() +\n  # Plot tracts, then dots on top of tracts\n  geom_sf(\n    data = dc_pop,\n    # Make interior of tracts transparent and boundaries black\n    fill = \"transparent\",\n    color = \"black\"\n  ) +\n  geom_sf(\n    data = dc_race_dots,\n    # Color in dots by racial group\n    aes(color = group),\n    # Adjust transparency and size to be more readable\n    alpha = 0.5,\n    size = 1.1,\n    stroke = FALSE\n  )"
  },
  {
    "objectID": "mapping.html#geofacets",
    "href": "mapping.html#geofacets",
    "title": "Introduction",
    "section": "Geofacets",
    "text": "Geofacets\nGeofaceting arranges sub-geography-specific plots into a grid that resembles a larger geography (usually the US). This can be a useful alternative to choropleth maps, which tend to overemphasize low-population density areas with large areas. To make geofacetted charts, use the facet_geo() function from the geofacet library, which can be thought of as equivalent to ggplot2’s facet_wrap(). For this example, we’ll use the built-in state_ranks data.\n\nlibrary(geofacet)\n\nhead(state_ranks %&gt;% as_tibble())\n\n# A tibble: 6 × 4\n  state name   variable    rank\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;\n1 AK    Alaska education     28\n2 AK    Alaska employment    50\n3 AK    Alaska health        25\n4 AK    Alaska wealth         5\n5 AK    Alaska sleep         27\n6 AK    Alaska insured       50\n\n\n\nset_urbn_defaults(style = \"print\")\n\nstate_ranks %&gt;%\n  filter(variable %in% c(\"education\", \"employment\")) %&gt;%\n  ggplot(aes(x = rank, y = variable)) +\n  geom_col() +\n  facet_geo(\n    facets = \"state\",\n    # Use custom urban geofacet grid which is built into urbnthemes\n    # For now we need to rename a few columns as urbnthemes has to be\n    # updated\n    grid = urbnthemes::urbn_geofacet %&gt;%\n      rename(\n        code = state_code,\n        name = state_name\n      )\n  )\n\n\n\n\nInteractive geofacets of the United States have been used in Urban Features like A Matter of Time which included geofaceted line charts showing trends in incarceration by state. Static geofacets of the United States were included in Barriers to Accessing Homeownership Down Payment, Credit, and Affordability by the Housing Finance Policy Center.\n\nTile grid map\nYou can select predefined grids, or create your own at https://hafen.github.io/grid-designer/\n\n# create a grid with all of the US states and territories \nmygrid &lt;- data.frame(\n  code = c(\"ME\", \"AK\", \"WI\", \"VT\", \"NH\", \"IL\", \"ID\", \"WA\", \"MN\", \"MT\", \"ND\", \"MI\", \"NY\", \"MA\", \"IA\", \"IN\", \"CT\", \"RI\", \"NJ\", \"PA\", \"OH\", \"SD\", \"WY\", \"NV\", \"OR\", \"CA\", \"NE\", \"DE\", \"MD\", \"VA\", \"WV\", \"KY\", \"MO\", \"CO\", \"UT\", \"AZ\", \"KS\", \"AR\", \"DC\", \"SC\", \"NC\", \"TN\", \"NM\", \"LA\", \"AL\", \"GA\", \"MS\", \"OK\", \"HI\", \"FL\", \"TX\"),\n  row = c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8),\n  col = c(12, 2, 7, 11, 12, 7, 3, 2, 6, 4, 5, 8, 10, 11, 6, 7, 11, 12, 10, 9, 8, 5, 4, 3, 2, 2, 5, 11, 10, 9, 8, 7, 6, 4, 3, 3, 5, 6, 10, 9, 8, 7, 4, 6, 8, 9, 7, 5, 2, 10, 5),\n  stringsAsFactors = FALSE\n)\n\n## Combine data into geo_grid for tiling:\ngeo_grid_data &lt;- mygrid %&gt;% \n  left_join(chip_with_geographies, by=c(\"code\" = \"state_abbv\")) \n\n## plot tile grid\ngeo_grid_data %&gt;% \n  ggplot(aes(x = col, y = row, fill = chip_pct_interval)) +\n  scale_fill_manual(values = palette_urbn_cyan[c(8, 7, 5, 3, 1)], \n                                     name = \"CHIP Enrollment %\") +\n  geom_tile(color = \"white\", linewidth = 1) +\n  geom_text(aes(label = code), color=\"white\", size = 4) +\n  scale_y_reverse() +\n  coord_equal() +\n  labs(fill=NULL)"
  },
  {
    "objectID": "mapping.html#cartograms",
    "href": "mapping.html#cartograms",
    "title": "Introduction",
    "section": "Cartograms",
    "text": "Cartograms\nCartograms are a modified form of a choropleth map with intentionally distorted sizes that map to a variable in your data. Below we create a cartogram with library(cartogram) where the state sizes are proportional to the population.\n\nlibrary(cartogram)\n\nset_urbn_defaults(style = \"map\")\n\nchip_with_geographies_weighted &lt;- chip_with_geographies %&gt;%\n  # Note column name needs to be in quotes for this package\n  cartogram_cont(weight = \"population\")\n\nggplot() +\n  geom_sf(\n    data = chip_with_geographies_weighted,\n    # Color in states by chip percentages\n    aes(fill = chip_pct)\n  )"
  },
  {
    "objectID": "mapping.html#interactive-maps",
    "href": "mapping.html#interactive-maps",
    "title": "Introduction",
    "section": "Interactive Maps",
    "text": "Interactive Maps\nInteractive maps can be a great exploratory tool to explore and understand your data. And luckily there are a lot of new R packages that make it really easy to create them. Interactive maps are powerful but we do not recommend them for official use in Urban publications as getting them in Urban styles and appropriate basemaps can be tricky (reach out to anarayanan@urban.org if you really want to include them).\n\nlibrary(mapview)\nlibrary(mapview) is probably the most user friendly of the interactive mapping R libraries. All you have to do to create an interactive map is:\n\nlibrary(mapview)\n\n\nchip_with_geographies_for_interactive_mapping &lt;- chip_with_geographies %&gt;%\n  # Filter out AL and HI bc they would appear in Mexico. If you want AL, HI and\n  # in the correct place in interactive maps, make sure to use tigris::states()\n  filter(!state_abbv %in% c(\"AK\", \"HI\"))\n\nmapview(chip_with_geographies_for_interactive_mapping)\n\n\n\n\n\n\nWhen you click on an object, you get a popup table of all it’s attributes. And when you hover over an object, you get a popup with an object id.\nEach of the above behaviors can be changed if desired. As you’ll see in the below section, the syntax for library(mapview) is significantly different from library(ggplot2) so be careful!\n\nColoring in points/polygons\nIn order to create a choropleth map where we color in the points/polygons by a variable, we need to feed in a column name in quotes to thezcol argument inside the mapview() function:\n\n# Create interactive state map colored in by chip enrollment\nmapview(chip_with_geographies_for_interactive_mapping, zcol = \"chip_enrollment\")\n\n\n\n\n\n\nIf you want more granular control over the color palette for the legend can also feed in a vector of color hex codes to col.regions along with a column name to zcol. This will create a continuous color range along the provided colors. Be careful though as the color interpolation is not perfect.\n\n# library(RColorBrewer)\nmapview(chip_with_geographies_for_interactive_mapping,\n  col.regions = c(\n    palette_urbn_green[6],\n    \"white\",\n    palette_urbn_cyan[6]\n  ),\n  zcol = \"chip_enrollment\"\n)\n\n\n\n\n\n\nIf you want to color in all points/polygons as the same color, just feed in a single color hex code to the col.regions argument:\n\nmapview(chip_with_geographies_for_interactive_mapping,\n  col.regions = palette_urbn_green[5]\n)\n\n\n\n\n\n\n\n\nAdding layers\nYou can add multiple sf objects on the same map by using the + operator. This is very useful when comparing 2 or more spatial datasets.\n\nmapview(chip_with_geographies_for_interactive_mapping, col.regions = palette_urbn_green[5]) +\n  mapview(state_capitals, col.regions = palette_urbn_cyan[5])\n\n\n\n\n\n\nYou can even create slider maps by using the | operator!\n\nmapview(chip_with_geographies_for_interactive_mapping, col.regions = palette_urbn_green[5]) |\n  mapview(state_capitals, col.regions = palette_urbn_cyan[5])\n\n\n\n\n\n\n\n\n\nMore details\nTo learn more about more advanced options with mapview maps, check out the documentation page and the reference manual.\nThere are also other interactive map making packages in R like leaflet (which mapview is a more user friendly wrapper of), tmap, and mapdeck. To learn about these other packages, this book chapter is a good starting point."
  },
  {
    "objectID": "mapping.html#cropping",
    "href": "mapping.html#cropping",
    "title": "Introduction",
    "section": "Cropping",
    "text": "Cropping\nCropping (or clipping) is geographically filtering an sf dataframe to just the area we are interested in. Say we wanted to look at the roads around Fire Station 24 in DC.\n\nlibrary(tigris)\nlibrary(units)\n\ndc_firestations &lt;- dc_firestations %&gt;%\n  st_transform(\"EPSG:6487\")\n\n\n# Draw 500 meter circle around one fire station\nfire_station_24_buffered &lt;- dc_firestations %&gt;%\n  filter(NAME == \"Engine 24 Station\") %&gt;%\n  st_buffer(set_units(500, \"meter\"))\n\n# Get listing of all roads in DC\ndc_roads &lt;- roads(\n  state = \"DC\",\n  county = \"District of Columbia\",\n  class = \"sf\",\n  progress_bar = FALSE\n) %&gt;%\n  st_transform(\"EPSG:6487\")\n\n# View roads on top of fire_station\nggplot() +\n  # Order matters! We need to plot fire_stations first, and then roads on top\n  # to see overlapping firestations\n  geom_sf(\n    data = fire_station_24_buffered,\n    fill = palette_urbn_cyan[1],\n    color = palette_urbn_cyan[7]\n  ) +\n  geom_sf(\n    data = dc_roads,\n    color = palette_urbn_gray[7]\n  ) +\n  theme_urbn_map()\n\n\n\n\nWe can clip the larger roads dataframe to just roads that overlap with the circle around the fire station with st_intersection().\n\n# Use st_intersection() to crop the roads data to just roads within the\n# fire_station radius\ndc_roads_around_fire_station_24_buffered &lt;- fire_station_24_buffered %&gt;%\n  st_intersection(dc_roads)\n\nggplot() +\n  geom_sf(\n    data = fire_station_24_buffered,\n    fill = palette_urbn_cyan[1],\n    color = palette_urbn_cyan[7]\n  ) +\n  geom_sf(\n    data = dc_roads_around_fire_station_24_buffered,\n    color = palette_urbn_gray[7]\n  ) +\n  theme_urbn_map()\n\n\n\n\nMore Coming Soon!"
  },
  {
    "objectID": "mapping.html#calculating-distance",
    "href": "mapping.html#calculating-distance",
    "title": "Introduction",
    "section": "Calculating Distance",
    "text": "Calculating Distance"
  },
  {
    "objectID": "mapping.html#spatial-joins",
    "href": "mapping.html#spatial-joins",
    "title": "Introduction",
    "section": "Spatial Joins",
    "text": "Spatial Joins\n\nPoint to Polygon\n\n\nPolygon to Polygon"
  },
  {
    "objectID": "mapping.html#aggregating",
    "href": "mapping.html#aggregating",
    "title": "Introduction",
    "section": "Aggregating",
    "text": "Aggregating"
  },
  {
    "objectID": "mapping.html#drivetransit-times",
    "href": "mapping.html#drivetransit-times",
    "title": "Introduction",
    "section": "Drive/Transit times",
    "text": "Drive/Transit times"
  },
  {
    "objectID": "mapping.html#geocoding",
    "href": "mapping.html#geocoding",
    "title": "Introduction",
    "section": "Geocoding",
    "text": "Geocoding\nGeocoding is the process of turning text (usually addresses) into geographic coordinates (usually latitudes/longitudes) for use in mapping. For Urban researchers, we highly recommend using the Urban geocoder as it is fast, accurate, designed to work with sensitive/confidential data and most importantly free to use for Urban researchers! To learn about how we set up and chose the geocoder for the Urban Institute, you can read our Data@Urban blog.\n\nCleaning Addresses\nThe single most important factor in getting accurate geocoded data is having cleaned, well structured address data. This can prove difficult as address data out in the wild is often messy and unstandardized. While the rules for cleaning addresses are very data specific, below are some examples of clean addresses you should aim for in your data cleaning process:\n\n\n\n\n\n\n\n\n\nf_address\nType of address\n\n\n\n\n123 Troy Drive, Pillowtown, CO, 92432\nresidnetial address\n\n\n789 Abed Avenue, Apt 666, Blankesburg, CO, 92489\nresidential apartment address\n\n\nShirley Boulevard and Britta Drive, Blanketsburg, CO, 92489\nstreet intersection\n\n\nPillowtown, CO\ncity\n\n\n92489, CO\nZip Code\n\n\n\n\n\n\n\nAll that being said, our geocoder is pretty tolerant of different address formats, typos/spelling errors and missing states, zip codes, etc. So don’t spend too much time cleaning every address in the data. Also note that while our geocoder is able to geocode cities and zip codes, it will return the lat/lon of the center of the city/zip code, which may not be what you want.\n\n\nInstructions\nTo use the Urban geocoder, you will need to:\n\nGenerate a CSV with a column named f_address which contains the addresses in single line format (ie 123 Abed Avenue, Blanketsburg, CO, 94328). This means that if you have the addresses split across multiple columns (ie Address, City, State, Zip columns), you will need to concatenate them into one column. Also see our Address cleaning section above.\nGo to the Urban geocoder and answer the initial questions. This will tell you whether your data is non-confidential or confidential data, and allow you to upload your CSV for geocoding.\nWait for an email telling you your results are ready. If your data is non-confidential, this email will contain a link to your geocoded results. This link expires in 24 hours, so make sure to download your data before then. If you data is confidential, the email will contain a link to the location on the Y Drive where your confidential geocoded data is stored. You can specify this output folder when submitting the CSV in step 1.\n\n\n\nGeocoder outputs\n\nThe geocoded file will be your original data, plus a few more columns (including latitude and longitude). each of the new columns that have been appended to your original data. It’s very important that you take a look at the Addr_type column in the CSV before doing further analysis to check the accuracy of the geocoding process.\n\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nMatch_addr\nThe actual address that the inputted address was matched to. This is the address that the geocoder used to get Latitudes / Longitudes. If there are potentially many typos or non standard address formats in your data file, you will want to take a close look at this column to confirm that the matched address correctly handled typos and badly formatted addresses.\n\n\nLongitude\nThe WGS 84 datum Longitude (EPSG code 4326)\n\n\nLatitude\nThe WGS 84 datum Latitude (EPSG code 4326)\n\n\nAddr_type\nThe match level for a geocode request. This should be used as an indicator of the precision of geocode results. Generally, Subaddress, PointAddress, StreetAddress, and StreetInt represent accurate matches. The list below contains all possible values for this field. Green values represent High accuracy matches, yellow represents Medium accuracy matches and red represents Low accuracy/inaccurate matches. If you have many yellow and red values in your data, you should manually check the results before proceeding with analysis. All possible values:\n\nSubaddress: A subset of a PointAddress that represents a house or building subaddress location, such as an apartment unit, floor, or individual building within a complex. The UnitName, UnitType, LevelName, LevelType, BldgName, and BldgType field values help to distinguish subaddresses which may be associated with the same PointAddress. Reference data consists of point features with associated house number, street name, and subaddress elements, along with administrative divisions and optional postal code; for example, 3836 Emerald Ave, Suite C, La Verne, CA, 91750.\n\nPointAddress: A street address based on points that represent house and building locations. Typically, this is the most spatially accurate match level. Reference data contains address points with associated house numbers and street names, along with administrative divisions and optional postal code. The X / Y (Longitude/Latitude) and geometry output values for a PointAddress match represent the street entry location for the address; this is the location used for routing operations. The DisplayX and DisplayY values represent the rooftop, or actual, location of the address. Example: 380 New York St, Redlands, CA, 92373.\n\nStreetAddress — A street address that differs from PointAddress because the house number is interpolated from a range of numbers. Reference data contains street center lines with house number ranges, along with administrative divisions and optional postal code information, for example, 647 Haight St, San Francisco, CA, 94117.\n\nStreetInt: A street address consisting of a street intersection along with city and optional state and postal code information. This is derived from StreetAddress reference data, for example, Redlands Blvd & New York St, Redlands, CA, 92373.\n\nStreetName: Similar to a street address but without the house number. Reference data contains street centerlines with associated street names (no numbered address ranges), along with administrative divisions and optional postal code, for example, W Olive Ave, Redlands, CA, 92373.\n\nStreetAddressExt: An interpolated street address match that is returned when parameter matchOutOfRange=true and the input house number exceeds the house number range for the matched street segment.\n\nDistanceMarker: A street address that represents the linear distance along a street, typically in kilometers or miles, from a designated origin location. Example: Carr 682 KM 4, Barceloneta, 00617.\n\nPostalExt: A postal code with an additional extension, such as the United States Postal Service ZIP+4. Reference data is postal code points with extensions, for example, 90210-3841.\n\nPOI: —Points of interest. Reference data consists of administrative division place-names, businesses, landmarks, and geographic features, for example, Golden Gate Bridge.\n\nLocality: A place-name representing a populated place. The Type output field provides more detailed information about the type of populated place. Possible Type values for Locality matches include Block, Sector, Neighborhood, District, City, MetroArea, County, State or Province, Territory, Country, and Zone. Example: Bogotá, COL,\n\nPostalLoc: A combination of postal code and city name. Reference data is typically a union of postal boundaries and administrative (locality) boundaries, for example, 7132 Frauenkirchen.\n\nPostal: Postal code. Reference data is postal code points, for example, 90210 USA.\n\n\nScore\nA number from 1–100 indicating the degree to which the input tokens in a geocoding request match the address components in a candidate record. A score of 100 represents a perfect match, while lower scores represent decreasing match accuracy.\n\n\nStatus\nIndicates whether a batch geocode request results in a match, tie, or unmatched. Possible values include\n\nM - Match. The returned address matches the input address and is the highest scoring candidate.\n\nT - Tied. The returned address matches the input address but has the same score as one or more additional candidates.\n\nU - Unmatched. No addresses match the inputted address.\n\n\ngeometry\nThe WKT (Well-known text) representation of the latitudes and longitudes. This column may be useful if you’re reading the CSV into R, Python, or ArcGIS\n\n\nRegion\nThe state that Match_addr is located in\n\n\nRegionAbbr\nAbbreviated State Name. For example, CA for California\n\n\nSubregion\nThe county that the input address is located in\n\n\nMetroArea\nThe name of the Metropolitan area that Match_addr is located in. This field may be blank if the input address is not located within a metro area.\n\n\nCity\nThe city that Match_addr is located in\n\n\nNbrhd\nThe Neighborhood that Match_addr is located in. Note these are ESRI defined neighborhoods which may or may not align with other sources neighborhood definitions"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Free Books",
    "section": "",
    "text": "Free Books\n\nIntro\n\nR for Data Science by Garrett Grolemund and Hadley Wickham\n\n\n\nData Viz\n\nggplot2: Elegant Graphics for Data Analysis by Hadley Wickham\nData Visualization - A practical introduction by Kieran Healy\n\n\n\n*down\n\nR Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, and Garrett Grolemund\nblogdown: Creating Websites with R Markdown by Yihui Xie, Amber Thomas, and Alison Presmanes Hill\nbookdown: Authoring Books and Technical Documents with R Markdown by Yihui Xie\n\n\n\nStatistics\n\nLearning Statistics with R by Danielle Navarro\nIntroduction to Econometrics with R by Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer\nAn Introduction to Bayesian Thinking by Merlise Clyde et. al.\nStatistical Inference via Data Science by Chester Ismay and Albert Y. Kim\n\n\n\nMachine Learning\n\nHands-On Machine Learning with R by Bradley Boehmke & Brandon Greenwell\nFeature Engineering and Selection: A Practical Approach for Predictive Models by Max Kuhn and Kjell Johnson\n\n\n\nMapping and Geospatial Analysis\n\nGeocomputation with R by Robin Lovelace, Jakub Nowosad, Jannes Muenchow\n\n\n\nText Analysis\n\nText Mining with R A Tidy Approach by Julia Silge and David Robinson\n\n\n\nProgramming\n\nAdvanced R by Hadley Wickham\nR Packages by Hadley Wickham\nMaster Spark with R by Javier Luraschi, Kevin Kuo, and Edgar Ruiz\nFunctional programming and unit testing for data munging with R by Bruno Rodrigues\n\n\n\n\nWebsites\n\nRStudio Essentials\nRStudio Education\nR Cheat Sheets\nAndrew Heiss’ free Data Viz Course"
  },
  {
    "objectID": "getting-data.html#librarytidycensus",
    "href": "getting-data.html#librarytidycensus",
    "title": "Introduction",
    "section": "library(tidycensus)",
    "text": "library(tidycensus)\nlibrary(tidycensus) by Kyle Walker (complete intro here) is the best tool for accessing some Census data sets in R from the Census Bureau API. The package returns tidy data frames and can easily pull shapefiles by adding geometry = TRUE.\nYou will need to apply for a Census API key and add it to your R session. Don’t add your API key to your script and don’t add it to a GitHub repository!\nHere is a simple example for one state with shapefiles:\n\nlibrary(tidyverse)\nlibrary(purrr)\nlibrary(tidycensus)\n\n# pull median household income and shapefiles for Census tracts in Alabama\nget_acs(geography = \"tract\", \n                variables = \"B19013_001\", \n                state = \"01\",\n                year = 2015,\n                geometry = TRUE,\n                progress = FALSE)\n\nSimple feature collection with 1181 features and 5 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -88.47323 ymin: 30.22333 xmax: -84.88908 ymax: 35.00803\nGeodetic CRS:  NAD83\nFirst 10 features:\n         GEOID                                          NAME   variable\n1  01003010500     Census Tract 105, Baldwin County, Alabama B19013_001\n2  01003011501  Census Tract 115.01, Baldwin County, Alabama B19013_001\n3  01009050500      Census Tract 505, Blount County, Alabama B19013_001\n4  01015981901 Census Tract 9819.01, Calhoun County, Alabama B19013_001\n5  01025957700     Census Tract 9577, Clarke County, Alabama B19013_001\n6  01025958002  Census Tract 9580.02, Clarke County, Alabama B19013_001\n7  01031011000      Census Tract 110, Coffee County, Alabama B19013_001\n8  01033020500     Census Tract 205, Colbert County, Alabama B19013_001\n9  01037961200      Census Tract 9612, Coosa County, Alabama B19013_001\n10 01039961700  Census Tract 9617, Covington County, Alabama B19013_001\n   estimate   moe                       geometry\n1     41944  8100 MULTIPOLYGON (((-87.80249 3...\n2     41417 14204 MULTIPOLYGON (((-87.71719 3...\n3     40055  8054 MULTIPOLYGON (((-86.75735 3...\n4        NA    NA MULTIPOLYGON (((-86.01323 3...\n5     32708  4806 MULTIPOLYGON (((-88.1805 31...\n6     29048 14759 MULTIPOLYGON (((-87.98623 3...\n7     44732  7640 MULTIPOLYGON (((-85.92018 3...\n8     49052  6543 MULTIPOLYGON (((-87.76733 3...\n9     31957  9954 MULTIPOLYGON (((-86.46069 3...\n10    32697  6021 MULTIPOLYGON (((-86.6998 31...\n\n\nSmaller geographies like Census tracts can only be pulled state-by-state. This example demonstrates how to iterate across FIPS codes to pull Census tracts for multiple states. The process is as follows:\n\nPick the variables of interest\nCreate a vector of state FIPS codes for the states of interest\nCreate a custom function that works on a single state FIPS code\nIterate the function along the vector of state FIPS codes with map_df() from library(purrr)\n\nHere is an example that pulls median household income at the Census tract level for multiple states:\n\n# variables of interest\nvars &lt;- c(\n  \"B19013_001\"  # median household income estimate\n)\n\n# states of interest: alabama, alaska, arizona\nstate_fips &lt;- c(\"01\", \"02\", \"04\")\n    \n# create a custom function that works for one state\nget_income &lt;- function(state_fips) {\n    \n    income_data &lt;- get_acs(geography = \"tract\", \n                                                 variables = vars, \n                                                 state = state_fips,\n                                                 year = 2015)\n    \n    return(income_data)\n    \n}\n\n# iterate the function\nmap_df(.x = state_fips, # iterate along the vector of state fips codes\n             .f = get_income) # apply get_income() to each fips_code  \n\n# A tibble: 2,874 × 5\n   GEOID       NAME                                        varia…¹ estim…²   moe\n   &lt;chr&gt;       &lt;chr&gt;                                       &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 01001020100 Census Tract 201, Autauga County, Alabama   B19013…   61838 11900\n 2 01001020200 Census Tract 202, Autauga County, Alabama   B19013…   32303 13538\n 3 01001020300 Census Tract 203, Autauga County, Alabama   B19013…   44922  5629\n 4 01001020400 Census Tract 204, Autauga County, Alabama   B19013…   54329  7003\n 5 01001020500 Census Tract 205, Autauga County, Alabama   B19013…   51965  6935\n 6 01001020600 Census Tract 206, Autauga County, Alabama   B19013…   63092  9585\n 7 01001020700 Census Tract 207, Autauga County, Alabama   B19013…   34821  7867\n 8 01001020801 Census Tract 208.01, Autauga County, Alaba… B19013…   73728  2447\n 9 01001020802 Census Tract 208.02, Autauga County, Alaba… B19013…   60063  8602\n10 01001020900 Census Tract 209, Autauga County, Alabama   B19013…   41287  7857\n# … with 2,864 more rows, and abbreviated variable names ¹​variable, ²​estimate\n\n\nlibrary(tidycensus) works well with library(tidyverse) and enables access to geospatial data, but it is limited to only some Census Bureau data sets. The next package has less functionality but allows for accessing any data available on the Census API."
  },
  {
    "objectID": "getting-data.html#librarycensusapi",
    "href": "getting-data.html#librarycensusapi",
    "title": "Introduction",
    "section": "library(censusapi)",
    "text": "library(censusapi)\nlibrary(censusapi) by Hannah Recht (complete intro here) can access any published table that is accessible through the Census Bureau API. A full listing is available here.\nYou will need to apply for a Census API key and add it to your R session. Don’t add your API key to your script and don’t add it to a GitHub repository!\nHere is a simple example that pulls median household income and its margin of error for Census tracts in Alabama:\n\nlibrary(tidyverse)\nlibrary(purrr)\nlibrary(censusapi)\nvars &lt;- c(\n  \"B19013_001E\",  # median household income estimate\n  \"B19013_001M\"   # median household income margin of error\n)\n\ngetCensus(name = \"acs/acs5\",\n                    key = Sys.getenv(\"CENSUS_API_KEY\"),\n                    vars = vars, \n                    region = \"tract:*\",\n                    regionin = \"state:01\",\n                    vintage = 2015) %&gt;%\n    as_tibble()\n\n# A tibble: 1,181 × 5\n   state county tract  B19013_001E B19013_001M\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 01    103    005109       29644        4098\n 2 01    103    005106       35864        3443\n 3 01    103    005107       66739        5468\n 4 01    103    005108       64632        9804\n 5 01    103    005701       46306        7926\n 6 01    103    005702       47769       12939\n 7 01    105    686800       30662        7299\n 8 01    009    050102       43325        9484\n 9 01    009    050300       37548        9655\n10 01    009    050700       46452        5167\n# … with 1,171 more rows\n\n\nSmaller geographies like Census tracts can only be pulled state-by-state. This example demonstrates how to iterate across FIPS codes to pull Census tracts for multiple states. The process is as follows:\n\nPick the variables of interest\nCreate a vector of state FIPS codes for the states of interest\nCreate a custom function that works on a single state FIPS code\nIterate the function along the vector of state FIPS codes with map_df() from library(purrr)\n\nHere is an example that pulls median household income at the Census tract level for multiple states:\n\n# variables of interest\nvars &lt;- c(\n  \"B19013_001E\",  # median household income estimate\n  \"B19013_001M\"   # median household income margin of error\n)\n\n# states of interest: alabama, alaska, arizona\nstate_fips &lt;- c(\"01\", \"02\", \"04\")\n    \n# create a custom function that works for one state\nget_income &lt;- function(state_fips) {\n    \n    income_data &lt;- getCensus(name = \"acs/acs5\", \n                                                     key = Sys.getenv(\"CENSUS_API_KEY\"),\n                                                     vars = vars, \n                                                     region = \"tract:*\",\n                                                     regionin = paste0(\"state:\", state_fips),\n                                                     vintage = 2015)\n    \n    return(income_data)\n    \n}\n\n# iterate the function\nmap_df(.x = state_fips, # iterate along the vector of state fips codes\n             .f = get_income) %&gt;% # apply get_income() to each fips_code  \n    as_tibble() \n\n# A tibble: 2,874 × 5\n   state county tract  B19013_001E B19013_001M\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 01    103    005109       29644        4098\n 2 01    103    005106       35864        3443\n 3 01    103    005107       66739        5468\n 4 01    103    005108       64632        9804\n 5 01    103    005701       46306        7926\n 6 01    103    005702       47769       12939\n 7 01    105    686800       30662        7299\n 8 01    009    050102       43325        9484\n 9 01    009    050300       37548        9655\n10 01    009    050700       46452        5167\n# … with 2,864 more rows"
  }
]