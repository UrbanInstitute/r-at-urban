<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>mapping.utf8.md</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114294141-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-114294141-1');
</script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R PROGRAMMING AT THE URBAN INSTITUTE</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="intro-to-r.html">INTRO TO R</a>
</li>
<li>
  <a href="graphics-guide.html">PLOTTING</a>
</li>
<li>
  <a href="mapping.html">MAPPING</a>
</li>
<li>
  <a href="optimization.html">OPTIMIZATION</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>




</div>


<p><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" /></p>
<div id="header">
<p><img src="mapping/www/images/urban-institute-logo.png" /></p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<hr />
<p>Geospatial analysis is the ingestion, manipulation, display, and modeling of geographic and spatial data. The data can be represented explicitly as coordinates (latitude &amp; longitude) or implicitly as addresses, Census tracts, or other identifiers.</p>
<p>This guide outlines the many tools in R for geospatial analysis and mapping. New tools are always being developed, so this guide will be occasionally updated as better methods emerge.</p>
<p>R can have a steeper learning curve than point-and-click tools for geospatial analysis like ArcGIS. The extra effort is worth the reward.</p>
<ul>
<li>Geospatial analysis in R scales better than pointing-and-clicking. Clear scripts can easily scale across time, across geography, and across analyses.</li>
<li>Point-and-click tools are not reproducible. The audience, other researchers, and the analyst/mapper 6 months after the analysis is completed will have little idea what happened in a stream of undocumented right- and left-clicks. R is a scripting language that if used properly, creates a reproducible script that can be read and rerun many years later.</li>
<li>Most point-and-click tools for geospatial analysis are proprietary and expensive. R is free opensource software. The software and most of its packages can be used for free by anyone for almost anything.</li>
</ul>
<p>Please don’t hesitate to contact Sarah Strochak (<a href="mailto:sstrochak@urban.org" class="email">sstrochak@urban.org</a>) or Aaron Williams (<a href="mailto:awilliams@urban.org" class="email">awilliams@urban.org</a>) if you have any questions about this guide or need any assistance with R.</p>
<p>Additionally, Rob Pitingolo (<a href="mailto:rpitingolo@urban.org" class="email">rpitingolo@urban.org</a>) and the Urban Institute Mapping Users Group are excellent resources for mapping and geospatial analysis.</p>
</div>
<div id="mapping" class="section level1">
<h1>Mapping</h1>
<hr />
<p><img src="mapping/www/images/amsterdam.jpg" /> <em><a href="https://en.wikipedia.org/wiki/Map#/media/File:World_Map_1689.JPG">World map, 1689</a></em></p>
<div id="basic-concepts" class="section level2">
<h2>Basic Concepts</h2>
<hr />
<div id="simple-features" class="section level3">
<h3>Simple features</h3>
<p>Simple features are a way to describe the spatial attributes of real life objects. In R, this is implemented as a data frame that contains a column of geographic information. Geographic information is made up of points, and can be represented as points, lines, polygons, multipolygons, and more.</p>
<p>Simple features work well with <code>tidyverse</code> functions, including <code>ggplot2</code>. This means that we can use a lot of the same data wranling tools when we are working with spatial data.</p>
<p><code>sf</code> dataframes in R generally include both spatial and non-spatial data. In the example below, the dataframe contains state identifiers, and a column called <code>geometry</code>, which contains a nested list of coordinates. Each coordinate contains a vertex of the shape of the state; when combined and appropriately grouped, this is what allows the shape to render corectly.</p>
<p><code>library(sf)</code> is a key tool for working with spatial data in R. Functions included in the package provide easy and reproducable ways to replicate many tasks commonly done in ArcGIS and other GIS software. The dataframe structure makes it easy to combine, filter, join, and manipulate geospatial data.</p>
</div>
</div>
<div id="getting-geospatial-data" class="section level2">
<h2>Getting geospatial data</h2>
<p>So you want to make a map in R- the first thing you need to do is get spatial data. There are many strategies to convert or obtain <code>sf</code> objects that can then be mapped.</p>
<hr />
<div id="r-packages-with-geographic-data" class="section level3">
<h3>R packages with geographic data</h3>
<div id="libraryurbnmapr" class="section level4">
<h4><code>library(urbnmapr)</code></h4>
<p><code>urbnmapr</code> provides sf objects for mapping US states and counties. The <code>get_urbn_map()</code> function allows you to load both states and counties, with options for including territories. For information on how to install urbnmapr, see the <a href="https://github.com/UrbanInstitute/urbnmapr">GitHub repository</a>.</p>
<pre class="r"><code>library(urbnmapr)

states &lt;- get_urbn_map(&quot;states&quot;, sf = TRUE)</code></pre>
</div>
<div id="librarytigris" class="section level4">
<h4><code>library(tigris)</code></h4>
<p><code>library(tigris)</code> allows you to easily download TIGER and cartographic boundaries from the US Census Bureaus. In order to load in the boundaries as <code>sf</code> objects, run once per session.</p>
<p><code>tigris</code> has all standard census geographies, including census tracts, counties, CBSAs, ZCTAs, congressional districts, and more. It also includes other elements such as water, roads, and military bases.</p>
<p>By default, <code>tigris</code> will download TIGER line boundaries. TIGER line shapefiles contain detailed, full boundaries. This means that the boundaries are not clipped to the shoreline. For thematic mapping, cartographic boundaries are a better choice, as they are clipped to the shoreline and generalized. To load catrographic boundaries, include the argument.</p>
<p>You can also load boudaries for past years; <code>tigris</code> will default to the most recent year.</p>
<p>Unlike <code>urbnmapr</code>, different functions are used for different geographic levels- for instance, the <code>blocks()</code> function will load census block groups, and the <code>states()</code> function will load states. For the full list of functions, see the <a href="https://cran.r-project.org/web/packages/tigris/tigris.pdf">package vignette</a>.</p>
<pre class="r"><code>library(tigris)

options(tigris_class = &quot;sf&quot;)

md_zctas &lt;- zctas(state = &quot;MD&quot;,
                  cb = TRUE)</code></pre>
</div>
<div id="libraryrnaturalearth" class="section level4">
<h4><code>library(rnaturalearth)</code></h4>
<p><code>library(rnaturalearth)</code> is similar to tigris, but allows you to download and use boundaries beyond the US. Instead of setting class to <code>sf</code> one time per session, the <code>returnclass = SF</code> argument can be used each time you use a function from the package.</p>
<pre class="r"><code>library(rnaturalearth)

world &lt;- ne_countries(returnclass = &quot;sf&quot;)

ggplot() +
  geom_sf(data = world, mapping = aes())</code></pre>
<p><img src="mapping/www/images/natural-earth-1.png" width="672" /></p>
</div>
</div>
<div id="converting-data-to-sf" class="section level3">
<h3>Converting data to <code>sf</code></h3>
<p><code>library(sf)</code> contains functions for converting existing data that has columns for latitude and longitude into an <code>sf</code> object. This is most easily done with point data. It is important to assign the correct CRS when converting- otherwise, your points might end up in a different map projection, and it will be difficult to reproject them.</p>
<pre class="r"><code>library(sf)

state_capitals &lt;- read_csv(&quot;mapping/data/state-capitals.csv&quot;)

state_capitals_sf &lt;- state_capitals %&gt;% 
  st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;),
           crs = 4326)</code></pre>
</div>
<div id="reading-in-shapefiles" class="section level3">
<h3>Reading in shapefiles</h3>
<p><code>library(sf)</code> also contains functions that allow you to read in shapefiles. Most shapefiles are traditionally stored as 6 different files. <code>st_read()</code> has two required arguments: the directory where the shapefile is located (<code>dsn =</code>) and the name of the layer (<code>layer =</code>). Note that you do not need a file extension on the layer, since R will be looking for all 6 files, each of which have different extensions.</p>
<pre class="r"><code>list.files(&quot;mapping/shapefiles&quot;)</code></pre>
<pre><code>## [1] &quot;Basemap_of_DC_in_Dark_Gray.cpg&quot; &quot;Basemap_of_DC_in_Dark_Gray.dbf&quot;
## [3] &quot;Basemap_of_DC_in_Dark_Gray.prj&quot; &quot;Basemap_of_DC_in_Dark_Gray.shp&quot;
## [5] &quot;Basemap_of_DC_in_Dark_Gray.shx&quot;</code></pre>
<pre class="r"><code>dc &lt;- st_read(dsn = &quot;mapping/shapefiles&quot;,
              layer = &quot;Basemap_of_DC_in_Dark_Gray&quot;)</code></pre>
<pre><code>## Reading layer `Basemap_of_DC_in_Dark_Gray&#39; from data source `/Users/sarahstrochak/Documents/urban/r-at-urban/mapping/shapefiles&#39; using driver `ESRI Shapefile&#39;
## Simple feature collection with 1 feature and 12 fields
## geometry type:  POLYGON
## dimension:      XY
## bbox:           xmin: -77.11981 ymin: 38.79157 xmax: -76.90917 ymax: 38.99596
## epsg (SRID):    4326
## proj4string:    +proj=longlat +datum=WGS84 +no_defs</code></pre>
<pre class="r"><code>ggplot() +
  geom_sf(dc, mapping = aes())</code></pre>
<p><img src="mapping/www/images/st-read-1.png" width="672" /></p>
</div>
</div>
<div id="mapping-1" class="section level2">
<h2>Mapping</h2>
<p>Most mapping in R fits the same theoretical framework as plotting in R using <code>library(ggplot2)</code>. Hadley Wickham’s ggplot2 is based on Leland Wilkinson’s <a href="https://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448"><em>The Grammar of Graphics</em></a> and Wickham’s <a href="http://vita.had.co.nz/papers/layered-grammar.html"><em>A Layered Grammar of Graphics</em></a>. The layered grammar of graphics is a structured way of thinking about the components of a plot, which then lend themselves to the simple structure of ggplot2 and ultimately mapping.</p>
<ul>
<li><strong>Data</strong> are what are visualized in a plot and <strong>mappings</strong> are directions for how data are mapped in a plot in a way that can be perceived by humans.</li>
<li><strong>Geoms</strong> are representations of the actual data like points, lines, and bars.</li>
<li><strong>Stats</strong> are statistical transformations that represent summaries of the data like histograms.</li>
<li><strong>Scales</strong> map values in the data space to values in the aesthetic space. Scales draw legends and axes.</li>
<li><strong>Coordinate Systems</strong> describe how geoms are mapped to the plane of the graphic.</li>
<li><strong>Facets</strong> break the data into meaningful subsets like small multiples.</li>
<li><strong>Themes</strong> control the finer points of a plot such as fonts, font sizes, and background colors.</li>
</ul>
<p><code>geom_sf()</code> is used for mapping in <code>ggplot()</code>. Since <code>sf</code> objects by default have a column called <code>geography</code> that contains a nested list of coordinates, you do not usually need to specify <code>aes()</code>.</p>
<p>Make sure you load <code>library(tidyverse)</code> or <code>library(ggplot2)</code> each time you make a map with <code>ggplot2</code>.</p>
<div id="the-basics" class="section level3">
<h3>The basics</h3>
<p>When using <code>library(ggplot2)</code>, you need to specify the <code>sf</code> dataframe you are using. If your geographic boundaries are stored in a column other than <code>geometry</code>, you will need to specify that too.</p>
<p>Starting with an example from the <code>urbnmapr</code> package, we can load in an <code>sf</code> object and then display it using <code>ggplot()</code>.</p>
<pre class="r"><code>library(urbnmapr)

states &lt;- get_urbn_map(&quot;states&quot;, sf = TRUE)

ggplot() +
  geom_sf(data = states, mapping = aes())</code></pre>
<p><img src="mapping/www/images/first-map-1.png" width="672" /></p>
</div>
<div id="styling-maps" class="section level3">
<h3>Styling maps</h3>
<div id="urbnthemes" class="section level4">
<h4><code>urbnthemes</code></h4>
<p><code>library(urbnthemes)</code> has functions that are built for mapping with <code>ggplot2</code>.</p>
<p>To install <code>urbnthemes</code>, visit the <a href="https://github.com/UrbanInstitute/urbnthemes">GitHub repository</a>.</p>
<p>You can use the mapping functions in two ways: setting the map defaults, or adding <code>theme_urbn_map()</code> to the end of your map. These functions will get rid of the axes, labels, and gridlines that are useful for charts, but not needed for maps.</p>
<p>For more information on creating Urban-styled maps, see the <a href="http://urbaninstitute.github.io/graphics-styleguide/">Urban Institute Data Visualization Style Guide</a>.</p>
<pre class="r"><code>library(urbnthemes)

set_urbn_defaults(style = &quot;map&quot;)

ggplot() +
  geom_sf(states, mapping = aes()) +
  theme_urbn_map()</code></pre>
<p><img src="mapping/www/images/urbnthemes-1.png" width="672" /></p>
</div>
<div id="map-design" class="section level4">
<h4>Map design</h4>
<p>The same commands used to change colors, opacity, lines, size, etc. in charts can be used for maps too. For instance, if I wanted to change the colors of the map above, I would simply use the <code>fill =</code> and <code>color =</code> parameters in <code>geom_sf()</code>. <code>fill</code> will change the color of the polygon; <code>color</code> will change the color of polygon outlines, lines, and points.</p>
<pre class="r"><code>ggplot() +
  geom_sf(states, mapping = aes(),
          fill = &quot;#ec008b&quot;, color = &quot;#ffffff&quot;) +
  theme_urbn_map()</code></pre>
<p><img src="mapping/www/images/urbnthemes-%20pink-1.png" width="672" /></p>
</div>
<div id="layering" class="section level4">
<h4>Layering</h4>
<p>Just like in other GIS software, you can layer multiple <code>sf</code> objects. The shapes will appear from bottom to top in the order they are called. It is important that all layers are in the same projection.</p>
<pre class="r"><code>state_capitals &lt;- read_csv(&quot;mapping/data/state-capitals.csv&quot;) %&gt;% 
  filter(!state %in% c(&quot;Alaska&quot;, &quot;Hawaii&quot;)) %&gt;% 
  st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;),
           crs = 4326) %&gt;% 
  st_transform(crs = 2163)

ggplot() +
  geom_sf(data = filter(states, !state_abbv %in% c(&quot;AK&quot;, &quot;HI&quot;)), 
          mapping = aes()) +
  geom_sf(data = state_capitals, mapping = aes(),
          color = &quot;#1696d2&quot;, size = 2.0) +
  theme_urbn_map()</code></pre>
<p><img src="mapping/www/images/layers-1.png" width="672" /></p>
</div>
</div>
<div id="choropleth-maps" class="section level3">
<h3>Choropleth maps</h3>
<p>Choropleth maps display geographic areas with shades, colors, or patterns in proportion to a variable or variables. Choropleth maps can represent massive geographies like the entire world and small geographies like Census Tracts.</p>
<hr />
</div>
</div>
<div id="choropleth-maps-1" class="section level2">
<h2>Choropleth Maps</h2>
<hr />
<div id="libraryurbnmapr-1" class="section level3">
<h3>library(urbnmapr)</h3>
<p><a href="https://github.com/UrbanInstitute/urbnmapr">urbnmapr</a> is an R package created by the Urban Institute. It includes state and county outlines for the entire United States with Hawaii and Alaska next to the Continental U.S. The packages includes a data frame for states called <code>states</code> and a data frame for counties called <code>counties</code>.</p>
<p>Variables mapped as colors or shades need to be joined using <code>left_join()</code> to geographic data loaded by <code>library(urbnmapr)</code>. In this example, the variable <code>&quot;state_name&quot;</code> is joined to <code>&quot;State&quot;</code>. If ever in doubt, use <code>anti_join()</code> to test which cases don’t join. After joining, use <code>geom_polygon()</code>. Be sure to include <code>coord_map(&quot;albers&quot;, lat0 = 39, lat1 = 45)</code> to create an Albers Equal Area projection.</p>
<!-- ```{r} -->
<!-- # load necessary packages -->
<!-- library(tidyverse) -->
<!-- library(forcats) -->
<!-- library(gridExtra) -->
<!-- library(urbnmapr) -->
<!-- library(urbnthemes) -->
<!-- set_urbn_defaults(style = "map") -->
<!-- # read the state CHIP data -->
<!-- chip <- read_csv("mapping/data/chip-enrollment.csv") -->
<!-- # set the state names to lower case and create the five groups based on the order -->
<!-- # of state CHIP enrollment     -->
<!-- chip <- chip %>% -->
<!--   arrange(`CHIP Enrollment`) %>% -->
<!--   mutate(Enrollment = c(rep("Group 1", times = 11),  -->
<!--                         rep("Group 2", times = 10), -->
<!--                         rep("Group 3", times = 10),  -->
<!--                         rep("Group 4", times = 10),  -->
<!--                         rep("Group 5", times = 10))) -->
<!-- # join chip data and state shapes -->
<!-- chip <- left_join(chip, states, by = c("State" = "state_name"))  -->
<!-- # test join -->
<!-- mismatches <- anti_join(chip, states, by = c("State" = "state_name"))  -->
<!-- # create a vector with 5 hexadecimal colors for the 5 groups -->
<!-- urban_colors <- c("#cfe8f3", "#a2d4ec", "#46abdb", "#12719e", "#062635") -->
<!-- # plot the data with colors based on state CHIP enrollment and white borders  -->
<!-- # between the states -->
<!-- ggplot(data = chip, mapping = aes(long, lat, group = group, fill = Enrollment)) + -->
<!--   geom_polygon(color = "#ffffff", size = 0.25) + -->
<!--   scale_fill_manual(values = urban_colors) +   -->
<!--   coord_map(projection = "albers", lat0 = 39, lat1 = 45) + -->
<!--   labs(title = "State CHIP Enrollment")  + -->
<!--   theme(plot.margin = margin(t = 0, r = 0, b = 0, l = 0)) -->
<!-- ``` -->
<!-- `library(urbnmapr)` makes it is easy to filter to a subset of geographies. Here, `filter(state_name %in% c("Washington", "Oregon", "Idaho"))` is used to filter to three states before `ggplot()` is called.  -->
<!-- ```{r state-map-northwest} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(urbnmapr) -->
<!-- # read the shapefiles for the three states -->
<!-- state <- states %>% -->
<!--  filter(state_name %in% c("Washington", "Oregon", "Idaho")) -->
<!-- # map! -->
<!-- ggplot(data = state, mapping = aes(x = long, y = lat, group = group)) +  -->
<!--  geom_polygon(color = "#ffffff", fill = "gray", size = 0.25) + -->
<!--  coord_map(projection = "albers", lat0 = 39, lat1 = 45) +  -->
<!--  labs(title = "Northwest United States") -->
<!-- ``` -->
<!-- `library(urbnmapr)` can also be used to map counties. Here, `counties` is used to map all counties in the Continental United States.  -->
<!-- ```{r us-county-map} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(urbnmapr) -->
<!-- # map! -->
<!-- ggplot(data = counties, mapping = aes(x = long, y = lat, group = group)) +  -->
<!--  coord_map(projection = "albers", lat0 = 39, lat1 = 45) +  -->
<!--  geom_polygon(color = "#ffffff", fill = "gray", size = 0.1) -->
<!-- ``` -->
<!-- Geographies can be added on top of each other as layers. In this case, states is called once with no fill and a thick border to outline states and then counties is called with fill and a thin border to outline counties.  -->
<!-- ```{r northwest-county-map} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(urbnmapr) -->
<!-- # read the shapefiles for counties -->
<!-- county <- counties %>% -->
<!--  filter(state_name %in% c("Washington", "Oregon", "Idaho")) -->
<!-- # read the shapefiles for states -->
<!-- state <- states %>% -->
<!--  filter(state_name %in% c("Washington", "Oregon", "Idaho")) -->
<!-- # map -->
<!-- ggplot(data = county, mapping = aes(x = long, y = lat, group = group)) +  -->
<!--  geom_polygon(color = "#ffffff", fill = "gray", size = 0.2) +   -->
<!--  geom_polygon(data = state, -->
<!--    mapping = aes(x = long, y = lat, group = group),  -->
<!--    color = "#ffffff",  -->
<!--    fill = NA,  -->
<!--    size = 0.4) +  -->
<!--  coord_map(projection = "albers", lat0 = 39, lat1 = 45) +   -->
<!--  labs(title = "Counties in the Northwest United States") -->
<!-- ``` -->
<!-- ### Mapping individual states -->
<!-- The groups of states above use the same Albers Equal-Area Conic Projection as the maps of the entire United States. For single state maps, the Urban Institute uses [state plane coordinate systems](https://en.wikipedia.org/wiki/State_Plane_Coordinate_System). This requires loading the data from `library(tidycensus)` and using special features. tidycensus has quality documentation. This [GitHub](https://github.com/walkerke/tidycensus) page and this [vignette](https://walkerke.github.io/tidycensus/articles/spatial-data.html) are good places to start.  -->
<!-- ```{r virginia} -->
<!-- library(tidycensus) -->
<!-- library(tidyverse) -->
<!-- library(urbnthemes) -->
<!-- get_acs(geography = "state", variables = "B19013_001",  -->
<!--        shift_geo = TRUE, geometry = TRUE) %>% -->
<!--  filter(NAME == "Virginia") %>% -->
<!--  ggplot() +  -->
<!--  geom_sf(color = "#ffffff", fill = "gray", size = 0.2) +  -->
<!--  coord_sf(crs = 32047) + -->
<!--  theme_void() + -->
<!--  theme(panel.grid = element_line(colour = "transparent")) -->
<!-- ``` -->
<!-- ### library(leaflet) -->
<!-- [Leaflet](http://leafletjs.com/) is a JavaScript library for building interactive maps. The syntax is different than ggplot2, but `library(leaflet)` makes easy building interactive maps in R.  -->
<!-- [This post](https://juliasilge.com/blog/using-tidycensus/) by Julia Silge is an excellent introduction to `library(leaflet)` and `library(tidycensus)`. -->
<!-- Certain geographies require a [Census API key](https://api.census.gov/data/key_signup.html). Add the API key with `tidycensus::census_api_key()`. The argument `install = TRUE` will permanently install the key on a computer.  -->
<!-- ```{r leaflet, results="hide"} -->
<!-- # load necessary packages -->
<!-- library(tidyverse) -->
<!-- library(sf) -->
<!-- library(stringr) -->
<!-- library(rgdal) -->
<!-- library(leaflet) -->
<!-- library(stringr) -->
<!-- library(viridis) -->
<!-- library(tidycensus) -->
<!-- # certain geographies require a Census API key -->
<!-- # census_api_key("") -->
<!-- # read mortgage data and drop unnecessary variables -->
<!-- hmda <- read_csv("mapping/data/hmdamap2015_10_purch.csv",  -->
<!--   col_types = cols( -->
<!--     tract = col_character(), -->
<!--     year1 = col_integer(), -->
<!--     tract_T = col_character(), -->
<!--     aa = col_integer(), -->
<!--     his = col_integer(), -->
<!--     nhw = col_integer(), -->
<!--     asian = col_integer(), -->
<!--     total = col_integer())) %>%  -->
<!--  select(-year1, -tract_T) -->
<!-- # The Census tract IDs in the hmda data do not perfectly match the Census tract -->
<!-- # IDS in the shapefiles. Add zeros to the front of the  10-digit census tracts  -->
<!-- # so the IDs match before using left_join() -->
<!-- hmda <- hmda %>% -->
<!--  mutate(tract = ifelse(!str_length(hmda$tract) == 11, str_c("0", tract), tract)) -->
<!-- # Pull data from the ACS using library(tidycensus). Rename GEOID to tract so the -->
<!-- # tract ID has the same variable name as on the mortgage data.  -->
<!-- ct_value <- get_acs(geography = "tract",  -->
<!--                     variables = "B25077_001",  -->
<!--                     state = "CT", -->
<!--                     geometry = TRUE) %>% -->
<!--  rename(tract = GEOID) -->
<!-- # join housing data to the shapefiles -->
<!-- ct_value <- left_join(x = ct_value, y = hmda, by = "tract") -->
<!-- # check for mismatches using anti_join. Hopefully nrow(mismatches) == 0 -->
<!-- mismatches <- anti_join(x = ct_value, y = hmda, by = "tract") -->
<!-- # create a color palette based on the total number of mortgages variable -->
<!-- pal <- colorNumeric(palette = c("#cfe8f3", "#062635"),  -->
<!--                    domain = ct_value$total) -->
<!-- ``` -->
<!-- ```{r build-leaflet} -->
<!-- # create the map -->
<!-- connecticut <- ct_value %>% -->
<!--  st_transform(crs = "+init=epsg:4326") %>% -->
<!--  leaflet(width = "100%") %>% -->
<!--  addProviderTiles(provider = "CartoDB.Positron") %>% -->
<!--  addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"), -->
<!--              stroke = FALSE, -->
<!--              smoothFactor = 0, -->
<!--              fillOpacity = 1, -->
<!--              color = ~ pal(total)) %>% -->
<!--  addLegend(position = "bottomright",  -->
<!--            pal = pal,  -->
<!--            values = ~ total, -->
<!--            title = "Mortgage Purchases", -->
<!--            opacity = 1) -->
<!-- library(htmltools) -->
<!-- browsable( -->
<!--   tagList(list( -->
<!--     tags$head( -->
<!--       # you'll need to be very specific -->
<!--       tags$style("* {font-family:Lato !important;}") -->
<!--       # could also use url -->
<!--       #tags$link(href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css",rel="stylesheet") -->
<!--     ), -->
<!--     connecticut -->
<!--   )) -->
<!-- ) -->
<!-- # https://stackoverflow.com/questions/35720698/is-it-possible-to-include-custom-css-in-htmlwidgets-for-r-and-or-leafletr -->
<!-- ``` -->
<!-- ### Census tract shapefiles -->
<!-- It is often desirable to map geographies that aren't easily available in an R package. Like any GIS, R can work with shapefiles, which are a vector data storage format created by Esri to store location, shape, and attributes of geographic features. Shapefiles are available for most geographies.  -->
<!-- `readOGR()` from `library(rgdal)` is the most used function for reading shapefiles. One challenge of working with shapefiles is the hierarchical data structure. Click on the shapefile in the R Studio environment to explore the tree and see how the data are organized. Another challenge is merges. In the following example, mortgage data need to be merged with the appropriate Census tracts.  -->
<!-- ```{r census-tract-choropleth, fig.height = 3.5} -->
<!-- # load necessary packages -->
<!-- library(tidyverse) -->
<!-- library(sp) -->
<!-- library(stringr) -->
<!-- library(rgdal) -->
<!-- library(broom) -->
<!-- # read in mortgage data -->
<!-- hmda <- read_csv("mapping/data/hmdamap2015_10_purch.csv",  -->
<!--                 col_types = cols( -->
<!--                  tract = col_character(), -->
<!--                  year1 = col_integer(), -->
<!--                  tract_T = col_character(), -->
<!--                  aa = col_integer(), -->
<!--                  his = col_integer(), -->
<!--                  nhw = col_integer(), -->
<!--                  asian = col_integer(), -->
<!--                  total = col_integer())) %>%  -->
<!--  select(-year1, -tract_T) -->
<!-- # The Census tract IDs in the hmda data do not perfectly match the Census tract -->
<!-- # IDS in the shapefiles. Add zeros to the front of the  10-digit census tracts  -->
<!-- # so the IDs match before using left_join() -->
<!-- hmda <- hmda %>% -->
<!--  mutate(tract = ifelse(!str_length(hmda$tract) == 11, str_c("0", tract), tract)) -->
<!-- # read in shapefile for Washington D.C. -->
<!-- tracts_dc <- readOGR(dsn = "mapping/shapefiles/tl_2015_11_tract", verbose = FALSE) -->
<!-- # create an extra data frame with the tract number and the position from 1 to n -->
<!-- tract_id <- tibble(tract = as.character(tracts_dc@data$GEOID),  -->
<!--                   position = 1:length(tracts_dc@data$GEOID)) -->
<!-- # convert shapefile to tibble. Add a vector for position that will be used to  -->
<!-- # merge the Census tract  -->
<!-- tracts_dc <- tidy(tracts_dc) %>% -->
<!--  rename(position = id) %>% -->
<!--  mutate(position = as.numeric(position)) %>% -->
<!--  mutate(position = position + 1) -->
<!-- # merge on tract number -->
<!-- tracts_dc <- left_join(x = tracts_dc, y = tract_id, by = "position") -->
<!-- # check for mismatches using anti_join. Hopefully nrow(mismatches) == 0 -->
<!-- mismatches1 <- anti_join(x = tracts_dc, y = tract_id, by = "position") -->
<!-- # With the new tract number, merge on the mortgage data -->
<!-- tracts_dc <- left_join(x = tracts_dc, y = hmda, by = "tract") -->
<!-- # check for mismatches using anti_join. Hopefully nrow(mismatches) == 0 -->
<!-- mismatches2 <- anti_join(x = tracts_dc, y = hmda, by = "tract") -->
<!-- # munge the data and transform it into a long data frame -->
<!-- tracts_dc_long <- tracts_dc %>% -->
<!--  gather(key = "race", value = "Mortgages",  -->
<!--         -long, -lat, -order, -hole, -piece,  -->
<!--         -group, -position, -tract, -total) %>% -->
<!--  mutate(race = factor(race,  -->
<!--                       levels = c("aa", "asian", "his", "nhw"),  -->
<!--                       labels = c("African American", "Asian", "Hispanic", "Non-Hispanic White"))) %>% -->
<!--  mutate(Mortgages = ifelse(Mortgages == 0, NA, Mortgages)) %>% -->
<!--  mutate(Mortgages = Mortgages * 10) -->
<!-- # plot! -->
<!-- tracts_dc_long %>% -->
<!--  ggplot(mapping = aes(x = long, y = lat, group = group, fill = Mortgages)) + -->
<!--  geom_polygon(size = 0.3) + -->
<!--  coord_map() + -->
<!--  facet_wrap(facets = ~race, nrow = 1) + -->
<!--  scale_fill_continuous(low = "#CEE8F3",  -->
<!--                        high = "#094C6B", -->
<!--                        breaks = c(0, 20, 40, 60, 80)) + -->
<!--  labs(x = NULL, -->
<!--       y = NULL) + -->
<!--  labs(title = "Mortgage Originations", -->
<!--       subtitle = "Home purchase loans in 2015 by race and ethnicity", -->
<!--       caption = "Urban Institute analysis of HMDA data") + -->
<!--  theme(axis.text = element_blank(), -->
<!--        axis.line = element_blank(), -->
<!--        axis.ticks = element_blank(),  -->
<!--        panel.grid.major = element_blank(), -->
<!--        legend.position = "right", -->
<!--        legend.direction = "vertical", -->
<!--        legend.title = element_text(face = "bold", size = 11), -->
<!--        strip.text = element_text(size = 11), -->
<!--        plot.caption = element_text(size = 11), -->
<!--        strip.background = element_rect(fill = "#ffffff")) -->
<!-- ``` -->
<!-- ## Tile Grid Maps -->
<!-- ------ -->
<!-- Choropleths tend to overemphasize low-population density areas because size represents area instead of the statistic of interest. This is especially true for maps of the United States because many western states are large and have low-density populations. Tile grid maps, which give equal size to each state, mitigates this problem.  -->
<!-- This example fills `geom_tile()` from `library(ggplot2)` with five discrete colors based on state CHIP enrollment and then uses `facet_geo()` from `library(geofacet)` to create a tile grid map.  -->
<!-- ```{r chip} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(forcats) -->
<!-- library(geofacet) -->
<!-- # read CHIP enrollment data -->
<!-- chip <- read_csv("mapping/data/chip-enrollment.csv", -->
<!--  col_types = cols( -->
<!--   State = col_character(), -->
<!--   `CHIP Enrollment` = col_integer(), -->
<!--   state_abbreviation = col_character())) -->
<!-- # Add xdimension = 1 and ydimension = 1 for dimensions of geom_tile. x and y  can be any arbitrary numbers greater than zero as long as xdimesion == ydimension.  Arrange the observations by state enrollment and add groups for the colors of the tiles  -->
<!-- chip <- chip %>% -->
<!--   mutate(xdimension = 1,  -->
<!--          ydimension = 1) %>% -->
<!--   arrange(desc(`CHIP Enrollment`)) %>% -->
<!--   mutate(enrollment_group = c(rep("Group 1", times = 11),  -->
<!--                               rep("Group 2", times = 10),  -->
<!--                               rep("Group 3", times = 10),  -->
<!--                               rep("Group 4", times = 10),  -->
<!--                               rep("Group 5", times = 10))) -->
<!-- # create a vector with 5 hexadecimal colors for the 5 groups -->
<!-- urban_colors <- c("#062635", "#12719e", "#46abdb", "#a2d4ec", "#cfe8f3") -->
<!-- # create a custom geofacet grid -->
<!-- urban_grid <- tibble( -->
<!--   row = c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,  -->
<!--           4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,  -->
<!--           7, 7, 8, 8, 8), -->
<!--   col = c(1, 11, 6, 10, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 6, 7, 8, 1, 4, 9), -->
<!--   code = c("AK", "ME", "WI", "VT", "NH", "WA", "ID", "MT", "ND", "MN", "IL", "MI", "NY", "MA", "OR", "NV", "WY", "SD", "IA", "IN", "OH", "PA", "NJ", "CT", "RI", "CA", "UT", "CO", "NE", "MO", "KY", "WV", "VA", "MD", "DE", "AZ", "NM", "KS", "AR", "TN", "NC", "SC", "DC", "OK", "LA", "MS", "AL", "GA", "HI", "TX", "FL"), -->
<!--   name = c("Alaska", "Maine", "Wisconsin", "Vermont", "New Hampshire", "Washington", "Idaho", "Montana", "North Dakota", "Minnesota", "Illinois", "Michigan", "New York", "Massachusetts", "Oregon", "Nevada", "Wyoming", "South Dakota", "Iowa", "Indiana", "Ohio", "Pennsylvania", "New Jersey", "Connecticut", "Rhode Island", "California", "Utah", "Colorado", "Nebraska", "Missouri", "Kentucky", "West Virginia", "Virginia", "Maryland", "Delaware", "Arizona", "New Mexico", "Kansas", "Arkansas", "Tennessee", " North Carolina", "South Carolina", " District of Columbia", "Oklahoma", "Louisiana", "Mississippi", "Alabama", "Georgia", "Hawaii", "Texas", "Florida") -->
<!-- ) -->
<!-- # create tile grid map -->
<!-- chip %>% -->
<!--   ggplot(aes(x = xdimension, y = ydimension, fill = enrollment_group)) + -->
<!--     geom_tile() + -->
<!--     scale_fill_manual(values = urban_colors) +   -->
<!--     geom_text(aes(label = state_abbreviation), color = "white") + -->
<!--     facet_geo(facets = ~state_abbreviation, grid = urban_grid) + -->
<!--     labs(title = "State CHIP Enrollment",  -->
<!--         x = NULL, -->
<!--          y = NULL) + -->
<!--    coord_equal() + -->
<!--     theme(axis.text = element_blank(), -->
<!--           axis.ticks = element_blank(), -->
<!--           axis.line = element_blank(), -->
<!--          strip.text = element_blank(), -->
<!--          plot.background = element_rect(color = "white"),     -->
<!--            panel.background = element_blank(),      -->
<!--           panel.grid = element_blank(), -->
<!--           panel.spacing = unit(0L, "pt"), -->
<!--          panel.grid.major = element_blank(), -->
<!--           panel.grid.minor = element_blank()) -->
<!-- ``` -->
<!-- ## Geofaceting -->
<!-- ------ -->
<!-- `library(geofacet)` adds geofaceting functionality to `library(ggplot2)`. Geofaceting arranges sub-geography-specific plots into a grid that resembles a larger geography.  -->
<!-- Interactive geofacets of the United States have been used by the Urban Institute in the features section. For example, ["A Matter of Time"](http://apps.urban.org/features/long-prison-terms/trends.html) included geofaceted line charts showing trends in incarceration by state. Static geofacets of the United States were included in ["Barriers to Accessing Homeownership Down Payment, Credit, and Affordability"](https://www.urban.org/sites/default/files/publication/94801/barriers-to-homeownership-down-payments-credit-access-and-affordability_2.pdf) by the Housing Finance Policy Center.  -->
<!-- `library(geofacet)` comes with two default United States grids, but the Urban Institute uses a custom layout for United States geofacets. The code for that layout is included in each of the following examples. Creating custom grids is simple and is outlined in the [vignette](https://hafen.github.io/geofacet/) for `library(geofacet)`. This [grid designer](https://hafen.github.io/grid-designer/) is useful for testing custom layouts. Custom geofacet grids can be made for any sized geography and any set of geographies.  -->
<!-- Lots of custom formatting in `theme()` is necessary because geofaceted plots are different than the plots for which the theme was optimized. Copying-and-pasting the code in `theme()` is a good start.  -->
<!-- ### geom_tile() -->
<!-- The first example is a variation on the tile grid map. Here, state labels are moved to the strip and values are added in each square as a text geom.  -->
<!-- ```{r modified-tile-grid-map, fig.height=6} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(geofacet) -->
<!-- library(fivethirtyeight) -->
<!-- # create a tibble with state name abbreviations -->
<!-- state_abbreviations <- tibble(state = c(state.name, "District of Columbia"), -->
<!--                               abbreviation = c(state.abb, "DC")) -->
<!-- # read the bad_drivers data from library(fivethirtyeight) and add maximum -->
<!-- # x- and y- dimensions for each geom_tile. The dimension could be any positive  -->
<!-- # integers as long as x == y -->
<!-- usa_drivers <- bad_drivers %>%  -->
<!--   mutate(xdimension = 1,  -->
<!--         ydimension = 1) -->
<!-- # merge state abbreviations on to bad_drivers based on state -->
<!-- usa_drivers <- left_join(x = usa_drivers, y = state_abbreviations, by = "state") -->
<!-- # test merge criteria for mismatches. hopefully nrow(mismatches) == 0 -->
<!-- mismatches <- left_join(x = usa_drivers, y = state_abbreviations, by = "state") -->
<!-- # create a custom geofacet grid -->
<!-- urban_grid <- tibble( -->
<!--   row = c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,  -->
<!--           4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,  -->
<!--           7, 7, 8, 8, 8), -->
<!--   col = c(1, 11, 6, 10, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 6, 7, 8, 1, 4, 9), -->
<!--   code = c("AK", "ME", "WI", "VT", "NH", "WA", "ID", "MT", "ND", "MN", "IL", "MI", "NY", "MA", "OR", "NV", "WY", "SD", "IA", "IN", "OH", "PA", "NJ", "CT", "RI", "CA", "UT", "CO", "NE", "MO", "KY", "WV", "VA", "MD", "DE", "AZ", "NM", "KS", "AR", "TN", "NC", "SC", "DC", "OK", "LA", "MS", "AL", "GA", "HI", "TX", "FL"), -->
<!--   name = c("Alaska", "Maine", "Wisconsin", "Vermont", "New Hampshire", "Washington", "Idaho", "Montana", "North Dakota", "Minnesota", "Illinois", "Michigan", "New York", "Massachusetts", "Oregon", "Nevada", "Wyoming", "South Dakota", "Iowa", "Indiana", "Ohio", "Pennsylvania", "New Jersey", "Connecticut", "Rhode Island", "California", "Utah", "Colorado", "Nebraska", "Missouri", "Kentucky", "West Virginia", "Virginia", "Maryland", "Delaware", "Arizona", "New Mexico", "Kansas", "Arkansas", "Tennessee", " North Carolina", "South Carolina", " District of Columbia", "Oklahoma", "Louisiana", "Mississippi", "Alabama", "Georgia", "Hawaii", "Texas", "Florida") -->
<!-- ) -->
<!-- # create tile grid map -->
<!-- usa_drivers %>% -->
<!--   ggplot(aes(x = xdimension, y = ydimension, fill = perc_alcohol)) + -->
<!--   geom_tile() + -->
<!--   geom_text(aes(label = paste0(as.character(perc_alcohol), "%")),  -->
<!--            color = "white",  -->
<!--            family = "Lato") + -->
<!--  scale_fill_gradientn() + -->
<!--   facet_geo(facets = ~abbreviation, grid = urban_grid) + -->
<!--   labs(title = "Don't Drink and Drive", -->
<!--       subtitle = "% of Drivers in Deadly Wrecks Who Were Alcohol-Impaired",  -->
<!--       caption = "National Highway Traffic Administration\n Data from library(fivethirtyeight)", -->
<!--        x = NULL, -->
<!--        y = NULL) + -->
<!--   theme(plot.background = element_rect(colour = "white"), -->
<!--         panel.grid = element_blank(), -->
<!--         panel.grid.major = element_blank(), -->
<!--         axis.text = element_blank(), -->
<!--         axis.ticks = element_blank(), -->
<!--         axis.line = element_blank(), -->
<!--         panel.spacing = unit(0L, "pt"), -->
<!--         legend.position = "none", -->
<!--         strip.text.x = element_text(size = 9L)) -->
<!-- ``` -->
<!-- ### geom_bar()  -->
<!-- Unlike the tile grid map, geofaceting isn't limited to just text and color in the facets. This geofaceted map uses bar plots. Be careful, it can quickly clutter.  -->
<!-- ```{r geo-facet-bar, fig.height=6} -->
<!-- # load necessary packages -->
<!-- library(tidyverse) -->
<!-- library(fivethirtyeight) -->
<!-- library(geofacet) -->
<!-- # create data frame with state driving data -->
<!-- usa_drivers <- bad_drivers %>% -->
<!--  mutate(perc_distracted = 100 - perc_not_distracted) %>% -->
<!--  select(state, perc_speeding, perc_alcohol, perc_distracted) %>% -->
<!--  gather(key = issue, value = value, - state) %>% -->
<!--  mutate(issue = ifelse(issue == "perc_speeding", "Speeding", issue), -->
<!--         issue = ifelse(issue == "perc_alcohol", "Alcohol-Impaired", issue), -->
<!--         issue = ifelse(issue == "perc_distracted", "Distracted", issue)) -->
<!-- # create a tibble with state name abbreviations -->
<!-- state_abbreviations <- tibble(state = c(state.name, "District of Columbia"), -->
<!--                              abbreviation = c(state.abb, "DC")) -->
<!-- # merge state abbreviations on to bad_drivers based on state -->
<!-- usa_drivers <- left_join(x = usa_drivers, y = state_abbreviations, by = "state") -->
<!-- # test merge criteria for mismatches. hopefully nrow(mismatches) == 0 -->
<!-- mismatches <- anti_join(x = usa_drivers, y = state_abbreviations, by = "state") -->
<!-- # create a custom geofacet grid -->
<!-- urban_grid <- tibble( -->
<!--   row = c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,  -->
<!--           4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,  -->
<!--           7, 7, 8, 8, 8), -->
<!--   col = c(1, 11, 6, 10, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 6, 7, 8, 1, 4, 9), -->
<!--   code = c("AK", "ME", "WI", "VT", "NH", "WA", "ID", "MT", "ND", "MN", "IL", "MI", "NY", "MA", "OR", "NV", "WY", "SD", "IA", "IN", "OH", "PA", "NJ", "CT", "RI", "CA", "UT", "CO", "NE", "MO", "KY", "WV", "VA", "MD", "DE", "AZ", "NM", "KS", "AR", "TN", "NC", "SC", "DC", "OK", "LA", "MS", "AL", "GA", "HI", "TX", "FL"), -->
<!--   name = c("Alaska", "Maine", "Wisconsin", "Vermont", "New Hampshire", "Washington", "Idaho", "Montana", "North Dakota", "Minnesota", "Illinois", "Michigan", "New York", "Massachusetts", "Oregon", "Nevada", "Wyoming", "South Dakota", "Iowa", "Indiana", "Ohio", "Pennsylvania", "New Jersey", "Connecticut", "Rhode Island", "California", "Utah", "Colorado", "Nebraska", "Missouri", "Kentucky", "West Virginia", "Virginia", "Maryland", "Delaware", "Arizona", "New Mexico", "Kansas", "Arkansas", "Tennessee", " North Carolina", "South Carolina", " District of Columbia", "Oklahoma", "Louisiana", "Mississippi", "Alabama", "Georgia", "Hawaii", "Texas", "Florida") -->
<!-- ) -->
<!-- # plot! -->
<!-- ggplot(data = usa_drivers, aes(x = issue, y = value, fill = issue)) + -->
<!--   geom_col() + -->
<!--  coord_flip() + -->
<!--  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)), -->
<!--                     breaks = c(0, 50, 100), -->
<!--                     labels = c("0", ".5", "1")) + -->
<!--   facet_geo(facets = ~abbreviation, grid = urban_grid) + -->
<!--  labs(title = "Driving is dangerous",  -->
<!--       subtitle = "Proportion of drivers in fatal collisions who were...", -->
<!--       x = NULL, -->
<!--       y = NULL, -->
<!--       caption = "National Highway Traffic Administration \n Data from library(fivethirtyeight)") + -->
<!--  theme(plot.background = element_rect(colour = "white"), -->
<!--        panel.grid = element_blank(), -->
<!--        panel.grid.major = element_blank(), -->
<!--        axis.text.x = element_text(margin = margin(t = 2)), -->
<!--        axis.text.y = element_blank(), -->
<!--        axis.text = element_text(size = 8L), -->
<!--        axis.line = element_blank(), -->
<!--        panel.border = element_rect(colour = "black",  -->
<!--                                    fill = NA,  -->
<!--                                    size = 0.3), -->
<!--         strip.background = element_rect(fill = "grey85",  -->
<!--                                        colour = "black",  -->
<!--                                        size = 0.3), -->
<!--        axis.ticks.length = unit(1L, "pt"), -->
<!--        strip.text.x = element_text(margin = margin(t = 1, b = 1), size = 11)) -->
<!-- ``` -->
<!-- ### geom_line() -->
<!-- ```{r geo-facet-line, fig.height=6} -->
<!-- # load necessary packages -->
<!-- library(tidyverse) -->
<!-- library(geofacet) -->
<!-- library(fivethirtyeight) -->
<!-- library(purrr) -->
<!-- # add random noise to create simulated longitudinal data -->
<!-- usa_drivers <- bad_drivers %>% -->
<!--  mutate(`2010` = (100 - perc_not_distracted) / 100)  -->
<!-- usa_drivers$`2011` <- usa_drivers$`2010` * rnorm(51, mean = 1.05, sd = 0.05) -->
<!-- usa_drivers$`2012` <- usa_drivers$`2011` * rnorm(51, mean = 1.05, sd = 0.05) -->
<!-- usa_drivers$`2013` <- usa_drivers$`2012` * rnorm(51, mean = 1.05, sd = 0.05) -->
<!-- usa_drivers$`2014` <- usa_drivers$`2013` * rnorm(51, mean = 1.05, sd = 0.05) -->
<!-- usa_drivers$`2015` <- usa_drivers$`2014` * rnorm(51, mean = 1.05, sd = 0.05) -->
<!-- # gather data from wide-format to long-format -->
<!-- usa_drivers <- usa_drivers %>% -->
<!--  gather(`2010`:`2015`, key = "Year", value = "Share Distracted") -->
<!-- # create a tibble with state abbreviations -->
<!-- state_abbreviations <- tibble(state = c(state.name, "District of Columbia"), -->
<!--                              abbreviation = c(state.abb, "DC")) -->
<!-- # merge state abbreviations on to bad_drivers based on state -->
<!-- usa_drivers <- left_join(x = usa_drivers, y = state_abbreviations, by = "state") -->
<!-- # test merge criteria for mismatches. hopefully nrow(mismatches) == 0 -->
<!-- mismatches <- anti_join(x = usa_drivers, y = state_abbreviations, by = "state") -->
<!-- # create a custom geofacet grid -->
<!-- urban_grid <- tibble( -->
<!--   row = c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,  -->
<!--           4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,  -->
<!--           7, 7, 8, 8, 8), -->
<!--   col = c(1, 11, 6, 10, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 6, 7, 8, 1, 4, 9), -->
<!--   code = c("AK", "ME", "WI", "VT", "NH", "WA", "ID", "MT", "ND", "MN", "IL", "MI", "NY", "MA", "OR", "NV", "WY", "SD", "IA", "IN", "OH", "PA", "NJ", "CT", "RI", "CA", "UT", "CO", "NE", "MO", "KY", "WV", "VA", "MD", "DE", "AZ", "NM", "KS", "AR", "TN", "NC", "SC", "DC", "OK", "LA", "MS", "AL", "GA", "HI", "TX", "FL"), -->
<!--   name = c("Alaska", "Maine", "Wisconsin", "Vermont", "New Hampshire", "Washington", "Idaho", "Montana", "North Dakota", "Minnesota", "Illinois", "Michigan", "New York", "Massachusetts", "Oregon", "Nevada", "Wyoming", "South Dakota", "Iowa", "Indiana", "Ohio", "Pennsylvania", "New Jersey", "Connecticut", "Rhode Island", "California", "Utah", "Colorado", "Nebraska", "Missouri", "Kentucky", "West Virginia", "Virginia", "Maryland", "Delaware", "Arizona", "New Mexico", "Kansas", "Arkansas", "Tennessee", " North Carolina", "South Carolina", " District of Columbia", "Oklahoma", "Louisiana", "Mississippi", "Alabama", "Georgia", "Hawaii", "Texas", "Florida") -->
<!-- ) -->
<!-- # plot! -->
<!-- usa_drivers %>% -->
<!--  ggplot(mapping = aes(x = Year, y = `Share Distracted`, group = abbreviation)) + -->
<!--   geom_line() + -->
<!--  scale_x_discrete(breaks = c(2010, 2015), labels = c("'10", "'15")) + -->
<!--  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)), breaks = c(0, 0.5, 1)) + -->
<!--   facet_geo(facets = ~abbreviation, grid = urban_grid) + -->
<!--  labs(title = "Driving is dangerous",  -->
<!--       subtitle = "Simulated Distracted Driving is Increasing", -->
<!--       x = NULL, -->
<!--       y = NULL, -->
<!--       caption = "National Highway Traffic Administration \n Data from library(fivethirtyeight) + Random Noise") + -->
<!--  theme(plot.background = element_rect(colour = "white"), -->
<!--        axis.text.x = element_text(margin = margin(t = 2)), -->
<!--        axis.text = element_text(size = 8L), -->
<!--        axis.line = element_blank(), -->
<!--        panel.border = element_rect(colour = "black",  -->
<!--                                    fill = NA,  -->
<!--                                    size = 0.3), -->
<!--         strip.background = element_rect(fill = "grey85",  -->
<!--                                        colour = "black",  -->
<!--                                        size = 0.3), -->
<!--        axis.ticks.length = unit(1L, "pt"), -->
<!--        strip.text.x = element_text(margin = margin(t = 1, b = 1), size = 11)) -->
<!-- ``` -->
<!-- ## Dot Maps -->
<!-- ------ -->
<!-- Dot maps represent observations or groups of observations at longitudes and latitudes. Most dot maps add dots on top of a recognizable geography such as the Continental United States. It is common to add color or size as aesthetics representing an additional variable like race and ethnicity or income.  -->
<!-- This motivating example loads a map of the United States, adds `geom_point()` for each capital as a layer on top of the map, and then labels the capitals with `geom_text_repel()`.  -->
<!-- ```{r state-capitals} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(urbnmapr) -->
<!-- library(ggrepel) -->
<!-- # drop alaska and hawaii -->
<!-- states_subset <- states %>% -->
<!--  filter(!state_name %in% c("Alaska", "Hawaii")) -->
<!-- # drop alaska and hawaii -->
<!-- # this data frame has the latitutde and longitude for each capital -->
<!-- state_capitals <- read_csv("mapping/data/state-capitals.csv") %>% -->
<!--  filter(!state %in% c("Alaska", "Hawaii")) -->
<!-- # map! -->
<!-- ggplot() +  -->
<!--   geom_polygon(data = states_subset, mapping = aes(x = long, y = lat, group = group),  -->
<!--               color = "#ffffff", fill = "#d2d2d2", size = 0.2) + -->
<!--  geom_point(data = state_capitals, aes(longitude, latitude), alpha = 0.5) + -->
<!--  geom_text_repel(data = state_capitals, aes(longitude, latitude, label = city),  -->
<!--            size = 3, color = "#000000", family = "Lato") + -->
<!--   coord_map(projection = "albers", lat0 = 39, lat1 = 45) +  -->
<!--  labs(title = "State Capitals", -->
<!--       x = NULL,  -->
<!--       y = NULL, -->
<!--       caption = "Urban Institute") -->
<!-- ``` -->
<!-- The code above is the quickest and easiest method for making a dot map in R. Dot maps in R typically don't include Alaska, Hawaii, or territories like Puerto Rico.  -->
<!-- Subsets of the above map can be made by adjusting the bounding box. Another option is `qmplot()`. This function will automatically fit the bounding box to the data. Use `I()` with `color =` and `alpha =` so those variables don't show up in the legends. Here's a map of mortgages in Washington, D.C.: -->
<!-- `qmplot()` has many different map types which can be set with the `maptype =` argument. `"toner-lite"` is the only map type that isn't cluttered.  -->
<!-- ```{r qmplot mortgages} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(ggmap) -->
<!-- # read the mortgage data for DC in 2011 -->
<!-- mortgages <- read_csv("mapping/data/districtofcolumbia2011.csv") -->
<!-- # quick plot -->
<!-- qmplot(x = longitude, y = latitude, data = mortgages, maptype = "toner-lite",  -->
<!--       color = I("#1696d2"), alpha = I(0.2)) + -->
<!--  labs(title = "Mortgage purchases in 2011", -->
<!--       subtitle = "Washington, D.C.",  -->
<!--       caption = "Urban Institute analysis of HMDA data") + -->
<!--  theme(axis.line = element_blank()) -->
<!-- ``` -->
<!-- Here's a similar map of mortgages in Washington, D.C. with `geom = "density2d"`. -->
<!-- ```{r qmplot mortgage density} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(ggmap) -->
<!-- # load mortgage data for DC in 2011 -->
<!-- mortgages <- read_csv("mapping/data/districtofcolumbia2011.csv") -->
<!-- # quick plot! -->
<!-- qmplot(x = longitude, y = latitude, data = mortgages, maptype = "toner-lite",  -->
<!--       geom = "density2d", color = I("#1696d2")) + -->
<!--  labs(title = "Mortgage purchases in 2011", -->
<!--       subtitle = "Washington, D.C.",  -->
<!--       caption = "Urban Institute analysis of HMDA data") + -->
<!--  theme(axis.line = element_blank()) -->
<!-- ``` -->
</div>
</div>
</div>
<div id="analysis" class="section level1">
<h1>Analysis</h1>
<hr />
<div id="geocoding" class="section level2">
<h2>Geocoding</h2>
<hr />
<p>Geocoding is the process of converting addresses into coordinates. Longitudes and latitudes are often necessary for creating dot maps, calculating distances, and linking addresses to geographies like Census tracts.</p>
<p>For a thorough outline of geocoding methods, read the National Neighborhood Indicators Partnership geocoding memo (<a href="https://urbanorg.box.com/s/lr6r6fbwg2peo6336e0vuh9iwrnfde4m">available on Box</a>) written by Rob Pitingolo. The rest of this section outline methods available in R for geocoding addresses.</p>
<div id="us-census-geocoder-api" class="section level4">
<h4>US Census Geocoder API</h4>
<!-- The [US Census Geocoder API](https://geocoding.geo.census.gov/geocoder/) is another option for geocoding. It lacks a fuzzy match so it is less forgiving of address imperfections and it is slower than the Google Maps Geocoding API, but its quota is based on number of observations per batch submission instead of a rate of observations per time. This is easier to accommodate grammatically by calling the function on data sets containing fewer than 1,000 observations.  -->
<!-- [Here's](https://andrewpwheeler.wordpress.com/2017/08/03/geocoding-with-census-data-and-the-census-api/) a useful blog post by Andrew Wheeler that inspired some of the following code.  -->
<!-- ```{r census geocoder} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(httr) -->
<!-- library(jsonlite) -->
<!-- library(stringr) -->
<!-- # create a tibble with an address -->
<!-- addresses <- tibble( -->
<!--  street = c("1940 Corner Rock Rd."), -->
<!--  city = c("Midlothian"), -->
<!--  state = c("Virginia"), -->
<!--  zip = c("23113") -->
<!-- ) -->
<!-- # save the API URL -->
<!-- api_url <- "https://geocoding.geo.census.gov/geocoder/locations/address?" -->
<!-- # function -->
<!-- get_census_address <- function(street, city, state, zip) { -->
<!--   # use GET() to retrieve JSON from the API based on street, city, state,  -->
<!--   # zip, and the API benchmark -->
<!--   unretrieved_json <- GET(url = api_url,  -->
<!--               query = list(street = street, -->
<!--                            city = city, -->
<!--                            state = state, -->
<!--                            zip = zip, -->
<!--                            format = 'json', -->
<!--                            benchmark = 4)) -->
<!--   # retrieve the contents of the API request as text with a UTF-8 encoding -->
<!--   retrieved_json <- content(unretrieved_json, as = 'text', encoding = "UTF-8")   -->
<!--   # simplify JSON into an r object -->
<!--   parsed_json <- fromJSON(retrieved_json, simplifyVector = TRUE) -->
<!--   # extract the complete matched addresses from the r object -->
<!--   matched_addresses <- parsed_json$result$addressMatches -->
<!--   # if there is at least one matcg, return it -->
<!--   if (length(matched_addresses) > 1) { -->
<!--     temp <- c(matched_addresses['matchedAddress'], matched_addresses['coordinates'][[1]]) -->
<!--     return(c(temp[[1]], temp[[2]], temp[[3]])) -->
<!--     } -->
<!--   # if there is no match, return missing values -->
<!--   else {return(c('', NA, NA))} -->
<!-- } -->
<!-- # iterate the function over the list of addresses -->
<!-- output <- addresses %>% -->
<!--   mutate(geocode = pmap(list(street, city, state, zip), get_census_address)) %>% -->
<!--   mutate(new_street = purrr::map(geocode, 1), -->
<!--          latitude = purrr::map(geocode, 2), -->
<!--          longitude = purrr::map(geocode, 3)) -->
<!-- output %>% -->
<!--   mutate(row_number = row_number()) %>% -->
<!--   select(row_number, address = new_street, latitude, longitude) %>% -->
<!--   mutate(accuracy = NA, -->
<!--          address = unlist(address), -->
<!--          latitude = unlist(latitude), -->
<!--          longitude = unlist(longitude)) %>% -->
<!--  kable(digits = 2, caption = "Geocoding with US Census Geocoder API", format = "html", align = "l") %>% -->
<!--  kableExtra::kable_styling(full_width = FALSE, position = "left") -->
<!-- ``` -->
<!-- An optimal strategy for geocoding many addresses could be to break the data into 1,000 observation chunks and submit each chunk to the US Census Geocoder API. Then, use the Google Maps Geocoding API to geocode observations for which the US Census Geocoder API could not find a match. This could all be accomplished with relatively simple R code.  -->
<!-- ## Calculating distances and travel times -->
<!-- ------ -->
<!-- #### mapdist() -->
<!-- `mapdist()` returns the expected travel distance and expected travel time between two locations. The function is vectorized. If a vector of location is passed into the function then it will return a tidy data frame. `mode =` can be set to "driving", "walking", "bicycling", or "transit".  -->
<!-- The `library(ggmap)` GitHub page is a good [resource](https://github.com/dkahle/ggmap) for this type of analysis.  -->
<!-- ```{r mapdist, eval = FALSE} -->
<!-- # load the necessary packages -->
<!-- library(ggmap) -->
<!-- ggmap::mapdist(from = "Lincoln Monument",  -->
<!--        to = "Washington Monument", -->
<!--        mode = "walking", -->
<!--        output = "simple", -->
<!--        source = "dsk") %>% -->
<!--  kable(digits = 2, caption = "Output from ggmap::mapdist()", format = "html", align = "l") %>% -->
<!--  kableExtra::kable_styling(full_width = FALSE, position = "left") -->
<!-- ``` -->
</div>
</div>
<div id="sampling-coordinates" class="section level2">
<h2>Sampling coordinates</h2>
<hr />
<p>Dot maps are often more informative and convincing than choropleth maps, but data with geographic variables are usually defined by geography level (Census tract, county, etc.) instead of longitude and latitude.</p>
<p>If the data are grouped by small geographies, like a Census tracts, coordinates can be randomly sampled from the shapefile for that geography. In this case, the information gained by being able to see the geographic distribution is often justifies the small amount of sampling error.</p>
<p>The Housing Finance Policy Center’s <a href="http://apps.urban.org/features/mortgages-by-race/">“An interactive view of the housing boom and bust”</a> uses data with sampled longitudes and latitudes from Census track shapefiles for millions of mortgages across sixteen years. The following example is based on the code from that project.</p>
<p>The two biggest challenges in sampling coordinates are usually: 1) Finding the correct shapefile because geographies change over time and geographic features like water exist in the middle of geographies. 2) Using and merging the shapefile in R because shapefiles are usually complicated hierarchical data structures.</p>
<p>IPUMS helps with first issue because it is a good <a href="https://usa.ipums.org/usa/volii/boundaries.shtml">source</a> for high-quality shapefiles.</p>
<p>The new version of RStudio helps with the second issue because it boasts a new feature that visualizes the branches of the data and helps select desired variables. Click on the shapefile in RStudio to bring up a map of the data. Mouse over the desired variable and click the little logo that appears to the far right.</p>
<p><img src="mapping/www/images/shapefile.png" /></p>
<p>A line of code that selects the desired variable should appear in the console. For example: <code>shapes@polygons[[1]]@labpt</code>. This trick makes hierarchical data much more manageable.</p>
<p>The following example samples coordinates for mortgage purchase originations by Asian Americans in Rhode Island.</p>
<div id="set-up" class="section level5">
<h5>Set up</h5>
<!-- ```{r sample points, eval = FALSE} -->
<!-- # load the necessary packages -->
<!-- library(tidyverse) -->
<!-- library(sp) -->
<!-- library(rgdal) -->
<!-- library(stringr) -->
<!-- sample_number <- 0 -->
<!-- ``` -->
<!-- ##### get_coordinates -->
<!-- The first function takes one observation with a Census tract number and the number of mortgages in the Census tract and returns a data frame with an observation for each mortgage with longitude and latitude. `spsample()` from `library(sp)` does the random sampling and has a number of options for the type of sampling. All of the function options can be seen by submitting `?spsample`. -->
<!-- ```{r get_coordinates, eval = FALSE} -->
<!-- get_coordinates <- function(census.tract, number.of.mortgages) { -->
<!--   # Purpose: takes shapefile and randomly sample longitudes and latitudes in census tracts -->
<!--   # Args:  -->
<!--   #   census.tract: Census tract ID -->
<!--   #   number.of.mortgages: number of mortgages in Census tract -->
<!--   # Output: list with longitudes and latitudes for mortgages in each ward -->
<!--  # Create unique seed number for each random sample -->
<!--  sample_number <<- sample_number + 1 -->
<!--  # Set seeds so pseudo-random sampling is reproducible -->
<!--  set.seed(max(sample_number, 1)) -->
<!--  # Create a temporary data frame with the sampled coordinates -->
<!--   temp <- spsample(x = tracts_shapefile@polygons[[census.tract]],  -->
<!--                   n = number.of.mortgages,  -->
<!--                   type = "random",  -->
<!--                   iter = 100) -->
<!--   # If temp has sampled coordinates, then split into longitude and latitude and return -->
<!--   # Else, assign and return NAs -->
<!--   if (!is.null(temp)) { -->
<!--     longitude <- temp@coords[, 1] -->
<!--     latitude <- temp@coords[, 2] -->
<!--     return(tibble(longitude = longitude, latitude = latitude)) -->
<!--   } else { -->
<!--     return(tibble(longitude = NA, latitude = NA)) -->
<!--   } -->
<!-- } -->
<!-- ``` -->
<!-- ##### latlong_function -->
<!-- The second function subsets the full data set by loan type and race/ethnicity and then iterates `get_coordinates()`, the function from above, across the subset.  -->
<!-- The code looks more complicated than it really is. First, the quasi-quotation is necessary because of tidy evaluation. Second, the function created nested vectors that need to be unnested with `unnest()`. -->
<!-- ```{r latlong_function, eval = FALSE} -->
<!-- latlong_function <- function(loan_type, race_ethnicity, formula, race.ethnicity, loan.type) { -->
<!--   # Purpose: Take df with one observation per Census tract and return df with one observation per 10 mortgages with coordinates -->
<!--   # Args:  -->
<!--   #   loan_type: purchase or refinance -->
<!--   #   race_ethnicity: total, aa, his, asian, nhw -->
<!--   #   formula: total > 0, aa > 0, his > 0, asian > 0, nhw > 0 -->
<!--   #   race.ehtnicity: -->
<!--   #   loan.type: -->
<!--   # Output: one of ten combinations of race and mortgage type -->
<!--  # Create quasi-quoted arguments  -->
<!--   race_ethnicity <- enquo(race_ethnicity) -->
<!--   formula <- enquo(formula) -->
<!--   # Print statements to keep track of progress -->
<!--   print(formula) -->
<!--   print(race_ethnicity) -->
<!--   print(exists("tracts_shapefile")) -->
<!--   # Match the positions of the Census tracts and subset by race/ethnicity -->
<!--   temp <- loan_type %>% -->
<!--    group_by(tract) %>% -->
<!--    mutate(position = match(tract, -->
<!--                            as.numeric(as.character(tracts_shapefile@data$GEOID)))) %>% -->
<!--    filter(!!formula) %>% -->
<!--    arrange(position)  -->
<!--   # If the subsetted data frame has > zero rows, then run get_coordinates -->
<!--   # Else, don't run get_coordinates and go to the next observation -->
<!--   if (nrow(temp) > 0) { -->
<!--    temp <- temp %>% -->
<!--      mutate(coordinates = map2(.x = unique(position),  -->
<!--                                .y = !!race_ethnicity,  -->
<!--                                .f = get_coordinates)) %>% -->
<!--      mutate(raceethnicity = race.ethnicity,  -->
<!--             loantype = loan.type) %>% -->
<!--      unnest() -->
<!--    return(temp) -->
<!--   } else { -->
<!--    rm(temp) -->
<!--   } -->
<!-- } -->
<!-- ``` -->
<!-- ##### readR() -->
<!-- The third function reads shapefiles, changes the map projection of the shapefiles, and runs `latlong_function()` on each race/ethnicity. It takes a shapefile name and returns a tidy tibble with observations for every ~10 mortgages.  -->
<!-- ```{r readR, eval = FALSE} -->
<!-- readR <- function(shapefile) { -->
<!--   # Purpose: Reads the state shapefile, set the map projection, and sample -->
<!--   #         for total plus the four race/ethnicity groups -->
<!--   # Args:  -->
<!--   #   shapefile: Name of the shapefile for sampling -->
<!--   # Output: Tibble with observations for every ten mortgages -->
<!--  # Read the relevant shapefile -->
<!--  tracts_shapefile <<- readOGR(paste0("mapping/shapefiles/", shapefile)) -->
<!--  # Set the map projection for the shapefile -->
<!--  tracts_shapefile <<- spTransform(tracts_shapefile, "+init=epsg:4326") -->
<!--  # Confirm the shapefile exists -->
<!--  print(exists("tracts_shapefile")) -->
<!--  # Create data frames for each race/ethnicity -->
<!--   purchase_total <- latlong_function(loan_type = purchase,  -->
<!--                                     race_ethnicity = total,  -->
<!--                                     formula = total > 0,  -->
<!--                                     race.ethnicity = "total",  -->
<!--                                     loan.type = "purchase") -->
<!--   purchase_aa <-    latlong_function(loan_type = purchase,  -->
<!--                                     race_ethnicity = aa,  -->
<!--                                     formula = aa > 0,  -->
<!--                                     race.ethnicity = "aa",  -->
<!--                                     loan.type = "purchase") -->
<!--   purchase_his <-   latlong_function(loan_type = purchase,  -->
<!--                                     race_ethnicity = his,  -->
<!--                                     formula = his > 0,  -->
<!--                                     race.ethnicity = "his",  -->
<!--                                     loan.type = "purchase") -->
<!--   purchase_asian <- latlong_function(loan_type = purchase,  -->
<!--                                     race_ethnicity = asian,  -->
<!--                                     formula = asian > 0,  -->
<!--                                     race.ethnicity = "asian",  -->
<!--                                     loan.type = "purchase") -->
<!--   purchase_nhw <-   latlong_function(loan_type = purchase,  -->
<!--                                     race_ethnicity = nhw,  -->
<!--                                     formula = nhw > 0,  -->
<!--                                     race.ethnicity = "nhw",  -->
<!--                                     loan.type = "purchase") -->
<!--   # combine the five data frames into one data fram -->
<!--   full_dataset <- bind_rows(purchase_aa, purchase_asian, purchase_his, purchase_nhw, purchase_total) -->
<!--   rm(purchase_aa, purchase_asian, purchase_his, purchase_nhw, purchase_total) -->
<!--   return(full_dataset) -->
<!-- } -->
<!-- ``` -->
<!-- ##### iterate() -->
<!-- The above code loads packages and defines functions. Nothing actually happens until the functions are called. The following code chunk actually calls the function.  -->
<!-- `readR()` can be run on just one shapefile like `readR("tl_2012")` or it can be iterated across a vector of shapefile names using `map()` from `library(purrr)`. This example uses the former. The actual program used the latter and iterated across shapefiles and data from 2000 to 2016. Each observation had a data frame for the given year and three unique shapefiles were used because Census tracts change over time.  -->
<!-- This code loads the data using `read_csv()` and runs the function `readR()` on the 2012 shapefile for Rhode Island.  -->
<!-- ```{r iterate, eval = FALSE} -->
<!-- purchase <- read_csv("mapping/data/hmdamap2012_10_purch.csv",  -->
<!--  col_types = cols( -->
<!--   tract = col_double(), -->
<!--   year1 = col_integer(), -->
<!--   tract_T = col_character(), -->
<!--   aa = col_integer(), -->
<!--   his = col_integer(), -->
<!--   nhw = col_integer(), -->
<!--   asian = col_integer(), -->
<!--   total = col_integer())) %>%  -->
<!--  filter(str_detect(tract, "^44")) %>% -->
<!--  filter(asian > 0) -->
<!-- rhode_island <- readR("tl_2012") -->
<!-- ``` -->
<!-- Once the coordinates are sampled, it's simple to create a dot density map using the methods from above.  -->
<!-- # Putting it all together -->
<!-- ------ -->
<!-- This section is a repository of advanced maps made in R.  -->
<!-- This plot uses `grid.arrange()` from `library(gridExtra)` to add a bar plot of the same data below the tile grid map. -->
<!-- ```{r state choropleth and bar, fig.height=6} -->
<!-- library(tidyverse) -->
<!-- library(forcats) -->
<!-- library(gridExtra) -->
<!-- library(urbnmapr) -->
<!-- chip <- read_csv("mapping/data/chip-enrollment.csv") -->
<!-- # create groupings for states      -->
<!-- chip <- chip %>% -->
<!--   mutate(state_name = State) %>% -->
<!--   arrange(`CHIP Enrollment`) %>% -->
<!--   mutate(enrollment_group = c(rep("Group 1", 11),  -->
<!--                               rep("Group 2", 10),  -->
<!--                               rep("Group 3", 10),  -->
<!--                               rep("Group 4", 10),  -->
<!--                               rep("Group 5", 10))) -->
<!-- states_subset <- left_join(states, chip, by = "state_name") -->
<!-- # create a vector with 5 hexadecimal colors for the 5 groups -->
<!-- urban_colors <- c("#cfe8f3", "#a2d4ec", "#46abdb", "#12719e", "#062635") -->
<!-- # Plot! -->
<!-- chip_map <- states_subset %>% -->
<!--  ggplot(aes(x = long, y = lat, group = group, fill = enrollment_group)) + -->
<!--   geom_polygon(color = "#ffffff", size = 0.25) + -->
<!--   scale_fill_manual(values = urban_colors) +   -->
<!--   coord_map("albers", lat0 = 39, lat1 = 45) +   -->
<!--   labs(title = "State CHIP Enrollment") + -->
<!--   theme(plot.margin = margin(t = 0, r = 0, b = 0, l = 0)) -->
<!-- # bar plot -->
<!-- chip_bar_plot <- chip %>% -->
<!--   ggplot(aes(x = fct_reorder(state_abbreviation, `CHIP Enrollment`),  -->
<!--             y = `CHIP Enrollment`, fill = enrollment_group)) + -->
<!--   geom_bar(stat = "identity") + -->
<!--   scale_fill_manual(values = urban_colors) + -->
<!--   scale_y_continuous(expand = c(0, 0)) + -->
<!--   labs(x = NULL, -->
<!--        y = NULL, -->
<!--        caption = "Urban Institute") + -->
<!--   theme(panel.grid = element_blank(), -->
<!--         axis.text.y = element_blank(), -->
<!--         axis.ticks = element_blank(), -->
<!--         axis.line = element_blank(), -->
<!--         axis.text = element_text(size = 6L), -->
<!--         legend.position = "none", -->
<!--        plot.margin = margin(t = 0, r = 0, b = 0, l = 0)) -->
<!-- grid.arrange(chip_map, chip_bar_plot, ncol = 1, heights = c(2, 1)) -->
<!-- ``` -->
</div>
</div>
<div id="bibliography-and-references" class="section level2">
<h2>Bibliography and references</h2>
<hr />
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.6.1 (2019-07-05)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.3
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] urbnthemes_0.0.1    urbnmapr_0.0.0.9002 sf_0.7-6           
##  [4] rnaturalearth_0.1.0 kableExtra_1.1.0    knitr_1.23         
##  [7] forcats_0.4.0       stringr_1.4.0       dplyr_0.8.3        
## [10] purrr_0.3.2         readr_1.3.1         tidyr_0.8.3        
## [13] tibble_2.1.3        ggplot2_3.2.0       tidyverse_1.2.1    
## 
## loaded via a namespace (and not attached):
##  [1] ggrepel_0.8.1      Rcpp_1.0.1         lubridate_1.7.4   
##  [4] lattice_0.20-38    class_7.3-15       assertthat_0.2.1  
##  [7] zeallot_0.1.0      digest_0.6.20      R6_2.4.0          
## [10] cellranger_1.1.0   backports_1.1.4    evaluate_0.14     
## [13] e1071_1.7-2        httr_1.4.0         pillar_1.4.2      
## [16] rlang_0.4.0        lazyeval_0.2.2     readxl_1.3.1      
## [19] rstudioapi_0.10    extrafontdb_1.0    rmarkdown_1.14    
## [22] webshot_0.5.1      extrafont_0.17     munsell_0.5.0     
## [25] broom_0.5.2        compiler_3.6.1     modelr_0.1.4      
## [28] xfun_0.8           pkgconfig_2.0.2    rgeos_0.4-3       
## [31] htmltools_0.3.6    tidyselect_0.2.5   gridExtra_2.3     
## [34] viridisLite_0.3.0  crayon_1.3.4       withr_2.1.2       
## [37] grid_3.6.1         nlme_3.1-140       jsonlite_1.6      
## [40] Rttf2pt1_1.3.7     gtable_0.3.0       DBI_1.0.0         
## [43] magrittr_1.5       units_0.6-3        scales_1.0.0      
## [46] KernSmooth_2.23-15 cli_1.1.0          stringi_1.4.3     
## [49] sp_1.3-1           xml2_1.2.0         vctrs_0.2.0       
## [52] generics_0.0.2     tools_3.6.1        glue_1.3.1        
## [55] hms_0.5.0          yaml_2.2.0         colorspace_1.4-1  
## [58] classInt_0.3-3     rvest_0.3.4        haven_2.1.1</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
