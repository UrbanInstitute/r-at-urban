<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114294141-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-114294141-1');
</script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R PROGRAMMING AT THE URBAN INSTITUTE</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="intro-to-r.html">INTRO TO R</a>
</li>
<li>
  <a href="graphics-guide.html">PLOTTING</a>
</li>
<li>
  <a href="mapping.html">MAPPING</a>
</li>
<li>
  <a href="optimization.html">OPTIMIZATION</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" /></p>
<div id="header">
<div class="figure">
<img src="mapping/images/urban-institute-logo.png" />

</div>
<hr />
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This guide outlines some of the many tools and tips for improving the speed and execution of your R code.</p>
<p>Sometimes, simply tweaking a few lines of code can lead to large performance gains in the execution of your program. Other issues may take more time to work through but can be a huge benefit to your project in the long term. An important lesson to learn when it comes to optimising your R (or any) program is knowing when to stop. Be sure to consider what “fast enough” is for your project and how much needs to be optimised.</p>
<p>For more information, see the CRAN Task View <a href="&#39;https://CRAN.R-project.org/view=HighPerformanceComputing&#39;">High-Performance and Parallel Computing with R</a>.</p>
<hr />
</div>
<div id="update-your-installation" class="section level1">
<h1>Update Your Installation</h1>
<p>It is easy to let your version of R lapse and lag behind the release schedule, but this is one of the easiest ways to improve the performance of R! In general, R will have a big annual release (i.e., 3.5.0) in the Spring and around 3-4 smaller patch releases (i.e., 3.5.1) throughout the rest of the year. If the middle digit of your installation is behind the current release, you should consider updating.</p>
<p>For instance, R 3.5.0 implemented an improved read from text files. A 5GB file took over 5 minutes to read in 3.4.4:</p>
<div class="figure">
<img src="optimization/images/data-load-3-4.png" style="width:75.0%" />

</div>
<p>While 3.5.0 took less than half the time:</p>
<div class="figure">
<img src="optimization/images/data-load-3-5.png" style="width:75.0%" />

</div>
<p>To see what the R-core development team is up to, check out the <a href="&#39;https://cran.r-project.org/doc/manuals/r-devel/NEWS.html&#39;">NEWS</a> file from the R project.</p>
<hr />
</div>
<div id="parallel-computing" class="section level1">
<h1>Parallel Computing</h1>
<p>Often times, time-intensive R code can be sped up by breaking the execution of the job across additional cores of your computer.</p>
<div id="learn-lapplypurrrmap" class="section level2">
<h2>Learn <code>lapply</code>/<code>purrr::map</code></h2>
<p>The first step in learning to run R code in parallel is learning the <code>lapply</code> (and variants) function from Base R or the <code>map</code> (and variants) function from the <code>purrr</code> package. Once you understand how <code>lapply</code> and <code>map</code> work, running your code in parallel will be simple.</p>
<p>Say you have a vector of numbers and want to find the square root of each one (ignore for now that <code>sqrt</code> is vectorised, which will be covered later). You could write a for loop and iterate over each element of the vector:</p>
<pre class="r"><code>x &lt;- c(1, 4, 9, 16)

out &lt;- vector(&#39;list&#39;, length(x))
for (i in seq_along(x)) {
    out[[i]] &lt;- sqrt(x[[i]])
}
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>The <code>lapply</code> function essentially handles the overhead of constructing a for loop for you. The syntax is:</p>
<pre class="r"><code>lapply(X, FUN, ...)</code></pre>
<p><code>lapply</code> will then take each element of <code>X</code> and apply the <code>FUN</code>ction to it. Our simple example then becomes:</p>
<pre class="r"><code>x &lt;- c(1, 4, 9, 16)
out &lt;- lapply(x, sqrt)
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>Those working within the <code>tidyverse</code> may use <code>map</code> from the <code>purrr</code> package equivalently:</p>
<pre class="r"><code>library(purrr)
x &lt;- c(1, 4, 9, 16)
out &lt;- map(x, sqrt)
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
</div>
<div id="motivating-example" class="section level2">
<h2>Motivating Example</h2>
<p>Once you are comfortable with <code>lapply</code> and/or <code>map</code>, running the same code in parallel takes just an additional line of code.</p>
<p>For <code>lapply</code> users, the <code>future.apply</code> package contains an equivalent <code>future_lapply</code> function. Just be sure to call <code>plan(multiprocess)</code> beforehand, which will handle the back-end orchestration needed to run in parallel.</p>
<pre class="r"><code># install.packages(&#39;future.apply&#39;)
library(future.apply)
plan(multiprocess)
out &lt;- future_lapply(x, sqrt)
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>For <code>purrr</code> users, the <code>furrr</code> (i.e., future purrr) package includes an equivalent <code>future_map</code> function:</p>
<pre class="r"><code># install.packages(&#39;furrr&#39;)
library(furrr)
plan(multiprocess)
y &lt;- future_map(x, sqrt)
unlist(y)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>How much faster did this simple example run in parallel?</p>
<pre class="r"><code>library(future.apply)
plan(multiprocess)

x &lt;- c(1, 4, 9, 16)

microbenchmark::microbenchmark(
    sequential = lapply(x, sqrt),
    parallel = future_lapply(x, sqrt),
    unit = &#39;s&#39;
)</code></pre>
<pre><code>## Unit: seconds
##        expr        min         lq          mean      median           uq
##  sequential 0.00000264 0.00000352 0.00000533203 0.000004399 0.0000064525
##    parallel 0.02238173 0.02285573 0.04217333952 0.023357137 0.0247217980
##          max neval cld
##  0.000025217   100  a 
##  1.845420337   100   b</code></pre>
<p>Parallelization was actually slower. In this case, the overhead of setting the code to run in parallel far outweighed any performance gain. In general, parallelization works well on long-running &amp; compute intensive jobs.</p>
</div>
<div id="a-somewhat-more-complex-example" class="section level2">
<h2>A (somewhat) More Complex Example</h2>
<p>In this example we’ll use the <code>diamonds</code> dataset from <code>ggplot2</code> and perform a kmeans cluster. We’ll use <code>lapply</code> to iterate the number of clusters from 2 to 5:</p>
<pre class="r"><code>df &lt;- ggplot2::diamonds
df &lt;- dplyr::select(df, -c(cut, color, clarity))

centers = 2:5

system.time(
    lapply(centers, 
                 function(x) kmeans(df, centers = x, nstart = 500)
                 )
    )</code></pre>
<pre><code>##    user  system elapsed 
##   45.68    0.39   46.10</code></pre>
<p>A now running the same code in parallel:</p>
<pre class="r"><code>library(future.apply)
plan(multiprocess)

system.time(
    future_lapply(centers, 
                                function(x) kmeans(df, centers = x, nstart = 500)
                                )
    )</code></pre>
<pre><code>##    user  system elapsed 
##    0.07    0.15   27.69</code></pre>
<p>While we didn’t achieve perfect scaling, we still get a nice bump in execution time.</p>
</div>
<div id="additional-packages" class="section level2">
<h2>Additional Packages</h2>
<p>For the sake of ease and brevity, this guide focused on the <code>futures</code> framework for parallelization. However, you should be aware that there are a number of other ways to parallelize your code.</p>
<div id="the-parallel-package" class="section level3">
<h3>The <code>parallel</code> Package</h3>
<p>The <code>parallel</code> package is included in your base R installation. It includes analogues of the various <code>apply</code> functions:</p>
<ul>
<li><code>parLapply</code></li>
<li><code>mclapply</code> - not available on Windows</li>
</ul>
<p>These functions generally require more setup, especially on Windows machines.</p>
</div>
<div id="the-doparallel-package" class="section level3">
<h3>The <code>doParallel</code> Package</h3>
<p>The <code>doParallel</code> package builds off of <code>parallel</code> and is useful for code that uses for loops instead of <code>lapply</code>. Like the parallel package, it generally requires more setup, especially on Windows machines.</p>
</div>
<div id="machine-learning---caret" class="section level3">
<h3>Machine Learning - <code>caret</code></h3>
<p>For those running machine learning models, the <code>caret</code> package can easily leverage <code>doParallel</code> to speed up the execution of multiple models. Lifting the example from the package documentation:</p>
<pre class="r"><code>library(doParallel)
cl &lt;- makePSOCKcluster(5) # number of cores to use
registerDoParallel(cl)

## All subsequent models are then run in parallel
model &lt;- train(y ~ ., data = training, method = &quot;rf&quot;)

## When you are done:
stopCluster(cl)</code></pre>
<p>Be sure to check out the full <a href="&#39;http://topepo.github.io/caret/parallel-processing.html&#39;">documentation</a> for more detail.</p>
<hr />
</div>
</div>
</div>
<div id="big-data" class="section level1">
<h1>Big Data</h1>
<p>As data collection and storage becomes easier and cheaper, it is relatively simple to obtain relatively large data files. An important point to keep in mind is that the size of your data will generally expand when it is read from a storage device into R. A general rule of thumb is that a file will take somewhere around 3-4 times more space in memory than it does on disk.</p>
<p>For instance, compare the size of the <code>iris</code> data set when it is saved as a csv file locally vs the size of the object when it is read in to an R session:</p>
<pre class="r"><code>file.size(&#39;optimization/iris.csv&#39;) / 1000</code></pre>
<pre><code>## [1] 3.716</code></pre>
<pre class="r"><code>df &lt;- readr::read_csv(&#39;optimization/iris.csv&#39;)
pryr::object_size(df)</code></pre>
<pre><code>## 9.7 kB</code></pre>
<p>This means that on a standard Urban Institute desktop, you may have issues reading in files that are larger than 4 GB.</p>
<div id="object-size" class="section level2">
<h2>Object Size</h2>
<p>The type of your data can have a big impact on the size of your data frame when you are dealing with larger files. There are four main types of atomic vectors in R:</p>
<ol style="list-style-type: decimal">
<li><code>logical</code></li>
<li><code>integer</code></li>
<li><code>double</code> (also called <code>numeric</code>)</li>
<li><code>character</code></li>
</ol>
<p>Each of these data types occupy a different amount of space in memory - <code>logical</code> and <code>integer</code> vectors use 4 bytes per element, while a <code>double</code> will occupy 8 bytes. R uses a global string pool, so <code>character</code> vectors are hard to estimate, but will generally take up more space for element.</p>
<p>Consider the following example:</p>
<pre class="r"><code>x &lt;- 1:100
pryr::object_size(x)</code></pre>
<pre><code>## 448 B</code></pre>
<pre class="r"><code>pryr::object_size(as.double(x))</code></pre>
<pre><code>## 848 B</code></pre>
<pre class="r"><code>pryr::object_size(as.character(x))</code></pre>
<pre><code>## 6.45 kB</code></pre>
<p>An incorrect data type can easily cost you a lot of space in memory, especially at scale. This often happens when reading data from a text or csv file - data may have a format such as <code>c(1.0, 2.0, 3.0)</code> and will be read in as a <code>numeric</code> column, when <code>integer</code> is more appropriate (and compact).</p>
<p>You may also be familiar with <code>factor</code> variables within R. Essentially a <code>factor</code> will represent your data as integers, and map them back to their character representation. This can save memory when you have a compact and unique level of factors:</p>
<pre class="r"><code>x &lt;- sample(letters, 10000, replace = T)
pryr::object_size(as.character(x))</code></pre>
<pre><code>## 81.5 kB</code></pre>
<pre class="r"><code>pryr::object_size(as.factor(x))</code></pre>
<pre><code>## 42.1 kB</code></pre>
<p>However if each element is unique, or if there is not a lot of overlap among elements, than the overhead will make a factor larger than its character representation:</p>
<pre class="r"><code>pryr::object_size(as.factor(letters))</code></pre>
<pre><code>## 2.22 kB</code></pre>
<pre class="r"><code>pryr::object_size(as.character(letters))</code></pre>
<pre><code>## 1.71 kB</code></pre>
</div>
<div id="cloud-computing" class="section level2">
<h2>Cloud Computing</h2>
<p>Sometimes, you will have data that are simply too large to ever fit on your local desktop machine. If that is the case, then the Elastic Cloud Computing Environment from the Office of Technology and Data Science can provide you with easy access to powerful analytic tools for computationally intensive project.</p>
<p>The Elastic Cloud Computing Environment allows researchers to quickly spin-up an Amazon Web Services (AWS) Elastic Cloud Compute (EC2) instance. These instances offer increased memory to read in large datasets, along with additional CPUs to provide the ability to process data in parallel at an impressive scale.</p>
<table>
<thead>
<tr class="header">
<th>Instance</th>
<th>CPU</th>
<th>Memory (GB)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Desktop</td>
<td>8</td>
<td>16</td>
</tr>
<tr class="even">
<td>c5.4xlarge</td>
<td>16</td>
<td>32</td>
</tr>
<tr class="odd">
<td>c5.9xlarge</td>
<td>36</td>
<td>72</td>
</tr>
<tr class="even">
<td>c5.18xlarge</td>
<td>72</td>
<td>144</td>
</tr>
<tr class="odd">
<td>x1e.8xlarge</td>
<td>32</td>
<td>976</td>
</tr>
<tr class="even">
<td>x1e.16xlarge</td>
<td>64</td>
<td>1952</td>
</tr>
</tbody>
</table>
<p>Feel free to contact Kyle Ueyama (<a href="mailto:kueyama@urban.org">kueyama@urban.org</a>) if this would be useful for your project.</p>
<hr />
</div>
</div>
<div id="common-pitfalls" class="section level1">
<h1>Common Pitfalls</h1>
<div id="for-loops-and-vector-allocation" class="section level2">
<h2>For Loops and Vector Allocation</h2>
<p>A refrain you will often hear is that for loops in R are slow and need to be avoided at all costs. This is not true! Rather, an improperly formatted loop in R can bring the execution of your program to a near standstill.</p>
<p>A common for loop structure may look something like:</p>
<pre class="r"><code>x &lt;- 1:100
out &lt;- c()
for (i in x) {
    out &lt;- c(out, sqrt(x))
    }</code></pre>
<p>The bottleneck in this loop is with the allocation of the vector <code>out</code>. Every time we iterate over an item in <code>x</code> and append it to <code>out</code>, R makes a copy of all the items already in <code>out</code>. As the size of the loop grows, your code will take longer and longer to run.</p>
<p>A better practice is to pre-allocate <code>out</code> to be the correct length, and then insert the results as the loop runs.</p>
<pre class="r"><code>x &lt;- 1:100
out &lt;- rep(NA, length(x))
for (i in seq_along(x)) {
        out[i] &lt;- sqrt(x[i])
}</code></pre>
<p>A quick benchmark shows how much more efficient a loop with a pre-allocated results vector is:</p>
<pre class="r"><code>bad_loop &lt;- function(x) {
    out &lt;- c()
    for (i in x) {
        out &lt;- c(out, sqrt(x))
    }
}

good_loop &lt;- function(x) {
    out &lt;- rep(NA, length(x))
    for (i in seq_along(x)) {
        out[i] &lt;- sqrt(x[i])
    }
}

x &lt;- 1:100
microbenchmark::microbenchmark(
    bad_loop(x),
    good_loop(x)
)</code></pre>
<pre><code>## Unit: microseconds
##          expr     min       lq       mean   median       uq      max neval
##   bad_loop(x) 940.954 968.0775 1195.85930 976.8745 994.4675 4194.266   100
##  good_loop(x)  11.438  12.3170   54.36195  13.1955  19.5010 3792.551   100
##  cld
##    b
##   a</code></pre>
<p>And note how performance of the “bad” loop degrades as the loop size grows.</p>
<pre class="r"><code>y &lt;- 1:250

microbenchmark::microbenchmark(
    bad_loop(y),
    good_loop(y)
)</code></pre>
<pre><code>## Unit: microseconds
##          expr       min        lq        mean     median        uq
##   bad_loop(y) 14421.013 16362.883 17891.75841 16486.3310 16998.445
##  good_loop(y)    26.391    27.564    39.60104    46.3305    48.383
##         max neval cld
##  117146.200   100   b
##      68.029   100  a</code></pre>
</div>
<div id="vectorized-functions" class="section level2">
<h2>Vectorized Functions</h2>
<p>Many functions in R are vectorized, meaning they can accept an entire vector (and not just a single value) as input. The <code>sqrt</code> function is one:</p>
<pre class="r"><code>x &lt;- c(1, 4, 9, 16)
sqrt(x)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>This removes the need to use <code>lapply</code> or a for loop. Vectorized functions in R are generally written in a compiled language like C, C++, or FORTRAN, which makes their implementation faster.</p>
<pre class="r"><code>x &lt;- 1:100
microbenchmark::microbenchmark(
    lapply(x, sqrt),
    sqrt(x)
)</code></pre>
<pre><code>## Unit: nanoseconds
##             expr   min    lq     mean median    uq   max neval cld
##  lapply(x, sqrt) 36654 37827 39897.21  38414 39000 73600   100   b
##          sqrt(x)   880  1174  1476.12   1174  1467 10558   100  a</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
