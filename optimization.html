<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>optimization.utf8</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.12.4/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="site_libs/d3-3.5.6/d3.min.js"></script>
<link href="site_libs/profvis-0.3.6.9000/profvis.css" rel="stylesheet" />
<script src="site_libs/profvis-0.3.6.9000/profvis.js"></script>
<script src="site_libs/profvis-0.3.6.9000/scroll.js"></script>
<link href="site_libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlight-6.2.0/highlight.js"></script>
<script src="site_libs/profvis-binding-0.3.7/profvis.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114294141-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-114294141-1');
</script>
			

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R@URBAN</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">HOME</a>
</li>
<li>
  <a href="intro-to-r.html">INTRO TO R</a>
</li>
<li>
  <a href="graphics-guide.html">DATA VIZ</a>
</li>
<li>
  <a href="mapping.html">MAPPING</a>
</li>
<li>
  <a href="getting-data.html">GETTING DATA</a>
</li>
<li>
  <a href="optimization.html">OPTIMIZATION</a>
</li>
<li>
  <a href="resources.html">RESOURCES</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">




</div>


<p><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" /></p>
<div id="header">
<p><img src="graphics-guide/www/images/urban-institute-logo.png" width="350"></p>
</div>
<hr />
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This guide outlines tools and tips for improving the speed and execution of R code.</p>
<p>Sometimes, simply tweaking a few lines of code can lead to large performance gains in the execution of a program. Other issues may take more time to work through but can be a huge benefit to a project in the long term.</p>
<p>An important lesson to learn when it comes to optimising an R (or any) program is knowing both if to start and when to stop. You most likely want to optimize your code because it is “too slow”, but what that means will vary from project to project. Be sure to consider what “fast enough” is for your project and how much needs to be optimized. If your program takes an hour to complete, spending 5 hours trying to make it faster can be time well spent if the script will be run regularly, and a complete waste of time if it’s an ad-hoc analysis.</p>
<p>For more information, see the CRAN Task View <a href="%22https://CRAN.R-project.org/view=HighPerformanceComputing%22">High-Performance and Parallel Computing with R</a>. The “Performant Code” section of Hadley Wickham’s <a href="%22http://adv-r.had.co.nz/%22">Advanced R</a> is another great resource and provides a deeper dive into what is covered in this guide.</p>
<hr />
</div>
<div id="update-your-installation" class="section level1">
<h1>Update Your Installation</h1>
<p>One of the easiest ways to improve the performance of R is to update R. In general, R will have a big annual release (i.e., 3.5.0) in the spring and around 3-4 smaller patch releases (i.e., 3.5.1) throughout the rest of the year. If the middle digit of your installation is behind the current release, you should consider updating.</p>
<p>For instance, R 3.5.0 implemented an improved read from text files. A 5GB file took over 5 minutes to read in 3.4.4:</p>
<p><img src="optimization/images/data-load-3-4.PNG" style="width:75.0%" /></p>
<p>While 3.5.0 took less than half the time:</p>
<p><img src="optimization/images/data-load-3-5.PNG" style="width:75.0%" /></p>
<p>To see what the R-core development team is up to, check out the <a href="%22https://cran.r-project.org/doc/manuals/r-devel/NEWS.html%22">NEWS</a> file from the R project.</p>
<hr />
</div>
<div id="profiling-benchmarking" class="section level1">
<h1>Profiling &amp; Benchmarking</h1>
<p>In order to efficiently optimize your code, you’ll first need to know where it’s running slowest. The <code>profvis</code> package provides a nice way of visualizing the execution time and memory useage of your program.</p>
<pre class="r"><code>library(profvis)
library(dplyr)

profvis({
  diamonds &lt;- read.csv(&quot;optimization/data/diamonds.csv&quot;)
  
  diamonds_by_cut &lt;- diamonds %&gt;%
    group_by(cut) %&gt;%
    summarise_if(is.numeric, mean)

  write.csv(diamonds_by_cut, file = &quot;optimization/data/diamonds_by_cut.csv&quot;)  

})</code></pre>
<div id="htmlwidget-76695835bd90709ea3e0" style="width:100%;height:600px;" class="profvis html-widget"></div>
<script type="application/json" data-for="htmlwidget-76695835bd90709ea3e0">{"x":{"message":{"prof":{"time":[1,2,3,4,5,6,7,8,9,10,10,11,11,12,12,13,13,14,14,15,15,15,15,15,15,15,15,15,15,15,15],"depth":[1,1,1,1,1,1,1,1,1,2,1,2,1,2,1,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1],"label":["rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site","rmarkdown::render_site",".External2","rmarkdown::render_site",".External2","rmarkdown::render_site",".External2","rmarkdown::render_site",".External2","rmarkdown::render_site",".External2","rmarkdown::render_site","structure","result","vec_as_location2_result","vctrs::vec_as_location2","pull_as_location2","tidyselect::vars_pull","pull.data.frame","tbl_if_vars","tbl_if_syms","manip_if","summarise_if","rmarkdown::render_site"],"filenum":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],"linenum":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],"memalloc":[67.7286605834961,68.9579925537109,70.4354782104492,71.4316635131836,71.4594421386719,75.3666305541992,76.3449859619141,76.3492965698242,76.3563232421875,80.892448425293,80.892448425293,82.539665222168,82.539665222168,83.3632736206055,83.3632736206055,83.7750778198242,83.7750778198242,84.5986862182617,84.5986862182617,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797,85.8488006591797],"meminc":[0,1.22933197021484,1.47748565673828,0.996185302734375,0.0277786254882812,3.90718841552734,0.978355407714844,0.00431060791015625,0.00702667236328125,4.53612518310547,0,1.647216796875,0,0.8236083984375,0,0.41180419921875,0,0.8236083984375,0,1.25011444091797,0,0,0,0,0,0,0,0,0,0,0],"filename":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]},"interval":10,"files":[],"prof_output":"/var/folders/ts/g8jm0k5x6rn5g79xpwwv6mxh0000gp/T//RtmpicdH7v/file1b71223fad00.prof","highlight":{"output":["^output\\$"],"gc":["^<GC>$"],"stacktrace":["^\\.\\.stacktraceo(n|ff)\\.\\.$"]},"split":"h"}},"evals":[],"jsHooks":[]}</script>
<p>In this toy example it looks like the <code>read.csv</code> function is the bottleneck, so work on optimizing that first.</p>
<p>Once you find the bottleneck that needs to be optimized, it can be useful to benchmark different potential solutions. The <code>microbenchmark</code> package can help you choose between different options. Continuing with the simple example with the <code>diamonds</code> dataset, compare the base <code>read.csv</code> function with <code>read_csv</code> from the <code>readr</code> package.</p>
<pre class="r"><code>library(microbenchmark)

microbenchmark(
  read.csv(&quot;optimization/data/diamonds.csv&quot;),
  readr::read_csv(&quot;optimization/data/diamonds.csv&quot;)
)</code></pre>
<pre><code>## Unit: milliseconds
##                                               expr      min        lq      mean
##         read.csv(&quot;optimization/data/diamonds.csv&quot;) 120.2320 137.32697 147.46531
##  readr::read_csv(&quot;optimization/data/diamonds.csv&quot;)  57.3842  71.89926  80.42523
##     median        uq      max neval
##  145.84582 154.93127 231.2173   100
##   77.58492  80.89209 380.3795   100</code></pre>
<p>In this case, <code>read_csv</code> is about twice as fast as the base R implementations.</p>
</div>
<div id="parallel-computing" class="section level1">
<h1>Parallel Computing</h1>
<p>Often, time-intensive R code can be sped up by breaking the execution of the job across additional cores of your computer. This is called parallel computing.</p>
<div id="learn-lapplypurrrmap" class="section level2">
<h2>Learn <code>lapply</code>/<code>purrr::map</code></h2>
<p>Learning the <code>lapply</code> (and variants) function from Base R or the <code>map</code> (and variants) function from the <code>purrr</code> package is the first step in learning to run R code in parallel. Once you understand how <code>lapply</code> and <code>map</code> work, running your code in parallel will be simple.</p>
<p>Say you have a vector of numbers and want to find the square root of each one (ignore for now that <code>sqrt</code> is vectorized, which will be covered later). You could write a for loop and iterate over each element of the vector:</p>
<pre class="r"><code>x &lt;- c(1, 4, 9, 16)

out &lt;- vector(&quot;list&quot;, length(x))
for (i in seq_along(x)) {
  out[[i]] &lt;- sqrt(x[[i]])
}
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>The <code>lapply</code> function essentially handles the overhead of constructing a for loop for you. The syntax is:</p>
<pre class="r"><code>lapply(X, FUN, ...)</code></pre>
<p><code>lapply</code> will then take each element of <code>X</code> and apply the <code>FUN</code>ction to it. Our simple example then becomes:</p>
<pre class="r"><code>x &lt;- c(1, 4, 9, 16)
out &lt;- lapply(x, sqrt)
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>Those working within the <code>tidyverse</code> may use <code>map</code> from the <code>purrr</code> package equivalently:</p>
<pre class="r"><code>library(purrr)
x &lt;- c(1, 4, 9, 16)
out &lt;- map(x, sqrt)
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
</div>
<div id="motivating-example" class="section level2">
<h2>Motivating Example</h2>
<p>Once you are comfortable with <code>lapply</code> and/or <code>map</code>, running the same code in parallel takes just an additional line of code.</p>
<p>For <code>lapply</code> users, the <code>future.apply</code> package contains an equivalent <code>future_lapply</code> function. Just be sure to call <code>plan(multiprocess)</code> beforehand, which will handle the back-end orchestration needed to run in parallel.</p>
<pre class="r"><code># install.packages(&quot;future.apply&quot;)
library(future.apply)
plan(multiprocess)
out &lt;- future_lapply(x, sqrt)
unlist(out)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>For <code>purrr</code> users, the <code>furrr</code> (i.e., future purrr) package includes an equivalent <code>future_map</code> function:</p>
<pre class="r"><code># install.packages(&quot;furrr&quot;)
library(furrr)
plan(multiprocess)
y &lt;- future_map(x, sqrt)
unlist(y)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>How much faster did this simple example run in parallel?</p>
<pre class="r"><code>library(future.apply)
plan(multiprocess)

x &lt;- c(1, 4, 9, 16)

microbenchmark::microbenchmark(
  sequential = lapply(x, sqrt),
  parallel = future_lapply(x, sqrt),
  unit = &quot;s&quot;
)</code></pre>
<pre><code>## Unit: seconds
##        expr         min           lq          mean     median           uq
##  sequential 0.000002107 0.0000025975 0.00000469366 0.00000400 0.0000060765
##    parallel 0.033693094 0.0375520385 0.04399394394 0.03855981 0.0401421545
##          max neval
##  0.000025002   100
##  0.368216916   100</code></pre>
<p>Parallelization was actually slower. In this case, the overhead of setting the code to run in parallel far outweighed any performance gain. In general, parallelization works well on long-running &amp; compute intensive jobs.</p>
</div>
<div id="a-somewhat-more-complex-example" class="section level2">
<h2>A (somewhat) More Complex Example</h2>
<p>In this example we’ll use the <code>diamonds</code> dataset from <code>ggplot2</code> and perform a kmeans cluster. We’ll use <code>lapply</code> to iterate the number of clusters from 2 to 5:</p>
<pre class="r"><code>df &lt;- ggplot2::diamonds
df &lt;- dplyr::select(df, -c(cut, color, clarity))

centers = 2:5

system.time(
  lapply(centers, 
         function(x) kmeans(df, centers = x, nstart = 500)
         )
  )</code></pre>
<pre><code>##    user  system elapsed 
##  42.139   1.003  43.475</code></pre>
<p>A now running the same code in parallel:</p>
<pre class="r"><code>library(future.apply)
plan(multiprocess)

system.time(
  future_lapply(centers, 
                function(x) kmeans(df, centers = x, nstart = 500)
                )
  )</code></pre>
<pre><code>##    user  system elapsed 
##   0.420   0.021  22.844</code></pre>
<p>While we didn’t achieve perfect scaling, we still get a nice bump in execution time.</p>
</div>
<div id="additional-packages" class="section level2">
<h2>Additional Packages</h2>
<p>For the sake of ease and brevity, this guide focused on the <code>futures</code> framework for parallelization. However, you should be aware that there are a number of other ways to parallelize your code.</p>
<div id="the-parallel-package" class="section level3">
<h3>The <code>parallel</code> Package</h3>
<p>The <code>parallel</code> package is included in your base R installation. It includes analogues of the various <code>apply</code> functions:</p>
<ul>
<li><code>parLapply</code></li>
<li><code>mclapply</code> - not available on Windows</li>
</ul>
<p>These functions generally require more setup, especially on Windows machines.</p>
</div>
<div id="the-doparallel-package" class="section level3">
<h3>The <code>doParallel</code> Package</h3>
<p>The <code>doParallel</code> package builds off of <code>parallel</code> and is useful for code that uses for loops instead of <code>lapply</code>. Like the parallel package, it generally requires more setup, especially on Windows machines.</p>
</div>
<div id="machine-learning---caret" class="section level3">
<h3>Machine Learning - <code>caret</code></h3>
<p>For those running machine learning models, the <code>caret</code> package can easily leverage <code>doParallel</code> to speed up the execution of multiple models. Lifting the example from the package documentation:</p>
<pre class="r"><code>library(doParallel)
cl &lt;- makePSOCKcluster(5) # number of cores to use
registerDoParallel(cl)

## All subsequent models are then run in parallel
model &lt;- train(y ~ ., data = training, method = &quot;rf&quot;)

## When you are done:
stopCluster(cl)</code></pre>
<p>Be sure to check out the full <a href="%22http://topepo.github.io/caret/parallel-processing.html%22">documentation</a> for more detail.</p>
<hr />
</div>
</div>
</div>
<div id="big-data" class="section level1">
<h1>Big Data</h1>
<p>As data collection and storage becomes easier and cheaper, it is relatively simple to obtain relatively large data files. An important point to keep in mind is that the size of your data will generally expand when it is read from a storage device into R. A general rule of thumb is that a file will take somewhere around 3-4 times more space in memory than it does on disk.</p>
<p>For instance, compare the size of the <code>iris</code> data set when it is saved as a .csv file locally vs the size of the object when it is read in to an R session:</p>
<pre class="r"><code>file.size(&quot;optimization/data/iris.csv&quot;) / 1000</code></pre>
<pre><code>## [1] 3.716</code></pre>
<pre class="r"><code>df &lt;- readr::read_csv(&quot;optimization/data/iris.csv&quot;)
pryr::object_size(df)</code></pre>
<pre><code>## 10,144 B</code></pre>
<p>This means that on a standard Urban Institute desktop, you may have issues reading in files that are larger than 4 GB.</p>
<div id="object-size" class="section level2">
<h2>Object Size</h2>
<p>The type of your data can have a big impact on the size of your data frame when you are dealing with larger files. There are four main types of atomic vectors in R:</p>
<ol style="list-style-type: decimal">
<li><code>logical</code></li>
<li><code>integer</code></li>
<li><code>double</code> (also called <code>numeric</code>)</li>
<li><code>character</code></li>
</ol>
<p>Each of these data types occupies a different amount of space in memory - <code>logical</code> and <code>integer</code> vectors use 4 bytes per element, while a <code>double</code> will occupy 8 bytes. R uses a global string pool, so <code>character</code> vectors are hard to estimate, but will generally take up more space for element.</p>
<p>Consider the following example:</p>
<pre class="r"><code>x &lt;- 1:100
pryr::object_size(x)</code></pre>
<pre><code>## 680 B</code></pre>
<pre class="r"><code>pryr::object_size(as.double(x))</code></pre>
<pre><code>## 680 B</code></pre>
<pre class="r"><code>pryr::object_size(as.character(x))</code></pre>
<pre><code>## 1,264 B</code></pre>
<p>An incorrect data type can easily cost you a lot of space in memory, especially at scale. This often happens when reading data from a text or csv file - data may have a format such as <code>c(1.0, 2.0, 3.0)</code> and will be read in as a <code>numeric</code> column, when <code>integer</code> is more appropriate and compact.</p>
<p>You may also be familiar with <code>factor</code> variables within R. Essentially a <code>factor</code> will represent your data as integers, and map them back to their character representation. This can save memory when you have a compact and unique level of factors:</p>
<pre class="r"><code>x &lt;- sample(letters, 10000, replace = TRUE)
pryr::object_size(as.character(x))</code></pre>
<pre><code>## 81,504 B</code></pre>
<pre class="r"><code>pryr::object_size(as.factor(x))</code></pre>
<pre><code>## 42,096 B</code></pre>
<p>However if each element is unique, or if there is not a lot of overlap among elements, than the overhead will make a factor larger than its character representation:</p>
<pre class="r"><code>pryr::object_size(as.factor(letters))</code></pre>
<pre><code>## 2,224 B</code></pre>
<pre class="r"><code>pryr::object_size(as.character(letters))</code></pre>
<pre><code>## 1,712 B</code></pre>
</div>
<div id="cloud-computing" class="section level2">
<h2>Cloud Computing</h2>
<p>Sometimes, you will have data that are simply too large to ever fit on your local desktop machine. If that is the case, then the Elastic Cloud Computing Environment from the Office of Technology and Data Science can provide you with easy access to powerful analytic tools for computationally intensive project.</p>
<p>The Elastic Cloud Computing Environment allows researchers to quickly spin-up an Amazon Web Services (AWS) Elastic Cloud Compute (EC2) instance. These instances offer increased memory to read in large datasets, along with additional CPUs to provide the ability to process data in parallel at an impressive scale.</p>
<table>
<thead>
<tr class="header">
<th>Instance</th>
<th>CPU</th>
<th>Memory (GB)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Desktop</td>
<td>8</td>
<td>16</td>
</tr>
<tr class="even">
<td>c5.4xlarge</td>
<td>16</td>
<td>32</td>
</tr>
<tr class="odd">
<td>c5.9xlarge</td>
<td>36</td>
<td>72</td>
</tr>
<tr class="even">
<td>c5.18xlarge</td>
<td>72</td>
<td>144</td>
</tr>
<tr class="odd">
<td>x1e.8xlarge</td>
<td>32</td>
<td>976</td>
</tr>
<tr class="even">
<td>x1e.16xlarge</td>
<td>64</td>
<td>1952</td>
</tr>
</tbody>
</table>
<p>Feel free to contact Kyle Ueyama (<a href="mailto:kueyama@urban.org" class="email">kueyama@urban.org</a>) if this would be useful for your project.</p>
<hr />
</div>
</div>
<div id="common-pitfalls" class="section level1">
<h1>Common Pitfalls</h1>
<div id="for-loops-and-vector-allocation" class="section level2">
<h2>For Loops and Vector Allocation</h2>
<p>A refrain you will often hear is that for loops in R are slow and need to be avoided at all costs. This is not true! Rather, an improperly constructed loop in R can bring the execution of your program to a near standstill.</p>
<p>A common for loop structure may look something like:</p>
<pre class="r"><code>x &lt;- 1:100
out &lt;- c()
for (i in x) {
  out &lt;- c(out, sqrt(x))
  }</code></pre>
<p>The bottleneck in this loop is with the allocation of the vector <code>out</code>. Every time we iterate over an item in <code>x</code> and append it to <code>out</code>, R makes a copy of all the items already in <code>out</code>. As the size of the loop grows, your code will take longer and longer to run.</p>
<p>A better practice is to pre-allocate <code>out</code> to be the correct length, and then insert the results as the loop runs.</p>
<pre class="r"><code>x &lt;- 1:100
out &lt;- rep(NA, length(x))
for (i in seq_along(x)) {
    out[i] &lt;- sqrt(x[i])
}</code></pre>
<p>A quick benchmark shows how much more efficient a loop with a pre-allocated results vector is:</p>
<pre class="r"><code>bad_loop &lt;- function(x) {
  out &lt;- c()
  for (i in x) {
    out &lt;- c(out, sqrt(x))
  }
}

good_loop &lt;- function(x) {
  out &lt;- rep(NA, length(x))
  for (i in seq_along(x)) {
    out[i] &lt;- sqrt(x[i])
  }
}

x &lt;- 1:100
microbenchmark::microbenchmark(
  bad_loop(x),
  good_loop(x)
)</code></pre>
<pre><code>## Unit: microseconds
##          expr      min        lq       mean   median        uq       max neval
##   bad_loop(x) 1133.907 1280.3810 2153.34204 1306.498 1361.2990 23149.091   100
##  good_loop(x)    8.967    9.7835   59.98815   11.825   17.7585  4602.437   100</code></pre>
<p>And note how performance of the “bad” loop degrades as the loop size grows.</p>
<pre class="r"><code>y &lt;- 1:250

microbenchmark::microbenchmark(
  bad_loop(y),
  good_loop(y)
)</code></pre>
<pre><code>## Unit: microseconds
##          expr       min         lq        mean     median         uq       max
##   bad_loop(y) 17990.334 21339.4215 29670.12769 30832.4505 34137.1765 55490.188
##  good_loop(y)    20.455    21.7095    31.65612    35.9105    37.6965    67.979
##  neval
##    100
##    100</code></pre>
</div>
<div id="vectorized-functions" class="section level2">
<h2>Vectorized Functions</h2>
<p>Many functions in R are vectorized, meaning they can accept an entire vector (and not just a single value) as input. The <code>sqrt</code> function from the prior examples is one:</p>
<pre class="r"><code>x &lt;- c(1, 4, 9, 16)
sqrt(x)</code></pre>
<pre><code>## [1] 1 2 3 4</code></pre>
<p>This removes the need to use <code>lapply</code> or a for loop. Vectorized functions in R are generally written in a compiled language like C, C++, or FORTRAN, which makes their implementation faster.</p>
<pre class="r"><code>x &lt;- 1:100
microbenchmark::microbenchmark(
  lapply(x, sqrt),
  sqrt(x)
)</code></pre>
<pre><code>## Unit: nanoseconds
##             expr   min      lq     mean  median    uq   max neval
##  lapply(x, sqrt) 33083 33419.5 34710.16 33574.0 33883 59356   100
##          sqrt(x)   625   710.0   872.48   821.5   960  2705   100</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
